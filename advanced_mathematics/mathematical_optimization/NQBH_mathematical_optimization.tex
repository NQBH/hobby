\documentclass[oneside]{book}
\usepackage[backend=biber,natbib=true,style=authoryear]{biblatex}
\addbibresource{/home/hong/1_NQBH/reference/bib.bib}
\usepackage[vietnamese,english]{babel}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,float,graphicx}
\allowdisplaybreaks
\numberwithin{equation}{section}
\newtheorem{assumption}{Assumption}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{definition}{Definition}[chapter]
\newtheorem{example}{Example}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{notation}{Notation}[chapter]
\newtheorem{principle}{Principle}[chapter]
\newtheorem{problem}{Problem}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{question}{Question}[chapter]
\newtheorem{remark}{Remark}[chapter]
\newtheorem{theorem}{Theorem}[chapter]
\usepackage[left=0.5in,right=0.5in,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\small \textsc{Sect.} ~\thesection}
\rhead{\small \nouppercase{\leftmark}}
\renewcommand{\sectionmark}[1]{\markboth{#1}{}}
\cfoot{\thepage}
\def\labelitemii{$\circ$}

\title{Some Topics in Mathematical Optimization}
\author{\selectlanguage{vietnamese} Nguyễn Quản Bá Hồng\footnote{Independent Researcher, Ben Tre City, Vietnam\\e-mail: \texttt{nguyenquanbahong@gmail.com}}}
\date{\today}

\begin{document}
\maketitle
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\tableofcontents

\chapter*{Foreword}

A collection of \& some personal notes on Mathematical Optimization, especially the 3 major topics: Optimal Control, Shape Optimization, \& Topology Optimization.

\textbf{Keywords.} Optimal control; Shape optimization; Topology optimization.

%------------------------------------------------------------------------------%

\chapter{Wikipedia's}

\section{\href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}Shape Optimization}}
``\textit{Shape optimization} is part of the field of \href{https://en.wikipedia.org/wiki/Optimal_control}{optimal control} theory. The typical problem is to find the \href{https://en.wikipedia.org/wiki/Shape}{shape} which is optimal in that it minimizes a certain cost \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} while satisfying given \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraints}. In many cases, the functional being solved depends on the solution of a given \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{PDE} defined on the variable domain.

\href{https://en.wikipedia.org/wiki/Topology_optimization}{Topology optimization} is, in addition, concerned with the number of connected components\texttt{/}boundaries belonging to the domain. Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them. Topological optimization techniques can then help work around the limitations of pure shape optimization.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}shape optimization}

\subsection{Definition}
``Mathematically, shape optimization can be posed as the problem of finding a \href{https://en.wikipedia.org/wiki/Bounded_set}{bounded set} $\Omega$, \href{https://en.wikipedia.org/wiki/Maxima_and_minima}{minimizing} a \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} $\mathcal{F}(\Omega)$, possibly subject to a \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraint} of the form $\mathcal{G}(\Omega) = 0$. Usually we are interested in sets $\Omega$ which are \href{https://en.wikipedia.org/wiki/Lipschitz_continuity}{Lipschitz} or $C^1$ \href{https://en.wikipedia.org/wiki/Boundary_(topology)}{boundary} \& consist of finite many \href{https://en.wikipedia.org/wiki/Connected_component_(analysis)}{components}, which is a way of saying that we would like to find a rather pleasing shape as a solution, \fbox{not some jumble of rough bits \& pieces}. Sometimes additional constraints need to be imposed to that end to ensure well-posedness of the problem \& uniqueness of the solution.

Shape optimization is an \href{https://en.wikipedia.org/wiki/Infinite-dimensional_optimization}{infinite-dimensional optimization} problem. Furthermore, the space of allowable shapes over which the optimization is performed does not admit a \href{https://en.wikipedia.org/wiki/Vector_space}{vector space} structure, making application of traditional optimization methods more difficult.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Definition}{Wikipedia\texttt{/}shape optimization\texttt{/}definition}

\subsection{Examples}
\begin{itemize}
	\item ``among all 3D shapes of given volume, find the one which has minimal surface area. Here: $\mathcal{F}(\Omega) = \operatorname{Area}(\partial\Omega)$, with $\mathcal{G}(\Omega) = \operatorname{Volume}(\Omega) = {\rm const}$. The answer, given by the \href{https://en.wikipedia.org/wiki/Isoperimetric_inequality}{isoperimetric inequality}, is a \href{https://en.wikipedia.org/wiki/Ball_(mathematics)}{ball}.
	\item Find the shape of an airplane wing which minimizes \href{https://en.wikipedia.org/wiki/Drag_(physics)}{drag}. Here the constraints could be the wing strength, or the wing dimensions.
	\item Find the shape of various mechanical structures, which can resist a given \href{https://en.wikipedia.org/wiki/Stress_(physics)}{stress} while having a minimal mass\texttt{/}volume.
	\item Given a known 3D object with a fixed radiation source inside, deduce the shape \& size of the source based on measurements done on part of the boundary of the object. A formulation of this \href{https://en.wikipedia.org/wiki/Inverse_problem}{inverse problem} using \href{https://en.wikipedia.org/wiki/Least-squares}{least squares} fit leads to a shape optimization problem.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Examples}{Wikipedia\texttt{/}shape optimization\texttt{/}examples}
\end{itemize}

\subsection{Techniques}
``Shape optimization problems are usually solved \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerically}, by using \href{https://en.wikipedia.org/wiki/Iterative_method}{iterative methods}. I.e., one starts with an initial guess for a shape, \& then gradually evolves it, until it morphs into the optimal shape.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Techniques}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques}

\subsubsection{Keeping track of the shape}
\textsf{Fig. Example: Shape optimization as applied to building geometry. Example provided courtesy of \url{Formsolver.com}.}

``To solve a shape optimization problem, one needs to find a way to represent a shape in the \href{https://en.wikipedia.org/wiki/Computer_memory}{computer memory}, \& follow its evolution. Several approaches are usually used.

1 approach is to follow the boundary of the shape. For that, one can sample the shape boundary in a relatively dense \& uniform manner, i.e., to consider enough points to get a sufficiently accurate outline of the shape. Then, one can evolve the shape by gradually moving the boundary points. This is called the \textit{Lagrangian approach}.

Another approach is to consider a \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} defined on a rectangular box around the shape, which is positive inside of the shape, zero on the boundary of the shape, \& negative outside of the shape. One can then evolve this function instead of the shape itself. One can consider a rectangular grid on the box \& sample the function at the grid points. As the shape evolves, the grid points do not change; only the function values at the grid points change. This approach, of using a fixed grid, is called the \textit{Eulerian approach}. The idea of using a function to represent the shape is at the basis of the \href{https://en.wikipedia.org/wiki/Level-set_method}{level set method}.

\textsf{Fig. Example: Optimization shape families resulting from differing goal parameters. Example provided courtesy of \url{Formsolver.com}}

A 3rd approach is to \fbox{think of the shape evolution as of a flow problem}. I.e., one can imagine that the shape is made of a plastic material gradually deforming s.t. any point inside or on the boundary of the shape can be always traced back to a point of the original shape in a 1-1 fashion. Mathematically, if $\Omega_0$ is the initial shape, \& $\Omega_t$ is the shape at time $t$, one considers the \href{https://en.wikipedia.org/wiki/Diffeomorphism}{diffeomorphisms} $f_t:\Omega_0\to\Omega_t$, for $t\le t\le t_0$. The idea is again that shapes are difficult entities to be dealt with directly, so manipulate them by means of a function.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Keeping_track_of_the_shape}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}keeping track of the shape}

\subsubsection{Iterative methods using shape gradients}
``Consider a smooth velocity field $V$ \& the family of transformations $T_s$ of the initial domain $\Omega_0$ under the velocity field $V$: $x(0) = x_0\in\Omega_0$, $x'(s) = V(x(s))$, $T_s(x_0) = x(s)$, $s\ge 0$, \& denote $\Omega_0\mapsto T_s(\Omega_0) = \Omega_s$. Then the G\^ateaux or shape derivative of $\mathcal{F}(\Omega)$ at $\Omega_0$ w.r.t. the shape is the limit of
\begin{align*}
	d\mathcal{F}(\Omega_0;V) = \lim_{s\to 0} \frac{\mathcal{F}(\Omega_s) - \mathcal{F}(\Omega_0)}{s}
\end{align*}
if this limit exists. If in addition the derivative is linear w.r.t. $V$, there is a unique element of $\nabla\mathcal{F}\in L^2(\partial\Omega)$ \& $d\mathcal{F}(\Omega_0;V) = \langle\nabla\mathcal{F},V\rangle_{\partial\Omega_0}$ where $\nabla\mathcal{F}$ is called the \textit{shape gradient}. This gives a natural idea of \href{https://en.wikipedia.org/wiki/Gradient_descent}{gradient descent}, where the boundary $\partial\Omega$ is evolved in the direction of negative shape gradient in order to reduce the value of the cost functional. Higher order derivatives can be similarly defined, leading to Newtonlike methods.

Typically, gradient descent is preferred, even if requires a large number of iterations, because, it can be hard to compute the 2nd-order derivative (i.e., the \href{https://en.wikipedia.org/wiki/Hessian_matrix}{Hessian}) of the objective functional $\mathcal{F}$.

If the shape optimization problem has constrains, i.e., the functional $\mathcal{G}$ is present, one has to find ways to convert the constrained problem into an unconstrained one. Sometimes ideas based on \href{https://en.wikipedia.org/wiki/Lagrange_multipliers}{Lagrange multipliers}, like the \href{https://en.wikipedia.org/wiki/Adjoint_state_method}{adjoint state method}, can work.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Iterative_methods_using_shape_gradients}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}iterative methods using shape gradients}

\subsubsection{Geometry parametrization}
``Shape optimization can be faced using standard optimization methods if a parametrization of the geometry is defined. Such parametrization is very important in CAE field where goal functions are usually complex functions evaluated using numerical models (CFD, FEA, $\ldots$). A convenient approach, suitable for a wide class of problems, consists in the paramtrization of the CAD model coupled with a full automation of all the process required for function evaluation (meshing, solving \& result processing). \textit{Mesh morphing} is a valid choice for complex problems that resolves typical issues associated with \textit{re-meshing} such as discontinuities in the computed objective \& constraint functions. In this case the parametrization is defined after the meshing stage acting directly on the numerical model used for calculation that is changed using mesh updating methods. There are several algorithms available for mesh morphing (\textit{deforming volumes, pseudosolids}, \href{https://en.wikipedia.org/wiki/Radial_basis_function}{radical basis functions}). The selection of the parametrization approach depends mainly on the size of the problem: the CAD approach is preferred for small-to-medium sized models whilst the mesh morphing approach is the best (\& sometimes the only feasible one) for large \& very large models. The multi-objective Pareto optimization (NSGA II) could be utilized as a powerful approach for shape optimization. In this regard, the Pareto optimization approach displays useful advantages in design method such as the effect of area constraint that other multi-objective optimization cannot declare it. The approach of using a penalty function is an effective technique which could be used in the 1st stage of optimization. In this method the constrained shape design problem is adapted to an unconstrained problem with utilizing the constraints in the objective function as a penalty factor. Most of the time penalty factor is dependent to the amount of constraint variation rather than constrain number. The GA real-coded technique is applied in the present optimization problem. Therefore, the calculations are based on real value of variables.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Geometry_parametrization}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}geometry parametrization}

%------------------------------------------------------------------------------%

\section{\href{https://en.wikipedia.org/wiki/Topology_optimization}{Wikipedia\texttt{/}Topology Optimization}}
``\textit{Topology optimization (TO)} is a mathematical method that optimizes material layout within a given design space, for a given set of \href{https://en.wikipedia.org/wiki/Structural_load}{loads}, \href{https://en.wikipedia.org/wiki/Boundary_conditions}{boundary conditions} \& \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraints} with the goal of maximizing the performance of the system. Topology optimization is different from \href{https://en.wikipedia.org/wiki/Shape_optimization}{shape optimization} \& sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations.

The conventional topology optimization formulation uses a \href{https://en.wikipedia.org/wiki/Finite_element_method}{FEM} to evaluate the design performance. The design is optimized using either gradient-based \href{https://en.wikipedia.org/wiki/Mathematical_programming}{mathematical programming} techniques such as the optimality criteria algorithm \& the \textit{method of moving asymptotes} or non gradient-based algorithms such as \href{https://en.wikipedia.org/wiki/Genetic_algorithms}{genetic algorithms}.

Topology optimization has a wide range of applications in aerospace, mechanical, bio-chemical \& civil engineering. Currently, engineers mostly use topology optimization at the concept level of a \href{https://en.wikipedia.org/wiki/Engineering_design_process}{design process}. Due to the free forms that naturally occur, the result is often difficult to manufacture. For that reason the result emerging from topology optimization is often fine-tuned for manufacturability. Adding constraints to the formulation in order to \href{https://en.wikipedia.org/wiki/Design_for_manufacturability}{increase the manufacturability} is an active field of research. In some cases results from topology optimization can be directly manufactured using \href{https://en.wikipedia.org/wiki/Additive_manufacturing}{additive manufacturing}; topology optimization is thus a key part of \href{https://en.wikipedia.org/wiki/Design_for_additive_manufacturing}{design for additive manufacturing}.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization}{Wikipedia\texttt{/}topology optimization}

\subsection{Problem statement}
``A topology optimization problem can be written in the general form of an \href{https://en.wikipedia.org/wiki/Optimization_problem}{optimization problem} as
\begin{align*}
	\min_\rho F\mbox{ where } F = F({\bf u}(\rho),\rho) = \int_\Omega f({\bf u}(\rho),\rho)\,{\rm d}V\mbox{ subject to } G_0(\rho) = \int_\Omega \rho\,{\rm d}V - V_0\le 0,\ G_j({\bf u}(\rho),\rho)\le 0,\ j = 1,\ldots,m.
\end{align*}
The problem statement includes the following:
\begin{itemize}
	\item An \href{https://en.wikipedia.org/wiki/Objective_function}{objective function} $F({\bf u}(\rho),\rho)$. This function represents the quantity that is being minimized for best performance. The most common objective function is compliance, where minimizing compliance leads to maximizing the stiffness of a structure.
	\item The \textit{material distribution} as a problem variable. This is described by the density of the material at each location $\rho({\bf x})$. Material is either \textit{present}, indicated by a 1, or \textit{absent}, indicated by a 0. ${\bf u} = {\bf u}(\rho)$ is a state field that satisfies a linear or nonlinear state equation depending on $\rho$.
	\item The \textit{design space} $(\Omega)$. This indicates the allowable volume within which the design can exist. Assembly \& packaging requirements, human \& tool accessibility are some of the factors that need to be considered in identifying this space. With the definition of the design space, regions or components in the model that cannot be modified during the course of the optimization are considered as non-design regions.
	\item $m$ \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{contraints} $G_j({\bf u}(\rho),\rho)\le 0$ a characteristic that the solution must satisfy. Examples are the maximum amount of material to be distributed (volume constraint) or maximum stress values.
\end{itemize}
Evaluating ${\bf u}(\rho)$ often includes solving a differential equation. This is most commonly done using the FEM since these equations do not have a known analytical solution.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Problem_statement}{Wikipedia\texttt{/}topology optimization\texttt{/}problem statement}

\subsection{Implementation methodologies}
``There are various implementation methodologies that have been used to solve topology optimization problems.''

\subsubsection{Discrete}
``Solving topology optimization problems in a discrete sense is done by discretizing the design domain into finite elements. The material densities inside these elements are then treated as the problem variables. In this case material density of 1 indicates the presence of material, while 0 indicates an absence of material. Owning to the attainable topological complexity of the design being dependent on the number of elements, a large number is preferred. Large numbers of finite elements increases the attainable topological complexity, but come at a cost. 1stly, solving the FEM systems becomes more expensive. 2ndly, algorithms that can handle a large number (several thousands of elements is not uncommon) of discrete variables with multiple constraints are unavailable. Moreover, they are impractically sensitive to parameter variations. In literature problems with up to 30000 variables have been reported.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Discrete}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}discrete}

\subsubsection{Solving the problem with continuous variables}
``The earlier stated complexities with solving topology optimization problems using binary variables has caused the community to search for other options. One is the modeling of the densities with continuous variables. The material densities can now also attain values between 0 \& 1. Gradient based algorithms that handle large amounts of continuous variables \& multiple constraints are available. But the material properties have to be modeled in a continuous setting. This is done through interpolation. 1 of the most implemented interpolation methodologies is the \textit{Solid Isotropic Material with Penalization} method (SIMP). This interpolation is essentially a power law $E = E_0 + \rho^p(E_1 - E_0)$. It interpolates the Young's modulus of the material to the scalar selection field. The value of the penalization parameter $p$ is generally taken between $[1,3]$. This has been shown to confirm the micro-structure of the materials. In the SIMP method a lower bound on the Young's modulus is added, $E_0$, to make sure the derivatives of the objective function are nonzero when the density becomes 0. The higher the penalization factor, the more SIMP penalizes the algorithm in the use of non-binary densities. Unfortunately, the penalization parameter also introduces non-convexities.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Solving_the_problem_with_continuous_variables}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}solving the problem with continuous variables}

\subsubsection{Shape derivatives}
``Topology optimization can be achieved by using shape derivatives.'' 

\subsubsection{Topological derivatives}

\subsubsection{Level set}

\subsubsection{Phase field}

\subsubsection{Evolutionary structural optimization}

\subsubsection{Commercial software}
``There are several commercial topology optimization software on the market. Most of them use topology optimization as a hint how the optimal design should look like, \& manual geometry re-construction is required. There are a few solutions which produce optimal designs ready for Additive Manufacturing.'' -- -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Commercial_software}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}commercial software}

\subsection{Examples}

\subsubsection{Structural compliance}
\textsf{Fig. Checker Board Patterns are shown in this result.} \textsf{Fig. Topology optimization result when filtering is used.} \textsf{Fig. Topology optimization of a compliance problem.}

``A stiff structure is one that has the least possible displacement when given certain set of boundary conditions. A global measure of the displacements is the \href{https://en.wikipedia.org/wiki/Strain_energy}{strain energy} (also called \href{https://en.wikipedia.org/wiki/Stiffness#Compliance}{compliance}) of the structure under the prescribed boundary conditions. The lower the strain energy the higher the stiffness of the structure. So, the objective function of the problem is to minimize the strain energy.

On a broad level, one can visualize that the more the material, the less the deflection\footnote{\textbf{deflection} [n] [uncountable, countable, usually singular] \textbf{deflection (of something)} a sudden change in the direction that something is moving in, usually after it has hit something; the act of causing something to change direction.} as there will be more material to resit the loads. So, the optimization requires an opposing constraint, the volume constraint. This is in reality a cost factor, as we would not want to spend a lot of money on the material. To obtain the total material utilized, an integration of the selection field over the volume can be done.

Finally the elasticity governing differential equations are plugged in so as to get the final problem statement.
\begin{align*}
	\min_\rho \int_\Omega \frac{1}{2}\boldsymbol{\sigma}:\boldsymbol{\varepsilon}\,{\rm d}\Omega\mbox{ subject to }\rho\in[0,1],\ \int_\Omega \rho\,{\rm d}\Omega\le V^\star,\ \nabla\cdot\boldsymbol{\sigma} + {\bf F} = {\bf 0},\ \boldsymbol{\sigma} = {\bf C}:\boldsymbol{\varepsilon}.
\end{align*}
But, a straightforward implementation in the finite element framework of such a problem is still infeasible\footnote{\textbf{unfeasible} [a] not possible to do or achieve, \textsc{opposite}: \textbf{feasible}.} owning to issues such as:
\begin{itemize}
	\item \textbf{Mesh dependency} i.e., the design obtained on 1 mesh is not the one that will be obtained on another mesh. The features of the design become more intricate\footnote{\textbf{intricate} [a] having a lot of different parts \& small details that fit together.} as the mesh gets refined.
	\item \textbf{Numerical instabilities.} The selection of region in the form of a chess board. 
\end{itemize}
Some techniques such as \href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{filtering} based on image processing are currently being used to alleviate\footnote{\textbf{alleviate} [v] \textbf{alleviate something} to make suffering or a problem less severe.} some of these issues. Although it seemed like this was purely a heuristic approach for a long time, theoretical connections to nonlocal elasticity have been made to support the physical sense of these methods.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Structural_compliance}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}structural compliance}

\subsubsection{Multiphysics problems}

\paragraph{Fluid-structure-interaction.} ``\href{https://en.wikipedia.org/wiki/Fluid%E2%80%93structure_interaction}{Fluid-structure-interaction} is a strongly coupled phenomenon \& concerns the interaction between a stationary or moving fluid \& an elastic structure. Many engineering applications \& natural phenomenon are subject to fluid-structure interaction \& to take such effects into consideration is therefore critical in the design of many engineering applications. Topology optimization for fluid structure interaction problems has been studied. Design solutions solved for different Reynolds numbers are shown below. The design solutions depend on the fluid flow with indicate that the coupling between the fluid \& the structure is resolved in the design problems.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Fluid-structure-interaction}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}multiphysics problems\texttt{/}fluid-structure-interaction}

\textsf{Fig. Design solutions for different Reynolds number for a wall inserted in a channel with a moving fluid.} \textsf{Fig. Sketch fo the well-known wall problem. The objective of the design problem is to minimize the structural compliance.} \textsf{Fig. Design evolution for a fluid-structure-interaction problem. The objective of the design problem is to minimize the structural compliance. The fluid-structure-interaction problem is modeled with Navier--Cauchy \& NSEs.}

\paragraph{Thermoelectric energy conversion.} ``\href{https://en.wikipedia.org/wiki/Thermoelectric_effect}{Thermoelectricity} is a multi-physic problem which concerns the interaction \& coupling between electric \& thermal energy in semi conducting materials. Thermoelectric energy conversion can be described by 2 separately identified effects: The Seebeck effect \& the Peltier effect. The Seebeck effect concerns the conversion of thermal energy into electric energy \& the Peltier effect concerns the conversion of electric energy into thermal energy. By spatially distributing 2 thermoelectric materials in a 2D design space with a topology optimization methodology, it is possible to exceed performance of the constitutive thermoelectric materials for \href{https://en.wikipedia.org/wiki/Thermoelectric_cooling}{thermoelectric coolers} \& \href{https://en.wikipedia.org/wiki/Thermoelectric_generator}{thermoelectric generators}.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Thermoelectric_energy_conversion}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}multiphysics problems\texttt{/}thermoelectric energy conversion}

\subsubsection{3F3D Form Follows Force 3D Printing}
``The current proliferation\footnote{\textbf{proliferation} [n] \textbf{1.} [uncountable, singular] \textbf{proliferation (of something)} a rapid increase in the number or amount of something; a large number of a particular thing; \textbf{2.} [uncountable] (\textit{biology}) the rapid reproduction of a cell, part or organism.} of 3D printer technology has allowed designers \& engineers to use topology optimization techniques when designing new products. Topology optimization combined with 3D printing can result in less weight, improved structural performance \& shortened design-to-manufacturing cycle. As the designs, while efficient, might not be realizable with more traditional manufacturing techniques.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#3F3D_Form_Follows_Force_3D_Printing}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}3F3D Form Follows Force 3D Printing}

\subsubsection{Design-dependent loads}
``The direction, magnitude, \& location of a design-dependent load alter with topology optimization iterations. Therefore, dealing with such loads in a TO setting is a challenging task. One can find novel methods to deal with such loads (e.g. pressure load, self-weight, etc.).'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Design-dependent_loads}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}design-dependent loads}

\textsf{Fig. A sketch of the design problem. The aim of the design problem is to spatially distribute 2 materials, Material A \& Material B, to maximize a performance measure such as cooling power or electric power output.} \textsf{Fig. Design evolution for an off-diagonal thermoelectric generator. The design solution of an optimization problem solved for electric power output. The performance of the device has been optimized by distributing \href{https://en.wikipedia.org/wiki/Skutterudite}{Skutterudite} (yellow) \& \href{https://en.wikipedia.org/wiki/Bismuth_telluride}{bismuth telluride} (blue) with a density-based topology optimization methodology. The aim of the optimization problem is to maximize the electric power output of the thermoelectric generator.} \textsf{Fig. Design evolution for a thermoelectric cooler. The aim of the design problem is to maximize the cooling power of the thermoelectric cooler.}

%------------------------------------------------------------------------------%

\chapter{\href{formsolver.com}{Formsolver.com}}

%------------------------------------------------------------------------------%

\chapter{Optimal Control}

\section{Introduction}
``The mathematical optimization of process governed by PDEs has seen considerable progress in the past decade. Ever faster computational facilities \& newly developed numerical techniques have opened the door to important practical applications in fields e.g. fluid flow, microelectronics\footnote{\textbf{microelectronics} [n] [uncountable] the design, production \& use of very small electronic circuits.}, crystal\footnote{\textbf{crystal} [n] \textbf{1.} [countable] a small piece of a substance with many even sides, that is formed naturally when the substance becomes solid; in chemistry, a \textbf{crystal} is any solid that has its atoms, ions or molecules arranged in an ordered, symmetrical way; \textbf{2.} [uncountable] a clear mineral, e.g. quartz, used in making decorative objects.} growth, vascular\footnote{\textbf{vascular} [a] [usually before noun] (\textit{medical}) connected with or containing veins.} surgery\footnote{\textbf{surgery} [n] \textbf{1.} [uncountable, countable] medical treatment of injuries or diseases that involves cutting open a person's body, sewing up wounds, etc.; \textbf{2.} [countable] (\textit{British English}) a place where a doctor sees patients; \textbf{3.} [countable] (\textit{British English}) a time during which a doctor, an MP or another professional person is available to see people.}, \& cardiac\footnote{\textbf{cardiac} [a] [only before noun] (\textit{medical}) connected with the heart or heart disease; if somebody has a \textbf{cardiac arrest}, their heart suddenly stops temporarily or permanently.} medicine, to name just a few. As a consequence, the communities of numerical analysts \& optimizers have taken a growing interest in applying their methods to optimal control problems involving PDEs $\ldots$'' [$\ldots$] ``$\ldots$ the comprehensive text by J.-L. Lions \cite{Lions1971} covers much of the theory of linear equations \& convex cost functionals.'' -- \cite[Preface to the German edition, p. xiii]{Troltzsch2010}

\cite{Troltzsch2010} focuses on basic concepts \& notions e.g.:
\begin{itemize}
	\item Existence theory for linear \& semilinear PDEs
	\item Existence of optimal controls
	\item Necessary optimality conditions \& adjoint equations
	\item 2nd-order sufficient optimality conditions
	\item Foundation of numerical methods
\end{itemize}

\begin{question}
	What is optimal control?
\end{question}
``The mathematical theory of optimal control has in the past few decades rapidly developed into an important \& separate field of applied mathematics. 1 area of application of this theory lies in aviation\footnote{\textbf{aviation} [n] [uncountable] the activity of designing, building \& flying aircraft.} \& space technology: aspects of optimization come into play whenever the motion of an aircraft or a space vessel\footnote{\textbf{vessel} [n] \textbf{1.} a tube that carries blood through the body of a person or an animal, or liquid through the parts of a plant; \textbf{2.} (\textit{formal}) a large ship or boat; \textbf{3.} (\textit{formal}) a container used for holding liquids, e.g. a bowl or cup.} (which can be modeled by ODEs) has to follow a trajectory\footnote{\textbf{trajectory} [n] (plural \textbf{trajectories}) (\textit{specialist}) \textbf{1.} the curved part of something that has been fired, hit or thrown into the air; \textbf{2.} the way in which a person, an event or a process develops over a period of time, often leading to a particular result.} that is ``optimal'' in a sense to be specified.'' -- \cite[Sect. 1.1: \textit{What is optimal control?}, p. 1]{Troltzsch2010}

All the essential features of an \textit{optimal control problem}:
\begin{itemize}
	\item a \textit{cost functional} to be minimized,
	\item an IVP for an ODE in order to determine the \textit{state} $y$,
	\item a \textit{control function} $u$, \&
	\item various constraints that have to be obeyed.
\end{itemize}
``The control $u$ may be freely chosen within the given constraints, while the state is uniquely determined by the differential equation \& the initial conditions. We have to choose $u$ in such a way that the cost function is minimized. Such controls are called \textit{optimal}.'' [$\ldots$] ``The optimal control of ODEs is of interest not only for aviation \& space technology. In fact, it is also important in fields e.g. robotics\footnote{\textbf{robotics} [n] [uncountable] the science of designing \& operating robots.}, movement sequences in sports, \& the control of chemical processes \& power plants, to name just a few of the various applications. In many cases, however, the processes to be optimized can no longer be adequately modeled by ODEs; instead, PDEs have to be employed for their description. E.g., heat conduction\footnote{\textbf{conduction} [n] [uncountable] (\textit{physics}) the process by which heat or electricity passes along or through a material.}, diffusion\footnote{\textbf{diffusion} [n] [uncountable] \textbf{1.} the spreading of something more widely; \textbf{2.} the mixing of substances by the natural movement of their particles; \textbf{3.} the spreading of elements of culture from 1 region or group to another.}, electromagnetic\footnote{\textbf{electromagnetic} [a] (\textit{physics}) in which the electrical \& magnetic properties of something are related.} waves, fluid flows, freezing processes, \& many other physical phenomenon\footnote{\textbf{phenomenon} [n] (plural \textbf{phenomena} a fact or an event in nature or society, especially one that is not fully understood.)} can be modeled by PDEs.

In these fields, there are numerous interesting problems in which a given cost functional has to be minimized subject to a differential equation \& certain constraints being satisfied. The difference from the above problem ``merely'' consists of the fact that a PDE has to be dealt with in place of an ordinary one.'' -- \cite[pp. 2--3]{Troltzsch2010}

\cite{Troltzsch2010} discusses, ``through examples in the form of mathematically simplified case studies, the optimal control of heating processes, 2-phase problems, \& fluid flows''. \cite{Troltzsch2010} focuses ``on linear \& semilinear elliptic \& parabolic PDEs, since a satisfactory regularity theory is available for the solutions to such equations. This is not the case for hyperbolic equations. Also, the treatment of quasilinear PDEs is considerably more difficult, \& the theory of their optimal control is still an open field in many respects.'' [$\ldots$] ``$\ldots$ the Hilbert space setting suffices as a functional analytic framework in the case of linear-quadratic theory.'' -- \cite[p. 3]{Troltzsch2010}

\subsection{Examples of Convex Problems}

\subsubsection{Optimal boundary heating}
See \cite[Subsect. 1.2.1, pp. 3--5]{Troltzsch2010}.

\begin{example}[Optimal boundary heating]
	Consider a body heated or cooled which occupies the spatial domain $\Omega\subset\mathbb{R}^3$. Apply to its boundary $\Gamma$ a \emph{heat source} $u$ (the \emph{control}), which is constant in time but depends on the location ${\bf x}$ on the boundary, i.e., $u = u({\bf x})$. Aim: choose the control in such a way that the corresponding \emph{temperature distribution} $y = y({\bf x})$ in $\Omega$ (the \emph{state}) is the best possible approximation to a desired stationary temperature distribution $y_\Omega = y_\Omega({\bf x})$:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Gamma |u({\bf x})|^2\,{\rm d}s({\bf x}),
	\end{align*}
	subject to the \emph{state equation}:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and the \emph{pointwise control constraints} $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ on $\Gamma$. ``Such pointwise bounds for the control are quite natural, since the available capacities for heating or cooling are usually restricted. The constant $\lambda\ge 0$ can be viewed as a measure of the energy costs needed to implement the control $u$. From the mathematical viewpoint, this term also serves as a \emph{regularization parameter}; it has the effect that possible optimal controls show improved regularity properties.'' [$\ldots$] ``The function $\alpha$ represents the \emph{heat transmission coefficient} from $\Omega$ to the surrounding medium. The functional $J$ to be minimized is called the \emph{cost functional}. The factor $\frac{1}{2}$ appearing in it has no influence on the solution of the problem. It is introduced just for the sake of convenience: it will later cancel out a factor 2 arising from differentiation. We seek an optimal control $u = u({\bf x})$ together with the associated state $y = y({\bf x})$. The minus sign in front of the Laplacian $\Delta$ appears to be unmotivated at 1st glance. It is introduced because $\Delta$ is not a \emph{coercive operator}, while $-\Delta$ is.'' -- \cite[p. 4]{Troltzsch2010}
\end{example}
``Observe that in the above problem the cost functional is quadratic, the state is governed by a linear elliptic PDE, \& the control acts on the boundary of the domain.'': thus have a \textit{linear-quadratic elliptic boundary control problem}.

\begin{remark}[Notations used in \cite{Troltzsch2010}]
	Denote the element of surface area by $ds$ \& the outward unit normal to $\Gamma$ at ${\bf x}\in\Gamma$ by $\nu({\bf x})$\footnote{NQBH: I prefer to use ${\bf n}({\bf x})$, with ``n'' stands for ``normal'', naturally \& obviously.}.
\end{remark}

\begin{remark}
	``The problem is strongly simplified. Indeed, in a realistic model Laplace's equation $\Delta y = 0$ has to be replaced by the stationary heat conduction equation $\nabla\cdot(a\nabla y) = 0$, where the coefficient $a$ can depend on ${\bf x}$ or even on $y$. If $a = a(y)$ or $a = a({\b f x},y)$, then the PDE is quasilinear. In addition, it will in many cases be more natural to describe the process by a time-dependent PDE.'' -- \cite[p. 4]{Troltzsch2010}
\end{remark}

\begin{example}[Optimal heat source]
	Similarly, the control can act as a \emph{heat source in the domain} $\Omega$. Problems of this kind arise if the body $\Omega$ is heated by electromagnetic induction or by microwaves. Assuming at 1st that the boundary temperature vanishes, we obtain the following problem:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Omega |u({\bf x})|^2\,{\rm d}{\bf x},
	\end{align*}
	subject to
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			y &= 0,&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ in $\Omega$. Here, the coefficient $\beta = \beta({\bf x})$ is prescribed. Observe that by the special choice $\beta = \chi_{\Omega_{\rm c}}$ (where $\chi_E$ denotes the characteristic function of a set $E$), it can be achieved that $u$ acts only in a subdomain $\Omega_{\rm c}\subset\Omega$. This problem is a \emph{linear-quadratic elliptic control problem with distributed control}. It can be more realistic to prescribe an exterior temperature $y_a$ rather than assume that the boundary temperature vanishes. Then a better model is given by the state equation
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(y_a - y),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
\end{example}

\subsubsection{Optimal nonstationary boundary control}
See \cite[pp. 5--6]{Troltzsch2010}. ``Let $\Omega\subset\mathbb{R}^3$ represent a potato that is to be roasted over a fire for some period of time $T > 0$.'' Denote its temperature by $y = y(t,{\bf x})$, with $(t,x)\in[0,T]\times\Omega$. ``Initially, the potato has temperature $y_0 = y_0({\bf x})$, \& we want to serve it at a pleasant palatable\footnote{\textbf{palatable} [a] \textbf{1.} (of food or drink) having a pleasant or acceptable taste; \textbf{2.} \textbf{palatable (to somebody)} pleasant or acceptable to somebody, \textsc{opposite}: \textbf{unpalatable}.} temperature $y_\Omega$ at the final time $T$.'' Write $Q\coloneqq(0,T)\times\Omega$, $\Sigma\coloneqq(0,T)\times\Gamma$. Then problem reads as follows:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y(T,{\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_0^T\int_\Gamma |u(t,{\bf x})|^2\,{\rm d}\Gamma\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_t - \Delta y &= 0,&&\mbox{ in } Q,\\
		\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Sigma,\\
		y(0,{\bf x}) &= y_0({\bf x}),&&\mbox{ in }\Omega,
	\end{split}\right.
\end{equation*}
\& $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ on $\Sigma$. By continued turning of the spit\footnote{\textbf{spit} [n] \textit{in}\texttt{/}\textit{from mouth} \textbf{1.} [uncountable] the liquid produced in your mouth, \textsc{synonym}: \textbf{saliva}; \textbf{2.} [countable, usually singular] the act of spitting liquid or food out of your mouth; \textit{piece of land} \textbf{3.} [countable] a long, thin piece of land that sticks out into the sea, a lake, etc.; \textit{for cooking meat} \textbf{4.} [countable] a long, thin, straight piece of metal that you put through meat to hold \& turn it while you cook it over a fire.}, we produce $u(t,{\bf x})$. The heating process has to be described by the \textit{nonstationary heat equation}, which is a parabolic differential equation: thus have to deal with a \textit{linear-quadratic parabolic boundary control problem}.

\subsubsection{Optimal vibrations}
``Suppose that a group of pedestrians crosses a bridge, trying to excite\footnote{\textbf{excite} [v] \textbf{1.} to make somebody feel a particular emotion or react in a particular way, \textsc{synonym}: \textbf{arouse}; \textbf{2.} \textbf{excite somebody} to make somebody feel very pleased, interested or enthusiastic, especially about something that is going to happen; \textbf{3.} \textbf{excite somebody\texttt{/}something} to make somebody\texttt{/}something nervous, upset or active \& unable to relax; \textbf{4.} \textbf{excite something} to produce a state of increased energy or activity in a physical or biological system, \textsc{synonym}: \textbf{stimulate}; \textbf{5.} \textbf{excite something} (\textit{physics}) to bring something to a state of higher energy.} oscillations\footnote{\textbf{oscillation} [n] \textbf{1.} [countable, uncountable] \textbf{oscillation (of something)} a regular movement between 1 position \& another; \textbf{2.} [countable] \textbf{oscillation (between A \& B)} a repeated change between different states, ideas, etc.; \textbf{3.} [countable] (\textit{specialist} regular variation in size, strength or position around a central point or value, especially of an electrical current or electric field.)} in it. This can be modeled (strongly abstracted) as follows: let $\Omega\subset\mathbb{R}^2$ denote the domain of the bridge, $y = y(t,{\bf x})$ its \textit{transversal\footnote{\textbf{transversal} [n] a line that intersects a system of lines.} displacement\footnote{\textbf{displacement} [n] \textbf{1.} [uncountable] the act of displacing somebody\texttt{/}something; the process of being displaced; \textbf{2.} [uncountable, singular] \textbf{displacement (of something)} (\textit{physics}) the distance between the final \& initial ($=$ 1st) positions of an object which has moved.}}, $u = u(t,{\bf x})$ the \textit{force density} acting in the vertical direction, \& $y_{\rm d} = y_{\rm d}(t,{\bf x})$ a \textit{desired evolution of the transversal vibrations\footnote{\textbf{vibration} [n] [countable, uncountable] \textbf{1.} \textbf{vibration (of something)} a continuous shaking movement; \textbf{2.} \textbf{vibration (of something)} (\textit{physics}) oscillation in a substance about its equilibrium state.}}. We then obtain the optimal control problem:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_0^T\int_\Omega |y(t,{\bf x}) - y_{\rm d}(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t + \frac{\lambda}{2}\int_0^T\int_\Omega |u(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_{tt} - \Delta y &= u,&&\mbox{ in } Q,\\
		y(0) &= y_0,&&\mbox{ in }\Omega,\\
		y_t(0) &= y_1,&&\mbox{ in }\Omega,\\
		y &= 0,&&\mbox{ on }\Sigma,
	\end{split}\right.
\end{equation*}
and $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ in $Q$. This is a \textit{linear-quadratic hyperbolic control problem with distributed control}.'' [$\ldots$] ``Interesting control problems for oscillating elastic networks have been treated by Lagnese et al. \textbf{[LLS94]}. An elementary introduction to the controllability of oscillations can be found in \textbf{[Kra95]}.

In the linear-quadratic case, the theory of hyperbolic problems has many similarities to the parabolic theory studied in \cite{Troltzsch2010}. However, the treatment of semilinear hyperbolic problems is much more difficult, since the smoothing properties of the associated solution operators are weaker. As a consequence, many of the techniques presented in \cite{Troltzsch2010} fail in the hyperbolic case.'' -- \cite[pp. 6--7]{Troltzsch2010}

\subsection{Examples of Nonconvex Problems}
``However, linear models do not suffice for many real-world phenomena. Instead, one often needs quasilinear or, much simpler, semilinear equations. Recall that a 2nd-order equation is called \textit{semilinear} if the main parts (i.e., the expressions involving highest-order derivatives) of the differential operators considered in the domain \& on the boundary are linear w.r.t. the desired solution. For such equations, the theory of optimal control is well developed.

\fbox{Optimal control problems with semilinear state equations are, as a rule, nonconvex, even if the cost functional is convex.} ``Associated optimal control problems can be obtained by prescribing a cost functional \& suitable constraints.'' -- \cite[p. 7]{Troltzsch2010}

\subsubsection{Problems involving semilinear elliptic equations}

\begin{example}[Heating with radiation boundary condition]
	If the heat radiation of the heated body is taken into account, then we obtain a problem with a nonlinear Stefan--Boltzmann boundary condition. If this case, the control $u$ is given by the temperature of the surrounding medium:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u^4 - y^4),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
	The nonlinearity $y^4$ occurs in the boundary condition, while the heat conduction equation itself is linear.
\end{example}

\begin{example}[Simplified superconductivity]
	
\end{example}

\begin{example}[Control of stationary flows]
	
\end{example}

\subsubsection{Problems involving semilinear parabolic equations}

\section*{Quick notes}
\textit{Primal-dual active set strategies}, whose the exposition now leads to the systems of linear equations to be solved.

%------------------------------------------------------------------------------%

\chapter{Shape Optimization}

\section{Introduction}
``Shape Optimization was introduced around 1970 by Jean C\'ea \cite{Cea_Gioan_Michel1973}, who understood, after several engineering studies [127, 12, 35, 110, 102, 83, 84, 7],\footnote{(see refs. in \cite{Moubachir_Zolesio2006})}, the future issues in the context of optimization problems. At that time, he proposed a list of open problems at the French National Colloquium in Numerical Analysis. These new problems were formulated in terms of minimization of functionals (referred as \textit{open loop control} or \textit{passive control}) governed by partial differential BVPs where the control variable was the geometry of a given boundary part [103, 76]. From the beginning, the terminology \textit{shape optimization} was not connected to the structural mechanical sciences in which elasticity \& optimization of the compliance played a central role. Furthermore, these research studies were mainly addressed in the context of the numerical analysis of the FEMs.

At the same time, there was some independent close results concerning fluid mechanics by young researchers e.g. O. Pironneau [123, 124, 78], Ph. Morice [107] \& also several approaches related to perturbation theory by P.R. Garabedian [74, 75] \& D.D Joseph [91, 92].

Very soon, it appeared that the shape control of BVPs was at the crossroads of several disciplines such as PDE analysis, non-autonomous semi-group theory, numerical approximation (including FEMs), control \& optimization theory, geometry \& even physics. Indeed several classical modeling in both structural \& fluid mechanics (among other fields) needed to be extended. An illustrative example concerns a very \textit{popular} problem in the 80's concerning the thickness optimization of a plate modeled by the classical Kirchoff biharmonic equation. This kind of solid model is based on the assumption that the thickness undergoes only small variations. Therefore, many pioneering works were violating the validity of this assumption, leading to strange results, e.g., the work presented in the Iowa NATO Study [85] stating the existence of optimal beams having \textit{zero cross section} values.

In the \textit{branch} which followed the passive control approach, we shall mention the work of G. Chavent [32, 34] based on the theory of distributed system control introduced by J.-L. Lions \cite{Lions1971}. Those results did not address optimization problems related to the domain but instead related to the coefficients inside the PDE. At that time, it was hoped that the solution of elliptic problems would be continuous w.r.t. the weak convergence of the coefficients. It appeared that this property was not achieved by this class of problem\footnote{Indeed, in his thesis [33], G. Chavent referred to such a result to appear in a work by F. Murat [113]. That paper [111] appeared but as a counterexample to the expected continuity property. He showed on a 1D simple example that with weak \textit{oscillating} convergence of the coefficients, the associated solution was converging to another problem in which the new coefficients were related to the limit of the \textit{inverse} coefficients associated to the original problem [112, 114].} At that point a main \textit{bifurcation} arose with the homogenization approach [10] which up to some point was considered as a part of the \textit{Optimal Design} theory.

The mathematical analysis of shape optimization problems began with the correct definition of derivatives of functionals \& functions w.r.t. the domain, together with the choice of tangential space to the family of shapes. Following the very powerful theory developed by J. Ne\v{c}as [117], the role of bilipschitzian mapping was emphasized for Sobolev spaces defined in moving domains based on the Identity perturbation method [115, 106, 134]. Concerning the large domain deformation viewpoint the previous approach led to the incremental domain evolution methods [143].

After 1975, the 2nd author introduced [145] an asymptotic analysis for domain evolution using classical geometrical flows which are intrinsic tools for manifolds evolutions \& gave existence results for the so-called \textit{shape differential equation} (see also [79]). At that period, applications focused more on sensitivity analysis problems than on asymptotic analysis of domains evolution. In 1972, A.M. Micheletti introduced in parallel [105, 104] a metric based on the Identity perturbation method thanks to the use of differentiable mappings, in order to study eigenvalues perturbation problems. The associated topology was extended by M. Delfour et. al [52] \& turns out to be the same as the one induced by the continuity along flow field deformations [147].

The systematic use of flow mapping \& intrinsic geometry through the fundamental role of the oriented distance function [47, 50] led to the revised analysis of the elastic shell theory [48, 49, 25, 26, 27, 28], of the boundary layer theory [3] or of the manifold derivation tools [53].

The use of both Bounded Variation (BV) analysis \& the notion of Cacciapoli sets led to the 1st compactness method for domain sequences \& several extensions to more regular boundaries were done through the use of different concepts such as \textit{fractal boundaries, density parameter} [23, 20, 21, 19] or \textit{Sobolev domains} [50].

At that point, an other important \textit{bifurcation point} in that theory occurred with the relaxation theory \& the Special Bounded Variation (SBV) analysis which was particularly well adapted for image segmentation problem [6]. At the opposite, the capacity constraint for Dirichlet boundary conditions led to a fine analysis initiated in [18] \& is still going on for cracks analysis.

The method of large evolution based on the flow mapping (known from 1980 as the \textit{speed method} [150]) turns to be the natural setting for weak evolution of geometry allowing topological changes through the convection of either characteristic functions or oriented distance functions.'' -- \cite[Chap. 1, pp. 1--3]{Moubachir_Zolesio2006}

\subsection{Classical \& moving shape analysis}
``The classical shape analysis investigates the effects of perturbations of the geometry in terms of continuity, differentiability \& optimization of quantities related to the state of a system defined in that geometry. In this case, the geometry is usually perturbed thanks to a map involving a scalar parameter usually referred to as a fictitious time. On the contrary, the moving shape analysis deals with systems that are intrinsically defined on a moving geometry. Hence, we shall deal with sensitivity analysis w.r.t. a continuous famil of shapes over a given time period. In this context, if we consider the geometry in a space-time configuration, the moving shape analysis may also be referred to as a \textit{non-cylindrical shape analysis}\footnote{The notion of tube (non-cylindrical evolution domains) was also independently introduced by J.P. Aubin via the concept of \textit{abstract mutations} [8].}.

A 1st issue in this analysis is to model the evolution of the geometry. This is a common topic with the classical shape analysis. There exists many ways to build families of geometries. E.g., a domain can be made variable by considering its image by a family of diffeomorphisms parametrized by the time parameter as it happens frequently in mechanics for the evolution of continuous media. This way of defining the motion of domains avoids a priori the modification of the underlying topology. This change of topology can be allowed by using the characteristic function of families of sets or the level set of a space-time scalar function.'' Refer to \cite{Delfour_Zolesio2001, Delfour_Zolesio2011} for a complete review on this topic. ``In Chap. 2, we shall deal with the particular problem of defining in a weak manner the convection of a characteristic function in the context of the \textit{speed method} developed in Zol\'esio's PhD thesis [147].

In numbers of applications, we shall consider a state variable associated to a system which is a solution of a PDE defined inside the moving domain over a given time period. Hence, we need to analyze the solvability of this non-cylindrical PDE system before going further. Here, again this topic has been already studied since it enters the classical shape analysis problem while introducing a perturbed state defined in the moving domain parametrized by the fictitious time parameter. Furthermore, this solvability analysis has been performed in numbers of mathematical problems involving moving domains.'' Refer to [135, 51] for some particular results in the context of the classical shape analysis. Also refer to the extensive literature concerning the analysis of PDE systems defined in moving domains, e.g., [96, 126, 132, 62, 130, 88, 128, 70, 100, 11].

``Contrary to the last topic, very few references exist for the sensitivity analysis w.r.t. the perturbation of the evolution of the moving geometry. Early studies have been conducted in [90, 151, 158, 141, 120, 43, 142, 2] for specific hyperbolic \& parabolic linear problems. An important step was performed in [154, 155] where Zol\'esio established the derivative of integrals over a moving domain w.r.t. its associated Eulerian velocity. These results were applied in order to study variational principles for an elastic solid under large displacements \& the incompressible Euler equation. This work was generalized in [58, 59].'' -- \cite[Chap. 1, Sect. 1.1, pp. 3--4]{Moubachir_Zolesio2006}

\subsection{Fluid-Structure Interaction Problems}
``A general fluid--solid model consists of an elastic solid either surrounded by a fluid (aircrafts, automobiles, bridge decks, $\ldots$) or surrounding a fluid flow (pipelines, arteries, reservoir tanks, $\ldots$). Here the motion of the interface between the fluid \& the solid is part of the unknown of the coupled system. It is a free boundary problem that can be solved by imposing continuity properties through the moving interface (e.g., the kinematic continuity of the velocities \& the kinetic continuity of the normal stresses). This model has been intensively studied in the last 2 decades on the level of its mathematical solvability [87, 54, 82, 39, 80, 131, 15, 9, 138, 41], its numerical approximation [89, 55, 119, 118, 122, 95, 67], its stability [73, 38, 64, 65] \& more recently on its controllability [66, 109]. In this lecture note, we will restrict ourselves to viscous Newtonian incompressible fluid flows described by the NSEs in space dimension 2 or 3. The case of a compressible Newtonian fluid can be incorporated in the present framework with the price of a heavier mathematical analysis (solvability, non-differentiability around shocks $\ldots$).''

\textbf{Goal.} ``To solve inverse or control problems based on the previous general fluid-solid model. As an example, we think to decrease the drag of a car inside the atmospheric air flow by producing specific vibrations on its body using smart materials such as piezoelectrical layers. In this example, the control variable can be chosen as the electrical energy input evolution inside the piezoelectrical device \& the objective is to decrease the drag which is a function of the coupled fluid-structure state (the air \& the body of the car) \& this state depends on the control variable. In order to build a control law for the electrical input, we need to characterize the relationship between the drag function \& the control variable on the level of its computation \& its variations.

As an other example, we can think of the problem of aeroelastic stability of structures. Both authors have been dealing with such a problem in the context of the stability analysis against wind loads of bridge decks. In [108], it has been suggested that such a problem can be set as the inverse problem consisting in recovering the smallest upstream wind speed that leads to the worst bridge deck vibrations. In this example, the decision variable can be chosen as the upstream wind speed \& the objective is to increase a functional based on the vibration amplitude history of the bridge deck during a given characteristic time period which is a function of the coupled fluid-structure state (the wind flow \& the bridge deck) which is also a function of the decision variable. Again, in order to recover the wind speed history, we need to characterize the relationship between the objective functional \& the decision variable on the level of its computation \& its variations.

In order to characterize the sensitivity of the objective functional w.r.t. the control variable, it is obvious that we need to characterize the sensitivity of the coupled fluid-structure state w.r.t. the control variable. Here we recall that the coupled fluid-structure state is the solution of a system of PDEs that are coupled through continuity relations defined on the moving interface (the fluid-structure interface). The key point towards this sensitivity analysis is to investigate the sensitivity of the fluid state, which is an Eulerian quantity, w.r.t. the motion of the solid, which is a Lagrangian quantity. This task falls inside the moving shape analysis framework described earlier. Indeed the fluid state is the solution of system of nonlinear PDEs defined in a moving domain. The boundary of this moving domain is the solid wall. Then using the tools developed in [59], it has been possible to perform in [58] the moving shape sensitivity analysis in the case of a Newtonian incompressible fluid inside a moving domain driven by the non-cylindrical NSEs.

All the previous results use a parametrization of the moving domain based on the Lagrangian flow o a given velocity field. Hence, the design variable is the Eulerian velocity of the moving domain, allowing topology changes while using the associated level set formulation. In [13, 14], the author used a non-cylindrical identity perturbation technique. It consists in perturbating the space-time identity operator by a family of diffeomorphism. Then, this family is chosen as the design parameter. It is a Lagrangian description of the moving geometry, which a priori does not allow topology changes but which leads to simpler sensitivity analysis results which are are still comparable with the one obtained by the non-cylindrical \textit{speed method}. In [57], the authors came back to the dynamical shape control of the Navier-Stokes \& recovered the results obtained in [58] using the Min-Max principle allowing to avoid the state differentiation step w.r.t. the velocity of the domain.

Now, we come back to the original problem consisting in the sensitivity analysis of the coupled fluid-structure state w.r.t. the control variable. Using the chain rule, the derivative of the coupled state w.r.t. the control variable involves the partial derivative of the fluid state w.r.t. the motion of the fluid-structure interface already characterized in [58, 57]. Hence, again using a Lagrangian penalization technique, already used \& justified in [45, 46], it has been possible to perform in [109] the sensitivity analysis of a simple fluid-structure interaction problem involving a rigid solid within an incompressible flow of a Newtonian fluid w.r.t. the upstream velocity field. As already mentioned, this simple model is particularly suited for bridge deck aeroelastic stability analysis [121].'' -- \cite[Chap. 1, Sect. 1.2, pp. 4--6]{Moubachir_Zolesio2006}
\begin{itemize}
	\item ``\cite[Chap. 2]{Moubachir_Zolesio2006} furnishes a simple illustration to some of the moving shape analysis results reported in the core of the lecture note. We deal with a simple inverse problem arising in phase change problems consisting in recovering the moving interface at the isothermal interface between a solid \& liquid phase from measurements of the temperature on a insultated fixed part of the solid boundary. We use a least-square approach \& we show how to compute the gradient of the least-square functional w.r.t. the velocity of the moving interface. It involves an adjoint state problem together with an adjoint transverse state, which is the novelty of the moving shape analysis compared to the classical one.
	\item In \cite[Chap. 3]{Moubachir_Zolesio2006}, we consider the weak Eulerian evolution of domains through the convection, generated by a non-smooth vector field ${\bf V}$, of measurable sets. The introduction of transverse variations enables the derivation of functionals associated to evolution tubes. We also introduce Eulerian variational formulations for the minimal curve problem. These formulations involve a geometrical adjoint state $\lambda$ which is backward in time \& is obtained thanks to the use of the so-called \textit{transverse field} ${\bf Z}$.
	\item In \cite[Chap. 4]{Moubachir_Zolesio2006}, we recall the concept of shape differential equation developed in [145, 147]. Here, we present a simplified version \& some applications in 2D which enable us to reach the time asymptotic result. Furthermore, we introduce the associated level set formulation whose speed vector version was already contained in [149].
	\item In \cite[Chap. 5]{Moubachir_Zolesio2006}, we deal with a challenging problem in fluid mechanics which consists in the control of a Newtonian fluid flow thanks to the velocity evolution law of a moving wall. Here, the optimal control problem has to be understood as the open loop version, i.e., it consists in minimizing a given objective functional w.r.t. the velocity of the moving wall. This study is performed within the non-cylindrical Eulerian moving shape analysis described in Chaps. 2--3. We focus on the use of a Lagrangian penalization formulation in order to avoid the fluid state differentiation step.
	\item In \cite[Chap. 6]{Moubachir_Zolesio2006}, we introduce the Lagrangian moving shape analysis framework. It differs from the Eulerian one form the fact that the design variable is the diffeomorphism that parametrizes the moving geometry. The sensitivity analysis is simpler since it does not involve the transverse velocity field. We apply these tools in order to deal with the control of a Newtonian fluid flow thanks to the displacement evolution law of a moving wall.
	\item \cite[Chap. 7]{Moubachir_Zolesio2006} moves to inverse problems related to fluid-structure interaction systems. Here, we consider a 2D elastic solid with rigid displacements inside the incompressible flow of a viscous Newtonian fluid. We try to recover informations about the inflow velocity field from the partial measurements of the coupled fluid-structure state. We use a least-square approach together with a Lagrangian penalization technique. We derive the structure of the gradient w.r.t. the inflow velocity field of a given cost function. Using the Min-Max principle, the cost function gradient reduces to the derivative of the Lagrangian w.r.t. the inflow velocity at the saddle point. This saddle point is solution of 1st order optimality conditions. We use non-cylindrical Eulerian derivatives to compute the partial derivative of the Lagrangian functional w.r.t. the solid state variables, involved in the optimality system.
	\item In \cite[Chap. 8]{Moubachir_Zolesio2006} we extend the results of Chap. 7, to the case of an elastic solid under large displacements inside an incompressible fluid flow. The main difference with the previous case is the use of a non-cylindrical Lagrangian shape analysis for establishing the KKT system. It forms the adjoint counterpart of the sensitivity analysis conducted in [66].'' -- \cite[Chap. 1, Sect. 1.3, pp. 6--7]{Moubachir_Zolesio2006}
\end{itemize}
``$\ldots$ we shall describe the different steps encountered while designing a complex fluid-structure interaction system. Indeed, let us consider a mechanical system that consists of a solid \& a fluid interacting with each other. We would like to increase the performances of this system. These performances have to be quantitatively translated inside a cost function that we have to optimize w.r.t. some parameters that we will call the control variables. In the sequel, we will describe different control situations:
\begin{enumerate}
	\item \textit{Control of a fluid flow around a fixed body}: it consists in trying to modify the fluid flow pattern around a fixed body using a boundary control which can act e.g. by blowing or suctioning the fluid at some part of the solid boundary. The control law will be designed in order to match some efficiency goals using the minimization of a cost functional.
	\item \textit{Shape design of a fixed solid inside a fluid flow}: in this case, the control is the shape of the body. We would like to find the best shape satisfying some geometrical constraints that will optimize some cost functionals. This problem is somewhat classical in the aeronautical field, but it requires some subtle mathematical tools that we will quickly recall.
	\item \textit{Dynamical shape design of a solid inside a fluid flow}: the novelty compared to the last item is that the shape is moving \& we are looking for the best evolution of this shape that both satisfies some geometrical constraints \& optimizes some cost functionals. This is a rather natural technique in order to control a fluid flow pattern, but still its design requires some new mathematical tools that will be sketched in this introduction \& more detailed in the core of this lecture note.
	\item \textit{Control of an elastic solid inside a fluid flow}: this is the most complex \& most realistic situation where both the fluid \& the solid have their own dynamics which are coupled through the fluid-solid interface. Then, we would like to control or optimize the behavior of this coupled system thanks to boundary conditions. The mathematical analysis of this situation uses the whole framework introduced previously. This is a challenging problem, both on the mathematical point of view \& on the technological side. The goal of this book is to partially answer to some issues related to this problem.'' -- \cite[Chap. 1, Sect. 1.4, pp. 7--8]{Moubachir_Zolesio2006}
\end{enumerate}

\subsubsection{Control of a fluid flow around a fixed body}

\paragraph{The objective functional.} ``A common topic in the optimization \& control field of PDE systems is the choice of appropriate cost functionals, i.e., meeting both our objectives \& the mathematical requirements that guarantee the convergence to at least 1 optimum parameter. This functional can depend both on the state variables $({\bf u},p)$ \& on the control parameter ${\bf g}$.'' [$\ldots$] ``More generally, we can consider any cost functionals that are twice-differentiable w.r.t. their arguments.''-- \cite[Chap. 1, Subsect. 1.4.1, pp. 9--10]{Moubachir_Zolesio2006}

\paragraph{The control problem.} ``Our goal is now furnish the 1st-order optimality conditions associated to the optimization problem. These conditions are very useful since they are the basis in order to build both a rigorous mathematical analysis \& gradient-based optimization algorithms.

There exists 2 main methods in order to derive these conditions: the 1st one is based on the differentiability of the state variables w.r.t. the control parameter \& the 2nd one relies on the existence of Lagrangian multipliers.'' -- \cite[Chap. 1, Subsect. 1.4.1, p. 10]{Moubachir_Zolesio2006}

\paragraph{Sensitivity.} ``Let us consider a \textit{control point} ${\bf g}\in\mathcal{U}$, then the cost functional $j({\bf g})$ is Fr\'echet differentiable w.r.t. ${\bf g}$ \cite{Abergel_Temam1990}, [71] \& its directional derivative is given by \textbf{(1.9)}
\begin{align*}
	\langle j'({\bf g}),{\bf h}\rangle = \langle\partial_{({\bf u},p)}J[({\bf u},p)({\bf g})],({\bf u}',p')({\bf g};{\bf h})\rangle,\mbox{ where }({\bf u}',p')({\bf g};{\bf h})\coloneqq\frac{d}{d{\bf g}}({\bf u},p)({\bf g})\cdot{\bf h}
\end{align*}
stands for the directional derivative of $({\bf u},p)({\bf g})$ w.r.t. ${\bf g}$.'' [$\ldots$]

``Then the 1st-order optimality condition writes \textbf{(1.11)} $\langle j'({\bf g},{\bf h})\rangle = 0$, $\forall{\bf h}\in\mathcal{U}$. I.e., the set of optimal controls is contained in the set of critical points for the cost function $j({\bf g})$. However, we would like to obtain an expression of this condition avoiding the direction ${\bf h}\in\mathcal{U}$. To this end, we introduce the \textit{adjoint variable} $({\bf v},\pi)$ solution of the \textit{adjoint linearized Navier--Stokes system} \textbf{(1.12)}. Consequently, we are able to identify the gradient of the cost function as the trace on $\Gamma^c$ of the \textit{adjoint normal stress tensor}, i.e., \textbf{(1.13)}
\begin{align*}
	\nabla j({\bf g}) = {}^\star\gamma_{(0,\tau)\times\Gamma^c}[\sigma({\bf v},\pi)\cdot{\bf n}].
\end{align*}
This formal proof provides the basic steps needed in order to build a gradient-based optimization method associated to the control problem $\min_{{\bf g}\in\mathcal{U}} j({\bf g})$.

An alternative approach consists in avoiding the derivation of the fluid state $({\bf u},p)$ w.r.t. the control ${\bf g}$ thanks to the introduction of a Lagrangian functional that includes not only the cost functional but also the state equation, \textbf{(1.14)}
\begin{align*}
	\mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g}) = J(\boldsymbol{\psi},r) + \langle e(\boldsymbol{\psi},r;{\bf g}),(\boldsymbol{\phi},q)\rangle,
\end{align*}
where $\langle e({\bf u},p;g),(\boldsymbol{\phi},q)\rangle$ stands for the weak form of the state equation NSEs (1.8), e.g.,
\begin{align*}
	\langle e(\boldsymbol{\psi},r;{\bf g}),(\boldsymbol{\phi},q)\rangle =&\, \int_{(0,\tau)\times\Omega^f} [-\boldsymbol{\psi}\cdot\partial_t\boldsymbol{\phi} + ({\rm D}\boldsymbol{\psi}\cdot\boldsymbol{\psi})\cdot\boldsymbol{\phi} - \nu\boldsymbol{\psi}\cdot\Delta\boldsymbol{\phi} + \boldsymbol{\psi}\cdot\nabla q - r\nabla\cdot\boldsymbol{\phi}] + \int_{(0,\tau)\times\Gamma^c} {\bf g}\cdot(\sigma(\boldsymbol{\phi},q)\cdot{\bf n})\,{\rm d}\Gamma\,{\rm d}t\\
	&+ \int_{(0,\tau)\times\partial D} {\bf u}_\infty\cdot(\sigma(\boldsymbol{\phi},q)\cdot{\bf n}) + \int_{\Omega^f} \boldsymbol{\psi}(\tau)\cdot\boldsymbol{\phi}(\tau) - \int_{\Omega^f} {\bf u}_0\cdot\boldsymbol{\phi}(0).
\end{align*}
Hence the control problem $\min_{{\bf g}\in\mathcal{U}} j({\bf g})$ is equivalent to the $\min$-$\max$ problem, \textbf{(1.15)}
\begin{align*}
	\min_{{\bf g}\in\mathcal{U}}\min_{(\boldsymbol{\psi},r)}\max_{(\boldsymbol{\phi},q)} \mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g}).
\end{align*}
For every control ${\bf g}\in\mathcal{U}$, it can be proven that the $\min$-$\max$ problem,
\begin{align*}
	\min_{(\boldsymbol{\psi},r)}\max_{(\boldsymbol{\phi},q)} \mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g})
\end{align*}
admits a unique saddle-point $({\bf u},p;{\bf v},\pi)$ which are solutions of the systems (1.8)--(1.12). Finally the 1st-order optimality for the problem (1.15) writes \textbf{(1.16)}
\begin{align*}
	\partial_{\bf g}\mathcal{L}({\bf u},p,{\bf v},\pi;{\bf g}) = 0
\end{align*}
which turns out to be equivalent to (1.13). Then, we can think to solve the optimality condition (1.11), using a continuous iterative method. Indeed let us introduce a scalar parameter $s\ge 0$, \& a \textit{control variable} ${\bf g}(s)$ that is differentiable w.r.t. $s$. Hence using the differentiability of $J({\bf g})$, we get
\begin{align*}
	J({\bf g}(r)) - J({\bf g}(0)) = \int_0^r \langle\nabla J({\bf g}(s)),{\bf g}'(s)\rangle_{\mathcal{U}^\star,\mathcal{U}}\,{\rm d}s.
\end{align*}
Let us choose the control s.t. \textbf{(1.17)}
\begin{align*}
	{\bf g}'(s) + \mathbb{A}^{-1}(s)\nabla J({\bf g}(s)) = 0,\ s\in(0,r),
\end{align*}
where $\mathbb{A}$ stands for an appropriate duality operator, then the functional writes
\begin{align*}
	J({\bf g}(r)) - J({\bf g}(0)) = -\int_0^r |\nabla J({\bf g}(s))|^2\,{\rm d}s.
\end{align*}
I.e., the control law (1.17) leads to a functional's decrease \& is referred to as a continuous gradient based optimization method. Using a discretization of the parameter $s$ leads to a standard gradient-based method such as the conjugate-gradient or the quasi-Newton method depending on the choice of $\mathbb{A}(s)$.'' -- \cite[Chap. 1, Subsect. 1.4.1, pp. 11--12]{Moubachir_Zolesio2006}

\subsubsection{Shape design of a fixed solid inside a fluid flow}
``We again consider the situation where a fixed solid is surrounded by a fluid flow. The shape control consists in finding the optimal shape of the solid that reduces some objective functional (e.g., the drag) under some perimeter, volume or curvature constraints. This optimization is an open-loop control since the shape of the obstacle is time-independent.''

\paragraph{The speed method.} ``Here the space of shapes is no more a linear space \& the associated differential calculus becomes more tricky. Our goal is to build \textit{gradient-based methods} in order to find the optimal shape, i.e., we would like to solve the following problem, \textbf{(1.18)} $\min_{\Omega\in\mathcal{A}} J(\Omega)$. In order to carry out the sensitivity analysis of functionals depending on the shape of the solid $\Omega$, we introduce a family of pertubated domains $\Omega_s\subset D$ parametrized by a scholar parameter $0\le s\le\varepsilon$. These domains are the images of the original domain $\Omega$ through a given family of smooth maps\footnote{Typically we have the following Lipschitz regularity assumptions:
\begin{align*}
	{\bf T}(\cdot,{\bf x})&\in\mathcal{C}^1([0,\varepsilon];\mathbb{R}^3),\ \forall{\bf x}\in D,\ \|{\bf T}(\cdot,{\bf x}) - {\bf T}(\cdot,{\bf y})\|_{\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3)}\le C\|{\bf x} - {\bf y}\|_{\mathbb{R}^3},\\
	{\bf T}^{-1}(\cdot,{\bf x})&\in\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3),\ \forall{\bf x}\in D,\ \|{\bf T}^{-1}(\cdot,{\bf x}) - {\bf T}^{-1}(\cdot,{\bf y})\|_{\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3)}\le C\|{\bf x} - {\bf y}\|_{\mathbb{R}^3},
\end{align*}
where $C > 0$.} ${\bf T}_s:\overline{D}\to\overline{D}$, i.e. $\Omega_s = {\bf T}_s(\Omega)$, $\Gamma_s = {\bf T}_s(\Gamma)$.

2 major classes of such mappings are given by:
\begin{itemize}
	\item the \textit{identity perturbation method} ([116, 125]), ${\bf T}_s = {\rm I} + s\boldsymbol{\theta}$, where $\boldsymbol{\theta}:\overline{D}\to\overline{D}$.
	\item the \textit{speed method} [145] \cite{Pironneau1984}, where the transformation is the flow associated to a given velocity field ${\bf V}(s,{\bf x})$,
	\begin{equation*}
		\left\{\begin{split}
			\partial_s{\bf T}_s({\bf x}) &= {\bf V}(s,{\bf T}_s({\bf x})),&&(s,{\bf x})\in(0,\varepsilon)\times D,\\
			{\bf T}_{s=0}({\bf x}) &= {\bf x},&&{\bf x}\in D.
		\end{split}\right.
	\end{equation*}
	In order for $\overline{D}$ to be globally invariant under ${\bf T}_s({\bf V})$ we need to impose the following \textit{viability conditions}, ${\bf V}(s,{\bf x})\cdot{\bf n}({\bf x}) = 0$, ${\bf x}\in\partial D$.
\end{itemize}
Let us consider the family of functionals $J(\Omega_s)$ that depends on the shapes $\Omega_s$, e.g., the work to overcome the drag exerted by the fluid on the solid boundary, \textbf{(1.19)}
\begin{align*}
	J_{\rm drag}(\Omega) = \int_{(0,\tau)\times\Gamma} ({\bf u} - {\bf u}_\infty)\cdot\sigma({\bf u},p)\cdot{\bf n}\,{\rm d}\Gamma\,{\rm d}t.
\end{align*}
This functional depends on $\Omega$ not only because it is an integral over the boundary $\Gamma$, but also because it involves the solution $({\bf u},p)$ of the Navier--Stokes system, \textbf{(1.20)}, that depends on $\Omega$.

To perform our sensitivity analysis, we choose to work in the framework of the \textit{speed method}\footnote{which leads, at least for the 1st order terms, to the same results as the identity perturbation framework [51].} We define the Eulerian derivative of the shape functional $J(\Omega)$ at point $\Omega$ in the direction of the vector field ${\bf V}\in\mathcal{V}$ as the limit,
\begin{align*}
	dJ(\Omega;{\bf V}) = \lim_{s\downarrow 0} \frac{J(\Omega_s({\bf V})) - J(\Omega)}{s},
\end{align*}
where $\mathcal{V}$ is a linear space\footnote{e.g., $\mathcal{V}\coloneqq\{{\bf V}\in\mathcal{C}^0(0,\varepsilon;\mathcal{C}^1(D;\mathbb{R}^3)),\ \nabla\cdot{\bf V} = 0\mbox{ in } D,\ \langle{\bf V},{\bf n}\rangle = 0\mbox{ on }\partial D\}$.} If this limit exists \& is finite $\forall{\bf V}\in\mathcal{V}$ \& the mapping $\mathcal{V}\to\mathbb{R}$, ${\bf V}\mapsto dJ(\Omega;{\bf V})$ is linear \& continuous, then the functional $J(\Omega)$ is said to be \textit{shape differentiable}.

Actually if $J(\Omega)$ is shape differentiable, then its Eulerian derivative only depends on ${\bf V}(0)$ \& there exists a distribution ${\bf G}(\Omega)\in\mathcal{D}(D;\mathbb{R}^3)'$ that we call the \textit{shape gradient} s.t.
\begin{align*}
	dJ(\Omega;{\bf V}) = \langle{\bf G}(\Omega),V(0)\rangle,\ \forall{\bf V}\in\mathcal{V}.
\end{align*}
In the sequel, we shall use the notation $\nabla J(\Omega)\coloneqq{\bf G}(\Omega)$. In the case of smooth domain, the gradient is only supported on the boundary $\Gamma$ \& depends linearly on the normal vector field ${\bf n}$. This result, called the \textit{structure theorem}\footnote{Refer to \cite[Theorem 3.5]{Delfour_Zolesio2001} for the case of non-smooth domains.}, is recalled as follows,

\begin{theorem}[Shape derivative structure theorem]
	Let $J(\cdot)$ be a differentiable shape functional at every shape $\Omega$ of class $\mathcal{C}^{k+1}$ for $k\ge 0$ with shape gradient ${\bf G}(\Omega)\in\mathcal{D}(D;\mathbb{R}^3)'$. In this case, the shape gradient has the following representation,
	\begin{align*}
		{\bf G}(\Omega) = {}^\star\gamma_\Gamma(g{\bf n}),
	\end{align*}
	where $g(\Gamma)\in\mathcal{D}^{-k}(\Gamma)$ stands for a scalar distribution \& ${}^\star\gamma_\Gamma$ stands for the adjoint trace operator\footnote{i.e.,
	\begin{align*}
		\langle{}^\star\gamma_\Gamma(g{\bf n}),{\bf V}\rangle_{\mathcal{D}(D;\mathbb{R}^3)',\mathcal{D}(D;\mathbb{R}^3)} = \langle g,{\bf V}\cdot{\bf n}\rangle_{\mathcal{D}'(\Gamma),\mathcal{D}(\Gamma)}.
	\end{align*}}.
\end{theorem}
This result is easier to understand when $g(\Gamma)$ is integrable over $\Gamma$, that is to say, $g\in L^1(\Gamma)$. Indeed in this case, it means that the directional shape derivative can always be written as follows,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Gamma g{\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
\end{align*}

\paragraph{Basic shape derivative calculus.} The notion of Eulerian derivative for shape functionals can be extended to functions defined on Banach or Hilbert spaces built on smooth domains $\Omega$. Hence, a function $y\in H(\Omega)$ admits a \textit{material derivative} at $\Omega$ in the direction ${\bf V}\in\mathcal{V}$ if the following limit
\begin{align*}
	\dot{y}(\Omega;{\bf v})\coloneqq\lim_{s\to 0} \frac{1}{s}[y(\Omega_s({\bf V}))\circ{\bf T}_s({\bf V}) - y(\Omega)]
\end{align*}
admits a limit in the Hilbert space\footnote{e.g., $W^{m,p}(\Omega)$  or $L^2(0,\tau;W^{m,p}(\Omega))$.} $H(\Omega)$.

Endowed with the following definition, it is possible to derive the Eulerian shape derivative of the following functionals,
\begin{align*}
	J(\Omega) = \int_\Omega y(\Omega)\,{\rm d}\Omega.
\end{align*}
If $y(\Omega)$ is weakly shape differentiable in $L^1(\Omega)$, then the functional $J(\Omega)$ is shape differentiable \& its directional derivative writes,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega [\dot{y}(\Omega;{\bf V}) + y(\Omega)\nabla\cdot{\bf V}(0)]\,{\rm d}\Omega.
\end{align*}
In order to apply the structure theorem, it is useful to define the notion of shape derivative for functions. Hence, if $y\in H(\Omega)$ admits a material derivative $\dot{y}(\Omega;{\bf V})\in H(\Omega)$ \& $\nabla y\cdot{\bf V}(0)\in H(\Omega)$ for all ${\bf V}\in\mathcal{V}$, we define the \textit{shape derivative} as
\begin{align*}
	y'(\Omega;{\bf V}) = \dot{y}(\Omega;{\bf V}) - \nabla y(\Omega)\cdot{\bf V}(0).
\end{align*}
In this case, the Eulerian shape derivative of $J(\Omega)$ takes the following form,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega [y'(\Omega;{\bf V}) + \nabla\cdot(y(\Omega){\bf V}(0))]\,{\rm d}\Omega.
\end{align*}
If $\Omega$ is class $\mathcal{C}^k$ with $k\ge 1$, then using the Stokes formula, we get
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega y'(\Omega;{\bf V}) + \int_\Gamma y(\Omega){\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
\end{align*}

\begin{remark}
	In the case where $y(\Omega) = Y|_\Omega$, where $Y\in H(D)$ with $\Omega\subset D$, its shape derivative is zero since $\dot{y}(\Omega;{\bf V}) = \nabla Y\cdot{\bf V}$. Hence,
	\begin{align*}
		dJ(\Omega;{\bf V}) = \int_\Gamma y(\Omega){\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
	\end{align*}
	This is a simple illustration of the structure theorem.
\end{remark}
In the case of functionals involving integration over the boundary $\Gamma$, we need to introduce the notion of \textit{material derivative} on $\Gamma$.

Let $z\in W(\Gamma)$ where $W(\Gamma)$ is an Hilbert space of functions (e.g., $W^{m,p}(\Gamma)$) defined over $\Gamma$. It is said that it admits a material derivative in the direction ${\bf V}\in\mathcal{V}$, if the following limit,
\begin{align*}
	\dot{z}(\Gamma;{\bf V})\coloneqq\lim_{s\to 0} \frac{1}{s}[z(\Gamma_s({\bf V}))\circ{\bf T}_s({\bf V}) - z(\Gamma)]
\end{align*}
admits a limit in the Hilbert space $W(\Gamma)$.

As a consequence of this definition, it is possible to derive the Eulerian shape derivative of the following functional,
\begin{align*}
	J(\Gamma) = \int_\Gamma z(\Gamma)\,{\rm d}\Gamma.
\end{align*}
If $z(\Gamma)$ is weakly shape differentiable in $L^1(\Omega)$, then the functional $J(\Gamma)$ is shape differentiable \& its directional derivative writes
\begin{align*}
	dJ(\Gamma;{\bf V}) = \int_\Gamma [\dot{z}(\Gamma;{\bf V}) + z(\Gamma)\operatorname{div}_\Gamma{\bf V}(0)]\,{\rm d}\Gamma,
\end{align*}
where
\begin{align*}
	\operatorname{div}_\Gamma{\bf V}\coloneqq\gamma_\Gamma[\nabla\cdot{\bf V} - ({\rm D}{\bf V}\cdot{\bf n})\cdot{\bf n}]
\end{align*}
stands for the \textit{tangential divergence}.

As in the previous case, it is also possible to introduce the notion of shape derivative for $z(\Gamma)$. Let $\Omega$ be of class $\mathcal{C}^k$ with $k\ge 2$. If $z\in W(\gamma)$ admits a material derivative $\dot{z}(\Gamma;{\bf V})\in W(\Gamma)$ \& $\nabla_\Gamma y\cdot{\bf V}(0)\in W(\Gamma)$ for all ${\bf V}\in\mathcal{V}$, we define the \textit{shape derivative} as
\begin{align*}
	z'(\Gamma;{\bf V}) = \dot{z}(\Gamma;{\bf V}) - \nabla_\Gamma z(\Gamma)\cdot{\bf V}(0)\mbox{ where }\nabla_\Gamma z = \nabla Z|_\Gamma - (\nabla Z\cdot{\bf n}){\bf n}
\end{align*}
stands for the \textit{tangential gradient} \& $Z$ is any smooth extension of $z$ inside $\Omega$.

Using the above definition, it is possible to transform the expression of the differential as follows,
\begin{align*}
	dJ(\Gamma;{\bf V}) = \int_\Gamma [z'(\Gamma;{\bf V}) + Hz(\Gamma){\bf V}(0)\cdot{\bf n}]\,{\rm d}\Gamma,
\end{align*}
where $H$ stands fro the \textit{mean curvature} of $\Gamma$.

\begin{remark}
	In the case where $z(\Gamma) = y(\Omega)|_\Gamma$, the Eulerian derivative takes the following form,
	\begin{align*}
		dJ(\Gamma;{\bf V}) = \int_\Gamma [y'(\Omega;{\bf V}) + (\nabla y(\Omega)\cdot{\bf n} + Hz(\Gamma){\bf V}(0)\cdot{\bf n})]\,{\rm d}\Gamma.
	\end{align*}
\end{remark}

\paragraph{Application to shape design.} Thanks to the framework introduced previously, it is possible to build a complete sensitivity analysis of shape functionals. Coming back to our optimal shape problem, we can state the following: the shape gradient for the tracking functional
\begin{align*}
	J(\Omega) = \int_{(0,\tau)\times\Omega} ({\bf u} - {\bf u}_d)^2\,{\rm d}{\bf x}\,{\rm d}t
\end{align*}
is given by \textbf{(1.21)}
\begin{align*}
	\nabla J(\Omega) = {}^\star\gamma_\Gamma[\sigma({\bf v},\pi)\cdot{\bf n}]
\end{align*}
where $({\bf u},p)$ is a solution of system (1.20) associated to the shape $\Omega$ \& $({\bf v},\pi)$ is solution of the adjoint system \textbf{(1.22).}

\paragraph{The associated shape differential equation.} Now as in the previous section, we can choose to solve the 1st-order optimality equation (1.21) using a continuous gradient-based method. I.e., we write
\begin{align*}
	J(\Omega_r({\bf V})) - J(\Omega_0) = \int_0^r \langle\nabla J(\Omega_s({\bf V})),{\bf V}(s)\rangle\,{\rm d}s.
\end{align*}
Then solving the equation \textbf{(1.23)}
\begin{align*}
	\nabla J({\bf V}(s)) + \mathbb{A}^{-1}(s)\cdot{\bf V}(s) = 0,\ s\in(0,+\infty)
\end{align*}
leads to a decrease of the functional $J(\Omega_s({\bf V}))$. The equation (1.23) is referred to as the \textit{shape differential equation} \& some of its properties are studied in \cite[Chap. 4]{Moubachir_Zolesio2006}. Notably, we study its solvability in the case of smooth shape functionals. We also prove some results concerning the asymptotic behavior of the solution of this equation, which hold essentially when the shape gradient has some continuity properties for an \textit{ad-hoc} shape topology\footnote{The Hausdorff-complementary topology.}.

\paragraph{The level-set framework.} In Chap. 4, we also relate the shape differential equation to the Hamilton--Jacobi equation involved in the level-set setting. The level-set setting consists in parametrizing the perturbed domain $\Omega_s$ as the positiveness set of a scalar function $\Phi:(0,\varepsilon)\times\overline{D}\to\mathbb{R}$,
\begin{align*}
	\Omega_s = \Omega_s(\Phi)\coloneqq\{{\bf x}\in D,\ \Phi(s,{\bf x}) > 0\},
\end{align*}
\& its boundary is the zero-level set,
\begin{align*}
	\Gamma_s = \Gamma_s(\Phi)\coloneqq\{{\bf x}\in D,\ \Phi(s,{\bf x}) = 0\}.
\end{align*}
This parametrization \& the one introduced in the \textit{speed method} can be linked thanks to the following identity,
\begin{align*}
	{\bf V}(s) = -\partial_s\Phi(s)\frac{\nabla\Phi(s)}{\|\nabla\Phi(s)\|^2}.
\end{align*}
Both frameworks are equivalent if $\Phi(s)$ belongs to set of functions without steps, i.e., $\|\nabla\Phi(s)\|$ is different from zero a.e. in $D$. We show how to build without step functions \& we study the shape differential equation in this setting.'' -- \cite[Chap. 1, Subsect. 1.4.2, pp. 13--19]{Moubachir_Zolesio2006}

\subsubsection{Dynamical shape design of a solid inside a fluid flow}
``$\ldots$ we consider that the shape of the solid is moving.'' \textbf{Goals.} to control this motion in order to optimize some objective functionals; to build gradient-based methods in order to find the optimal shape dynamic, i.e., we would like to solve the following problem, \textbf{(1.24)} $\min_{Q\in\mathcal{E}} J(Q)$ where $Q\in\mathcal{E}$ is a smooth evolution set, which means
\begin{align*}
	Q\coloneqq\bigcup_{t\in(0,\tau)} \{t\}\times\Omega_t,
\end{align*}
where $\Omega_t$ is a smooth domain of $\mathbb{R}^3$ with boundary $\Gamma_t$. The set,
\begin{align*}
	\Sigma\coloneqq\bigcup_{t\in(0,\tau)} \{t\}\times\Gamma_t
\end{align*}
stands for the \textit{non-cylindrical lateral boundary}. We call the set $Q$ a \textit{tube}.

\paragraph{The $\mathbb{R}^{d+1}$-approach.} ``The optimal control of moving domain is a problem which is relevant of classical (nonlinear) control theory as well as of classical shape theory. In fact on the pure theoretical level, the dynamical shape control theory can be viewed as an application of the shape optimization theory for space-time manifolds.'' \textsf{Fig. Non-cylindrical space-time domain.} ``Indeed the dynamical shape control consists in finding the optimal evolution of a spatial domain $\Omega_t$ in $\mathbb{R}^d$. Let us consider the mapping $\mathcal{S}:t\in\mathbb{R}\to\Omega_t\in\mathcal{P}(\mathbb{R}^d)$ where $\mathcal{P}(\mathbb{R}^d)$ stands for the set of parts inside $\mathbb{R}^d$. Usually we would like to minimize some cost functional,
\begin{align*}
	j(\mathcal{S}) = \int_0^\tau J(t,\mathcal{S}(t))\,{\rm d}t.
\end{align*}
Obviously, it is equivalent to the problem of finding the optimal tube
\begin{align*}
	Q = \bigcup_{0 < t < \tau} \{t\}\times\Omega_t\in\mathbb{R}^{d+1}.
\end{align*}
In fact the tube $Q$ is the graph in $\mathbb{R}\times\mathcal{P}(\mathbb{R}^d)\subset\mathbb{R}^{d+1}$ of the shape mapping $\mathcal{S}$. As for usual mappings defined from $\mathbb{R}$ in some space $E$, the graph $G\subset\mathbb{R}\times E$ \& of course any subset $G$ is not a graph. Now under simple conditions on that set $G$, it becomes a graph. In the same way, any subset $Q\in\mathbb{R}\times\mathcal{P}(\mathbb{R}^d)$ will not be a tube. Intuitively we would say that we require some \textit{causality} in the evolution of the set $\Omega_t$.

When the boundary of the set $\Omega_t$ is smooth enough\footnote{say there exists a tangent space.}, the idea is to avoid the normal field $\nu$ to the lateral boundary $\Sigma$ of the tube to be strictly vertical. To handle non-smooth situations, we adopt an Eulerian viewpoint that associates to each tube $Q$ the non-empty closed convex set of speed vector fields ${\bf V}$ which transport (in a weak sense) the characteristic function of the moving domain. When we consider the tube $Q$ as a subset of $\mathbb{R}^{d+1}$, the control problems becomes a usual shape optimization problem (as far as no real time consideration enters). The sensitivity analysis is then classically performed by considering \textit{horizontal} vector fields $\widetilde{\bf Z}(s,t,{\bf x}) = (0,{\bf Z}(s,t,{\bf x}))\in\mathbb{R}^{d+1}$ where $s$ is the \textit{perturbation parameter} of the tube.

Then the $(d + 1)$-dimensional shape optimization analysis fully applies \& the so-called \textit{Shape Differential Equation} furnishes descent direction, i.e., it furnishes the existence of a vector field ${\bf Z}^\star$ s.t., for some $\alpha > 0$,
\begin{align*}
	J(Q_s)\le J(Q) - \alpha\int_0^s \|{\bf Z}^\star(\sigma)\|^2\,{\rm d}\sigma,\ \forall s > 0.
\end{align*}
We show that the existence of that field ${\bf Z}^\star$ induces the existence of a usual vector field ${\bf V}(t,{\bf x})\in\mathbb{R}^d$ which builds that tube, i.e., $\Omega_t = {\bf T}({\bf V})(\Omega_0)$.

\paragraph{The $\mathbb{R}^d$-approach.} In order to carry out the sensitivity analysis of functionals depending on the tube $Q$, we assume that the domains are the images of the domain $\Omega_0\coloneqq\Omega_{t = 0}$ through a given family of smooth maps ${\bf T}_t:\overline{D}\to\overline{D}$, i.e., $\Omega_t = {\bf T}_t(\Omega_0)$, $\Gamma_t = {\bf T}_t(\Gamma_0)$. 2 major class of such mappings are given by:
\begin{itemize}
	\item the \textit{Lagrangian parametrization} ${\bf T}_t = \boldsymbol{\theta}(t,\cdot)$ where $\boldsymbol{\theta}:(0,\tau)\times\overline{D}\to\overline{D}$. In this case, the minimization problem (1.24) can be transformed as \textbf{(1.25)} $\min_{\boldsymbol{\theta}\in\Theta} J(Q(\boldsymbol{\theta}))$.
	\item the \textit{Eulerian parametrization}, where the transformation is the flow associated to a given velocity field ${\bf V}(t,{\bf x})$,
	\begin{equation*}
		\left\{\begin{split}
			\partial_t{\bf T}_t({\bf x}) &= {\bf V}(t,{\bf T}_t({\bf x})),&&(t,{\bf x})\in(0,\tau)\times D,\\
			{\bf T}_{t=0}({\bf x}) &= {\bf x},&&{\bf x}\in D.
		\end{split}\right.
	\end{equation*}
	In this case, the minimization problem (1.24) can be transformed as \textbf{(1.26)} $\min_{{\bf V}\in\mathcal{V}} J(Q({\bf V}))$.
\end{itemize}

\paragraph{Existence of tubes.} In the smooth case, the existence of tubes follows the Cauchy--Lipschitz theory on differential equations [147], \cite{Delfour_Zolesio2001}. In the non-smooth case, the Lipschitz regularity of the velocities ${\bf V}$ can be weakened using the equations satisfied by the characteristic functions $\xi(t,{\bf x})$ associated to the domain $\Omega_t({\bf V})$, \textbf{(1.27)}
\begin{equation*}
	\left\{\begin{split}
		\partial_t\xi + \nabla\xi\cdot{\bf V} &= 0,&&(0,\tau)\times D,\\
		\xi_{t=0} &= \chi_\Omega,&& D.
	\end{split}\right.
\end{equation*}
We shall consider velocity fields s.t. ${\bf V}\in L^1(0,\tau;L^2(D;\mathbb{R}^d))$ \& the divergence positive part $(\nabla\cdot{\bf V})^+\in L^1(0,\tau;L^\infty(D))$. In this case, using a Galerkin approximation \& some energy estimates, we are able to derive an existence result of solutions with initial data given in $H^{-1/2}(D)$. For the time being, no uniqueness result has been obtained for this smoothness level.

Actually, when the field ${\bf V}$ \& its divergence are simply $L^1$ functions, the notion of weak solutions associated to the convection problems (1.27) does not make sense. In this case, the correct modeling tool for shape evolution is to introduce the product space of elements $(\xi = \xi^2,{\bf V})$ equipped with a parabolic BV like topology for which the constraint (1.27) defines a closed subset $\mathcal{T}_\Omega$ which contains the weak closure of smooth elements
\begin{align*}
	\mathcal{T}_\Omega\coloneqq\{(\chi_\Omega\circ{\bf T}_t^{-1}({\bf V}),{\bf V});{\bf V}\in\mathcal{U}_{\rm ad}\}.
\end{align*}
This approach consists in handling characteristic functions $\xi = \xi^2$ which belongs to $L^1(0,\tau;\operatorname{BV}(D))$ together with vector fields ${\bf V}\in L^2(0,\tau;L^2(D,\mathbb{R}^d))$ solution of problem (1.27). For a given element $(\xi,{\bf V})\in\mathcal{T}_\Omega$, we consider the set of fields ${\bf W}$ s.t. $(\xi,{\bf W})\in\mathcal{T}_\Omega$, we consider the set of fields ${\bf W}$ s.t. $(\xi,{\bf W})\in\mathcal{T}_\Omega$. It forms a closed convex set, noted $\mathcal{V}_\xi$. Hence, we can define the unique minimal norm energy element ${\bf V}_\xi$ in the convex set $\mathcal{V}_\xi$. For a given tube $\xi$, the element ${\bf V}_\xi$ is the unique (with minimal norm) vector field associated to $\xi$ via the convection equation (1.27).

We choose to adopt a different point of view inspired by the optimization problems framework. Indeed, our final goal is to apply the weak set evolution setting to the control problem arising in various fields such as free boundary problems or image processing. The usual situation can be described as follows. Let us consider a given smooth enough functional $J(\xi,{\bf V})$. We would like to solve the following optimization problem \textbf{(1.28)} $\inf_{(\xi,{\bf V})\in\mathcal{T}_\Omega} J(\xi,{\bf V})$. The space $\mathcal{U}_{\rm ad}$ is a space of smooth velocities.

In most situations, such a problem does not admit solutions \& we need to add some regularization terms to ensure its solvability. Consequently, we shall introduce different penalization terms which furnish compactness properties of the minimizing sequences inside an ad-hoc weak topology involving bounded variation constraints. Then, the new problem writes \textbf{(1.29)}
\begin{align*}
	\inf_{(\xi,{\bf V})\in\mathcal{T}_\Omega} J(\xi,{\bf V}) + F(\xi,{\bf V}).
\end{align*}
The \textit{penalization term} $F(\xi,{\bf V})$ can be chosen using several approaches:
\begin{itemize}
	\item We can 1st consider the time-space perimeter of the lateral boundary $\Sigma$ of the tube, developed in [155]. This approach easily draws part of the variational properties associated to the bounded variation functions space framework. In particular, it uses the compactness properties of tube family with bounded perimeters in $\mathbb{R}^{d+1}$. Nevertheless, this method leads to heavy variational analysis developments.
	\item We can rather consider the time integral of the spatial perimeter of the moving domain which builds the tube, as introduced in [157]. We shall extend these results to the case of vector fields living in $L^2((0,\tau)\times D;\mathbb{R}^d)$. In this case, only existence results for solutions of the convection equation can be handled \& the uniqueness property is lost.
\end{itemize}

\paragraph{Tube derivative.} In this paragraph, we are interested in differentiability properties of integrals defined over moving domains,
\begin{align*}
	J(Q({\bf V})) = \int_{Q({\bf V})} f({\bf V})\,{\rm d}{\bf x}\,{\rm d}t.
\end{align*}
The transverse map $\mathcal{T}_\rho^t$ associated to 2 vector fields $({\bf V},{\bf W})\in\mathcal{U}$ is defined as follows,
\begin{align*}
	\mathcal{T}_\rho^t:\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\coloneqq\overline{\Omega_t({\bf V} + \rho{\bf W})}\\
	{\bf x}&\mapsto T_t({\bf V} + \rho{\bf W})\circ T_t({\bf V})^{-1}.
\end{align*}

\begin{remark}
	The transverse map allows us to perform sensitivity analysis on functions defined on the unperturbed domain $\Omega_t({\bf V})$.
\end{remark}
The following result states that the transverse map $\mathcal{T}_\rho^t$ can be considered as a dynamical flow w.r.t. the perturbation variable $\rho$. $\ldots$'' -- \cite[Chap. 1, Subsect. 1.4.3, pp. 19--23]{Moubachir_Zolesio2006} \texttt{[skipped pp. 23--31]}

\section{Inverse Stefan Problem}
``$\ldots$ we consider the identification of a moving boundary that represents the isothermal interface between a solid phase \& a liquid phase, from measurements on a fixed part of the solid boundary. This problem is referred in the literature as the \textit{inverse Stefan problem} [61, 144]. We make use of the \textit{transverse derivative concepts} introduced in [154, 155].'' -- \cite[Chap. 2, p. 33]{Moubachir_Zolesio2006}

\subsection{The inverse problem setting}
``For a given evolution of the \textit{melting interface}, we consider the solution of the heat equation (2.3) \& we consider its trace on the fixed boundary $\Sigma^s$.'' \textsf{Fig. 2.2. Non-cylindrical space-time domain.} ``On the mathematical viewpoint, we introduce the \textit{observation space} $\mathcal{O}\coloneqq L^2((0,\tau);L^2(\Gamma^s))$ \& the \textit{observation operator} \textbf{(2.5)} $\mathfrak{O}:\mathcal{U}_{\rm ad}\to\mathcal{O}$, ${\bf V}\mapsto\mathfrak{O}({\bf V})\coloneqq\gamma_{\Gamma^s}(y({\bf V}))$ where $y({\bf V})$ stands for the solution of (2.3) \& $\gamma_{\Gamma^s}$ is the zero order trace operator on $\Sigma^s$.

The inverse Stefan problem consists in recovering the evolution of the melting front $\Gamma^f(t)$ from the knowledge of the temperature on the fixed solid boundary $\Gamma^s$. I.e., for a given temperature $y_{\rm d}\in L^2((0,\tau);L^2(\Gamma^s))$, we look for ${\bf V}\in\mathcal{U}_{\rm ad}$ s.t. \textbf{(2.6)} $\mathfrak{O}({\bf V}) = y_{\rm d}$, in $\mathcal{O}$. It is a nonlinear ill-posed inverse problem that can be solved using a least-square minimization problem regularized thanks to a Tikhonov zero order term. Hence we look for the solution ${\bf V}$ of the following optimization problem \textbf{(2.7)}
\begin{align*}
	\min_{{\bf V}\in\mathcal{U}_{\rm ad}} \frac{1}{2}\|\mathfrak{O}({\bf V}) - y_{\rm d}\|_{\mathcal{O}}^2 + \frac{\alpha}{2}\|{\bf V}\|_{\mathcal{U}_{\rm ad}}^2,
\end{align*}
with $\alpha > 0$.'' -- \cite[Chap. 2, Sect. 2.2, p. 35]{Moubachir_Zolesio2006}

\subsection{The Eulerian derivative \& the transverse field}
``A possible choice in order to solve the above minimization problem is to use a gradient based method such as the \textit{conjugate gradient method}. Hence, we need to evaluate the gradient w.r.t. ${\bf V}$ of the functional \textbf{(2.13)} $j({\bf V})\coloneqq\frac{1}{2}\|\mathfrak{O}({\bf V}) - y_{\rm d}\|_{\mathcal{O}}^2$ where, for the sake of simpleness, we have dropped the regularizing term $\frac{\alpha}{2}\|{\bf V}\|_{\mathcal{U}_{\rm ad}}^2$. Let us choose a perturbation direction ${\bf W}\in\mathcal{U}_{\rm ad}$. We would like to compute the \textit{directional derivative} of $j$, \textbf{(2.14)}
\begin{align*}
	[{\rm D}_{\bf V}[j]({\bf V})]\cdot{\bf W}\coloneqq\lim_{\rho\to 0} \frac{1}{\rho}(j({\bf V} + \rho{\bf W}) - j({\bf V})).
\end{align*}
Then the goal is to evaluate the directional derivative of the element $y({\bf V})$ which is a solution of the moving heat equation (2.3). In order to do so, we write the associated variational formulation satisfied $y({\bf V})$, \textbf{(2.15)}
\begin{align*}
	\int_0^\tau\int_{\Omega_t({\bf V})} [\partial_ty({\bf V})\phi({\bf V}) + \nabla y({\bf V})\cdot\nabla\phi({\bf V})]\,{\rm d}{\bf x}\,{\rm d}t = 0,\ \forall\phi({\bf V})\in L^2((0,\tau);H_{0,\Gamma_t({\bf V})}^1(\Omega_t({\bf V}))),
\end{align*}
where we have set w.l.o.g., $(f,y_{\rm d},y_0) = (0,0,0)$ together with $\Omega_t({\bf V})\coloneqq\Omega^s(t)$ \& $\Gamma_t({\bf V})\coloneqq\Gamma^f(t)$. Looking at (2.15), it is clear that we need to establish how to differentiate the generic term $J({\bf V}) = \int_0^\tau\int_{\Omega_t({\bf V})} f({\bf V})\,{\rm d}{\bf x}\,{\rm d}t$ w.r.t. ${\bf V}$. To this end, we introduce the \textit{perturbated moving domain} $\Omega_t({\bf V} + \rho{\bf W})\coloneqq T_t({\bf V} + \rho{\bf W})(\Omega_0)$. This family generates a \textit{perturbed tube}
\begin{align*}
	Q({\bf V} + \rho{\bf W})\coloneqq\bigcup_{0\le t\le\tau} (\{t\}\times\Omega_t({\bf V} + \rho{\bf W}))
\end{align*}
as described in \textsf{Fig. 2.3. Perturbed tube.} Since the function $f({\bf V})$ is defined on the \textit{non-cylindrical reference tube} $Q({\bf V})$, it is natural to introduce the transformation between $Q({\bf V})$ \& $Q({\bf V} + \rho{\bf W})$. A canonical choice is furnished by
\begin{align*}
	\mathcal{T}^t(\rho;{\bf x}):\Omega_t({\bf V})&\to\Omega_t({\bf V} + \rho{\bf W})\\
	{\bf x}&\mapsto\mathcal{T}^t(\rho;{\bf x})\coloneqq[{\bf T}_t({\bf V} + \rho{\bf W})\circ{\bf T}_t({\bf V})^{-1}]({\bf x}).
\end{align*}
Hence, the perturbated functional can be written as follows,
\begin{align*}
	J({\bf V} + \rho{\bf W}) = \int_0^\tau\int_{\Omega_t({\bf V} + \rho{\bf W})} f({\bf V} + \rho{\bf W})\,{\rm d}{\bf x}\,{\rm d}t = \int_0^\tau\int_{\mathcal{T}_\rho^t(\Omega_t({\bf V}))} f({\bf V} + \rho{\bf W})\,{\rm d}{\bf x}\,{\rm d}t = \int_0^\tau\int_{\Omega_t({\bf V})} (\det{\rm D}\mathcal{T}_\rho^t)f({\bf V} + \rho{\bf W})\circ\mathcal{T}_\rho^t\,{\rm d}{\bf x}\,{\rm d}t,
\end{align*}
where we have performed a transport into the \textit{moving reference domain} $\Omega_t({\bf V})$. Now we shall need to differentiate the terms inside the integral w.r.t. $\rho$ at point $\rho = 0$. The easiest way to do so is to connect this problem to the classical shape derivative calculus handled inside the speed method framework [147, 135]. I.e., we need to identify a transverse velocity field that may generate the transverse map $\mathcal{T}^t(\rho;{\bf x})$ as the solution of a dynamical system w.r.t. the parameter $\rho\in[0,\rho_0]$. Actually, it can be proven that ${\bf T}({\bf V} + \rho{\bf W})$ is continuously differentiable\footnote{in $\mathcal{Z}_{\rm ad}\coloneqq\mathcal{C}^0([0,\tau];(\mathcal{C}^{k-1}(\overline{D}))^d)$.} w.r.t. $\rho$ \& that the transverse map $\mathcal{T}_\rho^t$ can be considered as the flow w.r.t. $\rho$ of the transverse vector field
\begin{align*}
	\mathcal{Z}(\rho;(t,{\bf x}))\coloneqq[\partial_\rho\mathcal{T}^t(\rho)]\circ\mathcal{T}^t(\rho)^{-1}({\bf x}) = [\partial_\rho{\bf T}({\bf V} + \rho{\bf W})]\circ{\bf T}({\bf V} + \rho{\bf W})^{-1}({\bf x}).
\end{align*}
p. 39

\textsf{Fig. 2.4. Transverse map.}

'' -- \cite[Chap. 2, Sect. 2.3, pp. 37--]{Moubachir_Zolesio2006}

\section{Dynamical Shape Control of NSEs}
\cite[Chap. 5]{Moubachir_Zolesio2006} ``deals with the analysis of an \textit{inverse dynamical shape problem} involving a fluid inside a moving domain. This type of inverse problem happens frequently in the design \& the control of many industrial devices such as aircraft wings, cable-stayed bridges, automobile shapes, satellite reservoir tanks \& more generally of systems involving fluid-solid interactions.

The control variable is the shape of the moving domain, \& the objective is to minimize a given cost functional that may be chosen by the designer.

On the theoretical level, early works concerning optimal control problems for general parabolic equations written in non-cylindrical domains have been considered in [43,29,30,142,2]. In [140,151,152], the stabilization of structures using the variation of the domain has been addressed. The basic principle is to define a map sending the non-cylindrical domain into a cylindrical one. This process leads to the mathematical analysis of non-autonomous PDE's systems.

Recently, a new methodology to obtain \textit{Eulerian derivatives} for non-cylindrical functionals has been introduced in [157, 156, 58]. This methodology was applied in [59] to perform dynamical shape control of the non-cylindrical NSEs where the evolution of the domain is the control variable. Hence the classical optimal shape optimization theory has been extended to deal with non-cylindrical domains.''

\textbf{Aim.} ``review several results on the dynamical shape control of the Navier--Stokes system \& suggest an alternative treatment using the Min-Max principle [45, 46]. Despite its lack of rigorous mathematical justification in the case where the Lagrangian functional is not convex, we shall show how this principle allows, at least formally, to bypass the tedious computation of the state differentiability w.r.t. the shape of the moving domain.'' -- \cite[Chap. 5, p. 109]{Moubachir_Zolesio2006}

\subsection{Problem Statement}
``Let us consider a moving domain $\Omega_t\in\mathbb{R}^d$. We introduce a diffeomorphic map sending a fixed reference domain $\Omega_0$ into the physical configuration $\Omega_t$ at time $t\ge 0$. W.l.o.g., we choose the reference configuration to be the physical configuration at initial time $\Omega_{t=0}$. Hence we define a map $T_t\in\mathcal{C}^1(\overline{\Omega_0})$ s.t. $\overline{\Omega_t} = T_t(\overline{\Omega_0})$, $\overline{\Gamma_t} = T_t(\overline{\Gamma_0})$. We set $\Sigma\coloneqq\bigcup_{0 < t < T} (\{t\}\times\Gamma_t)$, $Q\coloneqq\bigcup_{0 < t < T} (\{t\}\times\Omega_t)$. The map $T_t$ can be actually defined as the flow of a particular vector field, as described in the following lemma:

\begin{theorem}[ref. 147]
	$\overline{\Omega_t} = T_t(V)(\overline{\Omega_0})$, $\overline{\Gamma_t} = T_t(V)(\overline{\Gamma_0})$ where $T_t(V)$ is the solution of the following dynamical system:
	\begin{align*}
		T_t(V):\Omega_0&\to\Omega\\
		x_0&\mapsto x(t,x_0)\coloneqq T_t(V)(x_0)
	\end{align*}
	with \textbf{(5.1)}
	\begin{equation*}
		\left\{\begin{split}
			\frac{{\rm d}x}{{\rm d}\tau} &= V(\tau,x(\tau)),&&\tau\in[0,T],\\
			x(\tau = 0) &= x_0,&&\mbox{in }\Omega_0.
		\end{split}\right.
	\end{equation*}
\end{theorem}
The fluid filling $\Omega_t$ is assumed to be a viscous incompressible Newtonian fluid. Its evolution is described by its velocity ${\bf u}$ \& its pressure $p$. The couple $({\bf u},p)$ satisfies the classical NSEs written in non-conservative form \textbf{(5.2)}
\begin{equation*}
	\left\{\begin{split}
		\partial_t{\bf u} + {\rm D}{\bf u}\cdot{\bf u} - \nu\Delta{\bf u} + \nabla p &= 0,&&Q(V),\\
		\nabla\cdot{\bf u} &= 0,&&Q(V),\\
		{\bf u} &= V,&&\Sigma(V),\\
		{\bf u}(t = 0) &= {\bf u}_0,&&\Omega_0,
	\end{split}\right.
\end{equation*}
where $\nu$ stands for the kinematic viscosity. The quantity $\sigma({\bf u},p) = -p{\rm I} + \nu({\rm D}{\bf u} + {}^\star{\rm D}{\bf u})$ stands for the \textit{fluid stress tensor} inside $\Omega_t$, with $({\rm D}{\bf u})_{i,j} = \partial_ju_i$. We are interested in solving the following minimization problem: \textbf{(5.3)} $\min_{V\in\mathcal{U}} j(V)$ where $j(V) = J_V({\bf u}(V),p(V))$ with $({\bf u}(V),p(V))$ is a weak solution of problem (5.2) \& $J_V({\bf u},p)$ is a real functional of the following form: \textbf{(5.4)}
\begin{align*}
	J_V({\bf u},p) = \frac{\alpha}{2}\|\mathcal{B}{\bf u}\|_{Q(V)}^2 + \frac{\gamma}{2}\|\mathcal{K}V\|_{\Sigma(V)}^2,
\end{align*}
where $\mathcal{B}\in\mathcal{L}(\mathcal{H},\mathcal{H}^\star)$ is a general linear differential operator satisfying the following identity, \textbf{(5.5)}
\begin{align*}
	\langle\mathcal{B}{\bf u},{\bf v}\rangle + \langle{\bf u},\mathcal{B}^\star{\bf v}\rangle = \langle\mathcal{B}_\Sigma{\bf u},{\bf v}\rangle_{L^2(\Sigma)},
\end{align*}
where $\mathcal{H} = \{{\bf v}\in L^2(0,T;(H_0^1({\rm div},\Omega_t(V)))^d)\}$ \& $\mathcal{K}\in\mathcal{L}(\mathcal{U},L^2(\Sigma(V)))$ is a general linear differential operator satisfying the following identity, \textbf{(5.6)}
\begin{align*}
	\langle\mathcal{K}{\bf u},{\bf v}\rangle_{L^2(\Sigma)} + \langle{\bf u},\mathcal{K}^\star{\bf v}\rangle_{L^2(\Sigma)} = \langle\mathcal{K}_\Sigma{\bf u},{\bf v}\rangle_{L^2(\Sigma)}.
\end{align*}
The main difficulty in dealing with such a minimization problem is related to the fact that integrals over the domain $\Omega_t(V)$ depend on the control variable $V$. This point will be solved by using the Arbitrary Lagrange--Euler (ALE) map $T_t(V)$ introduced previously. The purpose of this chapter is to prove using several methods the following result,

\begin{theorem}[Main result]
	For $V\in\mathcal{U}$ \& $\Omega_0$ of class $\mathcal{C}^2$, the functional $j(V)$ possesses a gradient $\nabla j(V)$ which is supported on the moving boundary $\Gamma_t(V)$ \& can be represented by the following expression, \textbf{(5.7)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\varphi,\pi)\cdot{\bf n} + \alpha\mathcal{B}_\Sigma\mathcal{B}{\bf u} + \gamma[-\mathcal{K}^\star\mathcal{K}V + \mathcal{K}_\Sigma\mathcal{K}V],
	\end{align*}
	where $(\varphi,\pi)$ stands for the adjoint fluid state solution of the following system, \textbf{(5.8)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\varphi - {\rm D}\varphi\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\varphi - \nu\Delta\varphi + \nabla\pi &= -\alpha\mathcal{B}^\star\mathcal{B}{\bf u},&&Q(V),\\
			\nabla\cdot\varphi &= 0,&&Q(V),\\
			\varphi &= 0,&&\Sigma(V),\\
			\varphi(T) &= 0,&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.9)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with \textbf{(5.10)}
	\begin{align*}
		f = [-(\sigma(\varphi,\pi)\cdot{\bf n}) + \alpha\mathcal{B}_\Sigma\mathcal{B}{\bf u}]\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}\left[\alpha|\mathcal{B}{\bf u}|^2 + \gamma H|\mathcal{K}V|^2\right].
	\end{align*}
\end{theorem}

\begin{example}
	We set $(\mathcal{B},\mathcal{B}^\star,\mathcal{B}_\Sigma) = ({\rm I},-{\rm I},0)$, $(\mathcal{K},\mathcal{K}^\star,\mathcal{K}_\Sigma) = ({\rm I},-{\rm I},0)$. I.e., we consider the cost functional, \textbf{(5.11)}
	\begin{align*}
		J_V({\bf u},p) = \frac{\alpha}{2}\|{\bf u}\|_{L^2(Q(V))}^2 + \frac{\gamma}{2}\|V\|_{L^2(\Sigma(V))}^2.
	\end{align*}
	Then its gradient is given by \textbf{(5.12)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\boldsymbol{\varphi},\pi)\cdot{\bf n} + \gamma V,
	\end{align*}
	where $(\boldsymbol{\varphi},\pi)$ stands for the adjoint fluid state solution of the following system \textbf{(5.13)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\boldsymbol{\varphi} - {\rm D}\boldsymbol{\varphi}\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\boldsymbol{\varphi} - \nu\Delta\boldsymbol{\varphi} + \nabla\pi &= \alpha{\bf u},&&Q(V),\\
			\nabla\cdot\boldsymbol{\varphi} &= 0,&&Q(V),\\
			\boldsymbol{\varphi} &= {\bf 0},&&\Sigma(V),\\
			\boldsymbol{\varphi}(T) &= {\bf 0},&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.14)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with \textbf{(5.15)}
	\begin{align*}
		f = -\nu({\rm D}\boldsymbol{\varphi}\cdot{\bf n})\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}(\alpha + \gamma H)|V|^2.
	\end{align*}
\end{example}

\begin{example}
	We set $(\mathcal{B},\mathcal{B}^\star,\mathcal{B}_\Sigma) = (\operatorname{curl},\operatorname{curl},\land{\bf n})$, $(\mathcal{K},\mathcal{K}^\star,\mathcal{K}_\Sigma) = ({\rm I},-{\rm I},0)$, \textbf{(5.16)}
	\begin{align*}
		J_V({\bf u},p) = \frac{\alpha}{2}\|\operatorname{curl}{\bf u}\|_{L^2(Q(V))}^2 + \frac{\gamma}{2}\|V\|_{L^2(\Sigma(V))}^2.
	\end{align*}
	Then its gradient is given by \textbf{(5.17)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\boldsymbol{\varphi},\pi)\cdot{\bf n} + \alpha(\operatorname{curl}{\bf u})\land{\bf n} + \gamma V,
	\end{align*}
	where $(\boldsymbol{\varphi},\pi)$ stands for the adjoint fluid state solution of the following system, \textbf{(5.18)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\boldsymbol{\varphi} - {\rm D}\boldsymbol{\varphi}\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\boldsymbol{\varphi} - \nu\Delta\boldsymbol{\varphi} + \nabla\pi &= -\alpha\Delta{\bf u},&&Q(V),\\
			\nabla\cdot\boldsymbol{\varphi} &= 0,&&Q(V),\\
			\boldsymbol{\varphi} &= {\bf 0},&&\Sigma(V),\\
			\boldsymbol{\varphi}(T) &= {\bf 0},&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.19)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with
	\begin{align*}
		f = [-\nu{\rm D}\boldsymbol{\varphi}\cdot{\bf n} + \alpha(\operatorname{curl}{\bf u})\land{\bf n}]\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}\left[\alpha|\operatorname{curl}{\bf u}|^2 + \gamma H|V|^2\right].
	\end{align*}
\end{example}
In the next section, we introduce several concepts closely related to shape optimization tools for moving domain problems. We also recall \textit{elements of tangential calculus} that will be used through this chapter. Then we treat successively the following points,
\begin{enumerate}
	\item In Sect. 5.5, we choose to prove the differentiability of the fluid state $({\bf u},p)$ w.r.t. the design variable $V$. The directional shape derivative $({\bf u}',p')(V)\cdot W$ is then used to compute the directional derivative $j'(V)\cdot W$ of the cost functional $j(V)$. Using the adjoint state $(\boldsymbol{\varphi},\pi)(V)$ associated to $({\bf u}',p')(V)$ \& the adjoint field $\Lambda$ associated to the \textit{transverse field} $Z_t$ introduced in sect. 5.3, we are able to furnish an expression of the gradient $\nabla j(V)$ which is a distribution supported by the moving boundary $\Gamma_t(V)$.
	\item In Sect. 5.6, we choose to bypass the computation of the state shape derivative $({\bf u}',p')(V)\cdot W$, by using a Min-Max formulation of problem (5.3) \& a transport technique. The state \& multiplier spaces are chosen in order to be independent on the scalar perturbation parameter used in the computation of the derivative of the Lagrangian functional w.r.t. $V$. This method directly furnishes the fluid state \& transverse field adjoint systems \& the resulting gradient $\nabla j(V)$.
	\item In Sect. 5.7, we again use a Min-Max strategy coupled with a state \& multiplier functional space embedding. I.e., the state \& multiplier variables live in the hold-all domain $D$. Hence the derivative of the Lagrangian functional w.r.t. $V$ only involves terms coming from the flux variation through the moving boundary $\Gamma_t(V)$. This again leads to the direct computation of the fluid state \& transverse field adjoints \& consequently to the gradient $\nabla j(V)$.'' -- \cite[Chap. 5, Sect. 5.2, pp. 110--114]{Moubachir_Zolesio2006}
\end{enumerate}

\subsection{Elements of Non-cylindrical Shape Calculus}
``This section introduces several concepts that will be intensively used through this chapter. It concerns the differential calculus of integrals defined on moving domains or boundaries w.r.t.  their support.'' -- \cite[Chap. 5, Sect. 5.3, p. 114]{Moubachir_Zolesio2006}

\subsubsection{Non-cylindrical speed method}
``In this paragraph, we are interested in differentiability properties of integrals defined over moving domains,
\begin{align*}
	J_1(\Omega_t) = \int_{\Omega_t} f(\Omega_t)\,{\rm d}\Omega,\ J_2(\Gamma_t) = \int_{\Gamma_t} g(\Gamma_t)\,{\rm d}\Gamma.
\end{align*}
The behavior of $J_1$ \& $J_2$ while perturbing their moving support highly depends on the regularity in space \& time of the domains. In this work, we choose to work with domains $\Omega_t$ that are images of a fixed domain $\Omega_0$ through an ALE map $T_t(V)$ as introduced in the 1st section. Hence, the design parameter is no more the support $\Omega_t$ but rather the velocity field $V\in\mathcal{U}\coloneqq\mathcal{C}([0,T];(W^{k,\infty}(D))^d)$ that builds the support. This technique has the advantage to transform shape calculus into classical differential calculus on vector spaces [157, 59]. For another choice based on the \textit{non-cylindrical identity perturbation}, the reader is referred to the \cite[Chap. 6]{Moubachir_Zolesio2006}.''

\paragraph{Transverse applications.}
\begin{definition}[Transverse map]
	The \emph{transverse map} $\mathcal{T}_\rho^t$ associated to 2 vector fields $(V,W)\in\mathcal{U}$ is defined as follows,
	\begin{align*}
		\mathcal{T}_\rho^t:\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\coloneqq\overline{\Omega_t(V + \rho W)}\\
		{\bf x}&\mapsto T_t(V + \rho W)\circ T_t(V)^{-1}.
	\end{align*}
\end{definition}

\begin{remark}
	The transverse map allows us to perform sensitivity analysis on functions defined on the unperturbed domain $\Omega_t(V)$.
\end{remark}
The following result states that the transverse map $\mathcal{T}_\rho^t$ can be considered as a dynamical flow w.r.t. the perturbation variable $\rho$,

\begin{theorem}[ref. 156]
	The Transverse map $\mathcal{T}_\rho^t$ is the flow of a transverse field $\mathcal{Z}_\rho^t$ defined as follows \textbf{(5.20)}
	\begin{align*}
		\mathcal{Z}_\rho^t\coloneqq\mathcal{Z}^t(\rho,\cdot) = \left(\frac{\partial\mathcal{T}_\rho^t}{\partial\rho}\right)\circ(\mathcal{T}_\rho^t)^{-1},
	\end{align*}
	i.e., is the solution of the following dynamical system:
	\begin{align*}
		T_t^\rho(\mathcal{Z}_\rho^t):\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\\
		{\bf x}&\mapsto{\bf x}(\rho,{\bf x})\coloneqq T_t^\rho(\mathcal{Z}_\rho^t)({\bf x})
	\end{align*}
	with \textbf{(5.21)}
	\begin{equation*}
		\left\{\begin{split}
			\frac{{\rm d}{\bf x}(\rho)}{{\rm d}\rho} &= \mathcal{Z}^t(\rho,{\bf x}(\rho)),&&\rho\ge 0,\\
			{\bf x}(\rho = 0) &= {\bf x},&&\mbox{in }\Omega_t(V).
		\end{split}\right.
	\end{equation*}
\end{theorem}
Since, we will mainly consider derivatives of perturbed functions at point $\rho = 0$, we set $Z_t\coloneqq\mathcal{Z}_{\rho = 0}^t$. A fundamental result lies in the fact that $Z_t$ can be obtained as the solution of a linear time dynamical system depending on the vector fields $(V,W)\in\mathcal{U}$,

\begin{theorem}
	The vector field $Z_t$ is the unique solution of the following Cauchy problem, \textbf{(5.22)}
	\begin{equation*}
		\left\{\begin{split}
			\partial_tZ_t + [Z_t,V] &= W,&&(0,T)\times D,\\
			Z_{t=0} &= 0,&&D,
		\end{split}\right.
	\end{equation*}
	where $[Z_t,V]\coloneqq DZ_t\cdot V- DV\cdot Z_t$ stands for the Lie bracket of the pair $(Z_t,V)$.
\end{theorem}

\paragraph{Shape derivative of non-cylindrical functionals.} The main theorem of this section uses the notion of a non-cylindrical material derivative that we recall here,

\begin{definition}
	The derivative w.r.t. $\rho$ at point $\rho = 0$ of the following composed function,
	\begin{align*}
		f^\rho:[0,\rho_0]&\to H(\Omega_t(V))\\
		\rho&\mapsto f(V + \rho W)\circ\mathcal{T}_\rho^t
	\end{align*}
	$\dot{f}(V;W)$ is called the \emph{non-cylindrical material derivative} of $f(V)$ at point $V\in U$ in the direction $W\in\mathcal{U}$. We shall use the notation,
	\begin{align*}
		\dot{f}(V)\cdot W = \dot{f}(V;W)\coloneqq\left.\frac{d}{d\rho}f^\rho\right|_{\rho = 0}.
	\end{align*}
\end{definition}
With the above definition, we can state the differentiability properties of non-cylindrical integrals w.r.t. their moving support,

\begin{theorem}[ref. 59]
	For a bounded measurable domain $\Omega_0$ with boundary $\Gamma_0$, let us assume that for any direction $W\in U$ the following hypothesis holds,
	\begin{itemize}
		\item[(i)] $f(V)$ admits a non-cylindrical material derivative $\dot{f}(V)\cdot W$ then $J_1(\cdot)$ is G\^ateaux differentiable at point $V\in\mathcal{U}$ \& its derivative is given by the following expression, \textbf{(5.23)}
		\begin{align*}
			J_1'(V)\cdot W = \int_{\Omega_t(V)} [\dot{f}(V)\cdot W + f(V)\nabla\cdot Z_t]\,{\rm d}\Omega.
		\end{align*}
		Furthermore, if
		\item[(ii)] $f(V)$ admits a non-cylindrical shape derivative given by the following expression, \textbf{(5.24)}
		\begin{align*}
			f'(V)\cdot W = \dot{f}(V)\cdot W - \nabla f(V)\cdot Z_t,
		\end{align*}
	\end{itemize}
	then \textbf{(5.25)}
	\begin{align*}
		J_1'(V)\cdot W = \int_{\Omega_t(V)} [f'(V)\cdot W + \nabla\cdot(f(V)Z_t)]\,{\rm d}\Omega.
	\end{align*}
	Furthermore, if $\Omega_0$ is an open domain with a Lipschitzian boundary $\Gamma_0$, then \textbf{(5.26)}
	\begin{align*}
		J_1'(V)\cdot W = \int_{\Omega_t(V)} f'(V)\cdot W\,{\rm d}\Omega + \int_{\Gamma_t(V)} f(V)\langle Z_t,{\bf n}\rangle\,{\rm d}\Gamma.
	\end{align*}
\end{theorem}

\begin{remark}
	The last identity will be of great interest while trying to prove a gradient structure result for general non-cylindrical functionals.
\end{remark}
It is also possible to establish a similar result for integrals over moving boundaries. For that purpose, we need to define the non-cylindrical tangential material derivative,

\begin{definition}
	The derivative w.r.t. $\rho$ at point $\rho = 0$ of the following composed function,
	\begin{align*}
		g^\rho:[0,\rho_0]&\to H(\Gamma_t(V))\\
		\rho&\mapsto g(V + \rho W)\circ\mathcal{T}_\rho^t
	\end{align*}
	is called the \emph{non-cylindrical material derivative} of the function $g(V)\in H(\Gamma_t(V))$ in the direction $W\in\mathcal{U}$. We shall use the notation
	\begin{align*}
		\dot{g}(V)\cdot W = \dot{g}(V;W)\coloneqq\left.\frac{d}{d\rho}g^\rho\right|_{\rho = 0}.
	\end{align*}
\end{definition}
This concept is involved in the differentiability property of boundary integrals,

\begin{theorem}
	For a bounded measurable domain $\Omega_0$ with boundary $\Gamma_0$, let us assume that for any direction $W\in U$ the following hypothesis holds,
	\begin{itemize}
		\item[(i)] $g(V)$ admits a non-cylindrical material derivative $\dot{g}(V)\cdot W$ then $J_2(\cdot)$ is G\^ateaux differentiable at point $V\in\mathcal{U}$ \& its derivative is given by the following expression, \textbf{(5.27)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [\dot{g}(V)\cdot W + g(V)\operatorname{div}_\Gamma Z_t]\,{\rm d}\Gamma.
		\end{align*}
		Furthermore, if
		\item[(ii)] $g(V)$ admits a non-cylindrical shape derivative given by the following expression, \textbf{(5.28)}
		\begin{align*}
			g'(V)\cdot W = \dot{g}(V)\cdot W - \nabla_\Gamma g(V)\cdot Z_t,
		\end{align*}
		then \textbf{(5.29)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [\tilde{g}'(V)\cdot W + Hg(V)\langle Z_t,{\bf n}\rangle]\,{\rm d}\Gamma,
		\end{align*}
		where $H$ stands for the additive curvature. Furthermore, if $g(V) = \tilde{g}(V)|_{\Gamma_t(V)}$ with $\tilde{g}\in H(\Omega_t(V))$, then \textbf{(5.30)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [g'(V)\cdot W + (\nabla\tilde{g}(V)\cdot{\bf n} + Hg(V))\langle Z_t,{\bf n}\rangle]\,{\rm d}\Gamma.
		\end{align*}
	\end{itemize}
\end{theorem}

\paragraph{Adjoint transverse field.} It is possible to define the solution of the adjoint transverse system,

\begin{theorem}
	For $F\in L^2(0,T;(H^1(D))^d)$, there exists a unique field $\Lambda\in\mathcal{C}^0([0,T];(L^2(D))^d)$ solution of the backward dynamical system, \textbf{(5.31)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\Lambda - {\rm D}\Lambda\cdot V - {}^\star{\rm D}V\cdot\Lambda - (\nabla\cdot V)\Lambda &= F,&&(0,T),\\
			\Lambda(T) &= 0,
		\end{split}\right.
	\end{equation*}
\end{theorem}

\begin{remark}
	The field $\Lambda$ is the dual variable associated to the transverse field $Z_t$ \& is the solution of the adjoint problem associated to the transverse dynamical system.
\end{remark}
In this chapter, we shall deal with a specific RHS $F$ of the form $F(t) = {}^\star\gamma_{\Gamma^t(V)}(f(t){\bf n})$. In this case, the adjoint field $\Lambda$ is supported on the moving boundary $\Gamma_t(V)$ \& has the following structure,

\begin{theorem}[ref. 59]
	For $F(t) = {}^\star\gamma_{\Gamma^t(V)}(f(t){\bf n})$, with $f\in L^2(0,T;L^2(\Gamma_t(V)))$, the unique solution $\Lambda$ of the problem is given by the following identity, \textbf{(5.32)}
	\begin{align*}
		\Lambda = (\lambda\circ p)\nabla_{\chi_{\Omega_t}(V)}\in\mathcal{C}^0([0,T];(H^1(\Gamma_t))^d),
	\end{align*}
	where $\lambda\in\mathcal{C}^0([0,T];H^1(\Gamma_t))$ is the unique solution of the following boundary dynamical system, \textbf{(5.33)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T)\\
			\lambda(T) &= 0,&&\Gamma_t(V),
		\end{split}\right.
	\end{equation*}
	$p$ is the canonical projection on $\Gamma_t(V)$ \& $\chi_(\Omega_t)(V)$ is the characteristic function of $\Omega_t(V)$ inside $D$.
\end{theorem}

\paragraph{Gradient of non-cylindrical functionals.} In the next sections, we will often deal with boundary integrals of the following forms,
\begin{align*}
	K = \int_0^T\int_{\Gamma_t(V)} E\langle Z_t,{\bf n}\rangle
\end{align*}
with $E\in L^2(0,T;\Gamma_t(V))$ \& $Z_t$ is the solution of the transverse equation (5.22). The following result allows us to eliminate the auxiliary variable $Z_t$ inside the functional $K$,

\begin{theorem}[ref. 59]
	For any $E\in L^2(0,T;\Gamma_t(V))$ \& $(V,W)\in\mathcal{U}$, the following identity holds, \textbf{(5.34)}
	\begin{align*}
		\int_0^T\int_{\Gamma_t(V)} E\langle Z_t,{\bf n}\rangle = -\int_0^T\int_{\Gamma_t(V)} \lambda\langle W,{\bf n}\rangle,
	\end{align*}
	where $\lambda\in\mathcal{C}^0([0,T];H^1(\Gamma_t))$ is the unique solution of problem (5.33) with $f = E$.
\end{theorem}
'' -- \cite[Chap. 5, Subsect. 5.3.1, pp. 114--118]{Moubachir_Zolesio2006}

\subsection{Elements of tangential calculus}
``In this section, we review basic \textit{elements of differential calculus} on a $\mathcal{C}^k$-submanifold with $k\ge 2$ of codimension 1 in $\mathbb{R}^d$. The following approach avoids the use of local bases \& coordinates by using the intrinsic tangential derivative.'' -- \cite[Chap. 5, Sect. 5.4, pp. 119]{Moubachir_Zolesio2006}

\subsubsection{Oriented distance function}

%------------------------------------------------------------------------------%

\chapter{Topology Optimization}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}