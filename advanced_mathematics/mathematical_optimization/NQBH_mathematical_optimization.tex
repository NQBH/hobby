\documentclass[oneside]{book}
\usepackage[backend=biber,natbib=true,style=authoryear]{biblatex}
\addbibresource{/home/hong/1_NQBH/reference/bib.bib}
\usepackage[vietnamese,english]{babel}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,float,graphicx}
\allowdisplaybreaks
\numberwithin{equation}{section}
\newtheorem{assumption}{Assumption}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{definition}{Definition}[chapter]
\newtheorem{example}{Example}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{notation}{Notation}[chapter]
\newtheorem{principle}{Principle}[chapter]
\newtheorem{problem}{Problem}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{question}{Question}[chapter]
\newtheorem{remark}{Remark}[chapter]
\newtheorem{theorem}{Theorem}[chapter]
\usepackage[left=0.5in,right=0.5in,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\small \textsc{Sect.} ~\thesection}
\rhead{\small \nouppercase{\leftmark}}
\renewcommand{\sectionmark}[1]{\markboth{#1}{}}
\cfoot{\thepage}
\def\labelitemii{$\circ$}

\title{Some Topics in Mathematical Optimization}
\author{\selectlanguage{vietnamese} Nguyễn Quản Bá Hồng\footnote{Independent Researcher, Ben Tre City, Vietnam\\e-mail: \texttt{nguyenquanbahong@gmail.com}}}
\date{\today}

\begin{document}
\maketitle
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\tableofcontents

\chapter*{Foreword}

A collection of \& some personal notes on Mathematical Optimization, especially the 3 major topics: Optimal Control, Shape Optimization, \& Topology Optimization.

\textbf{Keywords.} Optimal control; Shape optimization; Topology optimization.

%------------------------------------------------------------------------------%

\chapter{Wikipedia's}

\section{\href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}Shape Optimization}}
``\textit{Shape optimization} is part of the field of \href{https://en.wikipedia.org/wiki/Optimal_control}{optimal control} theory. The typical problem is to find the \href{https://en.wikipedia.org/wiki/Shape}{shape} which is optimal in that it minimizes a certain cost \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} while satisfying given \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraints}. In many cases, the functional being solved depends on the solution of a given \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{PDE} defined on the variable domain.

\href{https://en.wikipedia.org/wiki/Topology_optimization}{Topology optimization} is, in addition, concerned with the number of connected components\texttt{/}boundaries belonging to the domain. Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them. Topological optimization techniques can then help work around the limitations of pure shape optimization.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}shape optimization}

\subsection{Definition}
``Mathematically, shape optimization can be posed as the problem of finding a \href{https://en.wikipedia.org/wiki/Bounded_set}{bounded set} $\Omega$, \href{https://en.wikipedia.org/wiki/Maxima_and_minima}{minimizing} a \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} $\mathcal{F}(\Omega)$, possibly subject to a \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraint} of the form $\mathcal{G}(\Omega) = 0$. Usually we are interested in sets $\Omega$ which are \href{https://en.wikipedia.org/wiki/Lipschitz_continuity}{Lipschitz} or $C^1$ \href{https://en.wikipedia.org/wiki/Boundary_(topology)}{boundary} \& consist of finite many \href{https://en.wikipedia.org/wiki/Connected_component_(analysis)}{components}, which is a way of saying that we would like to find a rather pleasing shape as a solution, \fbox{not some jumble of rough bits \& pieces}. Sometimes additional constraints need to be imposed to that end to ensure well-posedness of the problem \& uniqueness of the solution.

Shape optimization is an \href{https://en.wikipedia.org/wiki/Infinite-dimensional_optimization}{infinite-dimensional optimization} problem. Furthermore, the space of allowable shapes over which the optimization is performed does not admit a \href{https://en.wikipedia.org/wiki/Vector_space}{vector space} structure, making application of traditional optimization methods more difficult.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Definition}{Wikipedia\texttt{/}shape optimization\texttt{/}definition}

\subsection{Examples}
\begin{itemize}
	\item ``among all 3D shapes of given volume, find the one which has minimal surface area. Here: $\mathcal{F}(\Omega) = \operatorname{Area}(\partial\Omega)$, with $\mathcal{G}(\Omega) = \operatorname{Volume}(\Omega) = {\rm const}$. The answer, given by the \href{https://en.wikipedia.org/wiki/Isoperimetric_inequality}{isoperimetric inequality}, is a \href{https://en.wikipedia.org/wiki/Ball_(mathematics)}{ball}.
	\item Find the shape of an airplane wing which minimizes \href{https://en.wikipedia.org/wiki/Drag_(physics)}{drag}. Here the constraints could be the wing strength, or the wing dimensions.
	\item Find the shape of various mechanical structures, which can resist a given \href{https://en.wikipedia.org/wiki/Stress_(physics)}{stress} while having a minimal mass\texttt{/}volume.
	\item Given a known 3D object with a fixed radiation source inside, deduce the shape \& size of the source based on measurements done on part of the boundary of the object. A formulation of this \href{https://en.wikipedia.org/wiki/Inverse_problem}{inverse problem} using \href{https://en.wikipedia.org/wiki/Least-squares}{least squares} fit leads to a shape optimization problem.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Examples}{Wikipedia\texttt{/}shape optimization\texttt{/}examples}
\end{itemize}

\subsection{Techniques}
``Shape optimization problems are usually solved \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerically}, by using \href{https://en.wikipedia.org/wiki/Iterative_method}{iterative methods}. I.e., one starts with an initial guess for a shape, \& then gradually evolves it, until it morphs into the optimal shape.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Techniques}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques}

\subsubsection{Keeping track of the shape}
\textsf{Fig. Example: Shape optimization as applied to building geometry. Example provided courtesy of \url{Formsolver.com}.}

``To solve a shape optimization problem, one needs to find a way to represent a shape in the \href{https://en.wikipedia.org/wiki/Computer_memory}{computer memory}, \& follow its evolution. Several approaches are usually used.

1 approach is to follow the boundary of the shape. For that, one can sample the shape boundary in a relatively dense \& uniform manner, i.e., to consider enough points to get a sufficiently accurate outline of the shape. Then, one can evolve the shape by gradually moving the boundary points. This is called the \textit{Lagrangian approach}.

Another approach is to consider a \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} defined on a rectangular box around the shape, which is positive inside of the shape, zero on the boundary of the shape, \& negative outside of the shape. One can then evolve this function instead of the shape itself. One can consider a rectangular grid on the box \& sample the function at the grid points. As the shape evolves, the grid points do not change; only the function values at the grid points change. This approach, of using a fixed grid, is called the \textit{Eulerian approach}. The idea of using a function to represent the shape is at the basis of the \href{https://en.wikipedia.org/wiki/Level-set_method}{level set method}.

\textsf{Fig. Example: Optimization shape families resulting from differing goal parameters. Example provided courtesy of \url{Formsolver.com}}

A 3rd approach is to \fbox{think of the shape evolution as of a flow problem}. I.e., one can imagine that the shape is made of a plastic material gradually deforming s.t. any point inside or on the boundary of the shape can be always traced back to a point of the original shape in a 1-1 fashion. Mathematically, if $\Omega_0$ is the initial shape, \& $\Omega_t$ is the shape at time $t$, one considers the \href{https://en.wikipedia.org/wiki/Diffeomorphism}{diffeomorphisms} $f_t:\Omega_0\to\Omega_t$, for $t\le t\le t_0$. The idea is again that shapes are difficult entities to be dealt with directly, so manipulate them by means of a function.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Keeping_track_of_the_shape}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}keeping track of the shape}

\subsubsection{Iterative methods using shape gradients}
``Consider a smooth velocity field $V$ \& the family of transformations $T_s$ of the initial domain $\Omega_0$ under the velocity field $V$: $x(0) = x_0\in\Omega_0$, $x'(s) = V(x(s))$, $T_s(x_0) = x(s)$, $s\ge 0$, \& denote $\Omega_0\mapsto T_s(\Omega_0) = \Omega_s$. Then the G\^ateaux or shape derivative of $\mathcal{F}(\Omega)$ at $\Omega_0$ w.r.t. the shape is the limit of
\begin{align*}
	d\mathcal{F}(\Omega_0;V) = \lim_{s\to 0} \frac{\mathcal{F}(\Omega_s) - \mathcal{F}(\Omega_0)}{s}
\end{align*}
if this limit exists. If in addition the derivative is linear w.r.t. $V$, there is a unique element of $\nabla\mathcal{F}\in L^2(\partial\Omega)$ \& $d\mathcal{F}(\Omega_0;V) = \langle\nabla\mathcal{F},V\rangle_{\partial\Omega_0}$ where $\nabla\mathcal{F}$ is called the \textit{shape gradient}. This gives a natural idea of \href{https://en.wikipedia.org/wiki/Gradient_descent}{gradient descent}, where the boundary $\partial\Omega$ is evolved in the direction of negative shape gradient in order to reduce the value of the cost functional. Higher order derivatives can be similarly defined, leading to Newtonlike methods.

Typically, gradient descent is preferred, even if requires a large number of iterations, because, it can be hard to compute the 2nd-order derivative (i.e., the \href{https://en.wikipedia.org/wiki/Hessian_matrix}{Hessian}) of the objective functional $\mathcal{F}$.

If the shape optimization problem has constrains, i.e., the functional $\mathcal{G}$ is present, one has to find ways to convert the constrained problem into an unconstrained one. Sometimes ideas based on \href{https://en.wikipedia.org/wiki/Lagrange_multipliers}{Lagrange multipliers}, like the \href{https://en.wikipedia.org/wiki/Adjoint_state_method}{adjoint state method}, can work.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Iterative_methods_using_shape_gradients}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}iterative methods using shape gradients}

\subsubsection{Geometry parametrization}
``Shape optimization can be faced using standard optimization methods if a parametrization of the geometry is defined. Such parametrization is very important in CAE field where goal functions are usually complex functions evaluated using numerical models (CFD, FEA, $\ldots$). A convenient approach, suitable for a wide class of problems, consists in the paramtrization of the CAD model coupled with a full automation of all the process required for function evaluation (meshing, solving \& result processing). \textit{Mesh morphing} is a valid choice for complex problems that resolves typical issues associated with \textit{re-meshing} such as discontinuities in the computed objective \& constraint functions. In this case the parametrization is defined after the meshing stage acting directly on the numerical model used for calculation that is changed using mesh updating methods. There are several algorithms available for mesh morphing (\textit{deforming volumes, pseudosolids}, \href{https://en.wikipedia.org/wiki/Radial_basis_function}{radical basis functions}). The selection of the parametrization approach depends mainly on the size of the problem: the CAD approach is preferred for small-to-medium sized models whilst the mesh morphing approach is the best (\& sometimes the only feasible one) for large \& very large models. The multi-objective Pareto optimization (NSGA II) could be utilized as a powerful approach for shape optimization. In this regard, the Pareto optimization approach displays useful advantages in design method such as the effect of area constraint that other multi-objective optimization cannot declare it. The approach of using a penalty function is an effective technique which could be used in the 1st stage of optimization. In this method the constrained shape design problem is adapted to an unconstrained problem with utilizing the constraints in the objective function as a penalty factor. Most of the time penalty factor is dependent to the amount of constraint variation rather than constrain number. The GA real-coded technique is applied in the present optimization problem. Therefore, the calculations are based on real value of variables.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Geometry_parametrization}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}geometry parametrization}

%------------------------------------------------------------------------------%

\section{\href{https://en.wikipedia.org/wiki/Topology_optimization}{Wikipedia\texttt{/}Topology Optimization}}
``\textit{Topology optimization (TO)} is a mathematical method that optimizes material layout within a given design space, for a given set of \href{https://en.wikipedia.org/wiki/Structural_load}{loads}, \href{https://en.wikipedia.org/wiki/Boundary_conditions}{boundary conditions} \& \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraints} with the goal of maximizing the performance of the system. Topology optimization is different from \href{https://en.wikipedia.org/wiki/Shape_optimization}{shape optimization} \& sizing optimization in the sense that the design can attain any shape within the design space, instead of dealing with predefined configurations.

The conventional topology optimization formulation uses a \href{https://en.wikipedia.org/wiki/Finite_element_method}{FEM} to evaluate the design performance. The design is optimized using either gradient-based \href{https://en.wikipedia.org/wiki/Mathematical_programming}{mathematical programming} techniques such as the optimality criteria algorithm \& the \textit{method of moving asymptotes} or non gradient-based algorithms such as \href{https://en.wikipedia.org/wiki/Genetic_algorithms}{genetic algorithms}.

Topology optimization has a wide range of applications in aerospace, mechanical, bio-chemical \& civil engineering. Currently, engineers mostly use topology optimization at the concept level of a \href{https://en.wikipedia.org/wiki/Engineering_design_process}{design process}. Due to the free forms that naturally occur, the result is often difficult to manufacture. For that reason the result emerging from topology optimization is often fine-tuned for manufacturability. Adding constraints to the formulation in order to \href{https://en.wikipedia.org/wiki/Design_for_manufacturability}{increase the manufacturability} is an active field of research. In some cases results from topology optimization can be directly manufactured using \href{https://en.wikipedia.org/wiki/Additive_manufacturing}{additive manufacturing}; topology optimization is thus a key part of \href{https://en.wikipedia.org/wiki/Design_for_additive_manufacturing}{design for additive manufacturing}.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization}{Wikipedia\texttt{/}topology optimization}

\subsection{Problem statement}
``A topology optimization problem can be written in the general form of an \href{https://en.wikipedia.org/wiki/Optimization_problem}{optimization problem} as
\begin{align*}
	\min_\rho F\mbox{ where } F = F({\bf u}(\rho),\rho) = \int_\Omega f({\bf u}(\rho),\rho)\,{\rm d}V\mbox{ subject to } G_0(\rho) = \int_\Omega \rho\,{\rm d}V - V_0\le 0,\ G_j({\bf u}(\rho),\rho)\le 0,\ j = 1,\ldots,m.
\end{align*}
The problem statement includes the following:
\begin{itemize}
	\item An \href{https://en.wikipedia.org/wiki/Objective_function}{objective function} $F({\bf u}(\rho),\rho)$. This function represents the quantity that is being minimized for best performance. The most common objective function is compliance, where minimizing compliance leads to maximizing the stiffness of a structure.
	\item The \textit{material distribution} as a problem variable. This is described by the density of the material at each location $\rho({\bf x})$. Material is either \textit{present}, indicated by a 1, or \textit{absent}, indicated by a 0. ${\bf u} = {\bf u}(\rho)$ is a state field that satisfies a linear or nonlinear state equation depending on $\rho$.
	\item The \textit{design space} $(\Omega)$. This indicates the allowable volume within which the design can exist. Assembly \& packaging requirements, human \& tool accessibility are some of the factors that need to be considered in identifying this space. With the definition of the design space, regions or components in the model that cannot be modified during the course of the optimization are considered as non-design regions.
	\item $m$ \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{contraints} $G_j({\bf u}(\rho),\rho)\le 0$ a characteristic that the solution must satisfy. Examples are the maximum amount of material to be distributed (volume constraint) or maximum stress values.
\end{itemize}
Evaluating ${\bf u}(\rho)$ often includes solving a differential equation. This is most commonly done using the FEM since these equations do not have a known analytical solution.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Problem_statement}{Wikipedia\texttt{/}topology optimization\texttt{/}problem statement}

\subsection{Implementation methodologies}
``There are various implementation methodologies that have been used to solve topology optimization problems.''

\subsubsection{Discrete}
``Solving topology optimization problems in a discrete sense is done by discretizing the design domain into finite elements. The material densities inside these elements are then treated as the problem variables. In this case material density of 1 indicates the presence of material, while 0 indicates an absence of material. Owning to the attainable topological complexity of the design being dependent on the number of elements, a large number is preferred. Large numbers of finite elements increases the attainable topological complexity, but come at a cost. 1stly, solving the FEM systems becomes more expensive. 2ndly, algorithms that can handle a large number (several thousands of elements is not uncommon) of discrete variables with multiple constraints are unavailable. Moreover, they are impractically sensitive to parameter variations. In literature problems with up to 30000 variables have been reported.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Discrete}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}discrete}

\subsubsection{Solving the problem with continuous variables}
``The earlier stated complexities with solving topology optimization problems using binary variables has caused the community to search for other options. One is the modeling of the densities with continuous variables. The material densities can now also attain values between 0 \& 1. Gradient based algorithms that handle large amounts of continuous variables \& multiple constraints are available. But the material properties have to be modeled in a continuous setting. This is done through interpolation. 1 of the most implemented interpolation methodologies is the \textit{Solid Isotropic Material with Penalization} method (SIMP). This interpolation is essentially a power law $E = E_0 + \rho^p(E_1 - E_0)$. It interpolates the Young's modulus of the material to the scalar selection field. The value of the penalization parameter $p$ is generally taken between $[1,3]$. This has been shown to confirm the micro-structure of the materials. In the SIMP method a lower bound on the Young's modulus is added, $E_0$, to make sure the derivatives of the objective function are nonzero when the density becomes 0. The higher the penalization factor, the more SIMP penalizes the algorithm in the use of non-binary densities. Unfortunately, the penalization parameter also introduces non-convexities.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Solving_the_problem_with_continuous_variables}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}solving the problem with continuous variables}

\subsubsection{Shape derivatives}
``Topology optimization can be achieved by using shape derivatives.'' 

\subsubsection{Topological derivatives}

\subsubsection{Level set}

\subsubsection{Phase field}

\subsubsection{Evolutionary structural optimization}

\subsubsection{Commercial software}
``There are several commercial topology optimization software on the market. Most of them use topology optimization as a hint how the optimal design should look like, \& manual geometry re-construction is required. There are a few solutions which produce optimal designs ready for Additive Manufacturing.'' -- -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Commercial_software}{Wikipedia\texttt{/}topology optimization\texttt{/}implementation methodologies\texttt{/}commercial software}

\subsection{Examples}

\subsubsection{Structural compliance}
\textsf{Fig. Checker Board Patterns are shown in this result.} \textsf{Fig. Topology optimization result when filtering is used.} \textsf{Fig. Topology optimization of a compliance problem.}

``A stiff structure is one that has the least possible displacement when given certain set of boundary conditions. A global measure of the displacements is the \href{https://en.wikipedia.org/wiki/Strain_energy}{strain energy} (also called \href{https://en.wikipedia.org/wiki/Stiffness#Compliance}{compliance}) of the structure under the prescribed boundary conditions. The lower the strain energy the higher the stiffness of the structure. So, the objective function of the problem is to minimize the strain energy.

On a broad level, one can visualize that the more the material, the less the deflection\footnote{\textbf{deflection} [n] [uncountable, countable, usually singular] \textbf{deflection (of something)} a sudden change in the direction that something is moving in, usually after it has hit something; the act of causing something to change direction.} as there will be more material to resit the loads. So, the optimization requires an opposing constraint, the volume constraint. This is in reality a cost factor, as we would not want to spend a lot of money on the material. To obtain the total material utilized, an integration of the selection field over the volume can be done.

Finally the elasticity governing differential equations are plugged in so as to get the final problem statement.
\begin{align*}
	\min_\rho \int_\Omega \frac{1}{2}\boldsymbol{\sigma}:\boldsymbol{\varepsilon}\,{\rm d}\Omega\mbox{ subject to }\rho\in[0,1],\ \int_\Omega \rho\,{\rm d}\Omega\le V^\star,\ \nabla\cdot\boldsymbol{\sigma} + {\bf F} = {\bf 0},\ \boldsymbol{\sigma} = {\bf C}:\boldsymbol{\varepsilon}.
\end{align*}
But, a straightforward implementation in the finite element framework of such a problem is still infeasible\footnote{\textbf{unfeasible} [a] not possible to do or achieve, \textsc{opposite}: \textbf{feasible}.} owning to issues such as:
\begin{itemize}
	\item \textbf{Mesh dependency} i.e., the design obtained on 1 mesh is not the one that will be obtained on another mesh. The features of the design become more intricate\footnote{\textbf{intricate} [a] having a lot of different parts \& small details that fit together.} as the mesh gets refined.
	\item \textbf{Numerical instabilities.} The selection of region in the form of a chess board. 
\end{itemize}
Some techniques such as \href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{filtering} based on image processing are currently being used to alleviate\footnote{\textbf{alleviate} [v] \textbf{alleviate something} to make suffering or a problem less severe.} some of these issues. Although it seemed like this was purely a heuristic approach for a long time, theoretical connections to nonlocal elasticity have been made to support the physical sense of these methods.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Structural_compliance}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}structural compliance}

\subsubsection{Multiphysics problems}

\paragraph{Fluid-structure-interaction.} ``\href{https://en.wikipedia.org/wiki/Fluid%E2%80%93structure_interaction}{Fluid-structure-interaction} is a strongly coupled phenomenon \& concerns the interaction between a stationary or moving fluid \& an elastic structure. Many engineering applications \& natural phenomenon are subject to fluid-structure interaction \& to take such effects into consideration is therefore critical in the design of many engineering applications. Topology optimization for fluid structure interaction problems has been studied. Design solutions solved for different Reynolds numbers are shown below. The design solutions depend on the fluid flow with indicate that the coupling between the fluid \& the structure is resolved in the design problems.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Fluid-structure-interaction}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}multiphysics problems\texttt{/}fluid-structure-interaction}

\textsf{Fig. Design solutions for different Reynolds number for a wall inserted in a channel with a moving fluid.} \textsf{Fig. Sketch fo the well-known wall problem. The objective of the design problem is to minimize the structural compliance.} \textsf{Fig. Design evolution for a fluid-structure-interaction problem. The objective of the design problem is to minimize the structural compliance. The fluid-structure-interaction problem is modeled with Navier--Cauchy \& NSEs.}

\paragraph{Thermoelectric energy conversion.} ``\href{https://en.wikipedia.org/wiki/Thermoelectric_effect}{Thermoelectricity} is a multi-physic problem which concerns the interaction \& coupling between electric \& thermal energy in semi conducting materials. Thermoelectric energy conversion can be described by 2 separately identified effects: The Seebeck effect \& the Peltier effect. The Seebeck effect concerns the conversion of thermal energy into electric energy \& the Peltier effect concerns the conversion of electric energy into thermal energy. By spatially distributing 2 thermoelectric materials in a 2D design space with a topology optimization methodology, it is possible to exceed performance of the constitutive thermoelectric materials for \href{https://en.wikipedia.org/wiki/Thermoelectric_cooling}{thermoelectric coolers} \& \href{https://en.wikipedia.org/wiki/Thermoelectric_generator}{thermoelectric generators}.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Thermoelectric_energy_conversion}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}multiphysics problems\texttt{/}thermoelectric energy conversion}

\subsubsection{3F3D Form Follows Force 3D Printing}
``The current proliferation\footnote{\textbf{proliferation} [n] \textbf{1.} [uncountable, singular] \textbf{proliferation (of something)} a rapid increase in the number or amount of something; a large number of a particular thing; \textbf{2.} [uncountable] (\textit{biology}) the rapid reproduction of a cell, part or organism.} of 3D printer technology has allowed designers \& engineers to use topology optimization techniques when designing new products. Topology optimization combined with 3D printing can result in less weight, improved structural performance \& shortened design-to-manufacturing cycle. As the designs, while efficient, might not be realizable with more traditional manufacturing techniques.'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#3F3D_Form_Follows_Force_3D_Printing}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}3F3D Form Follows Force 3D Printing}

\subsubsection{Design-dependent loads}
``The direction, magnitude, \& location of a design-dependent load alter with topology optimization iterations. Therefore, dealing with such loads in a TO setting is a challenging task. One can find novel methods to deal with such loads (e.g. pressure load, self-weight, etc.).'' -- \href{https://en.wikipedia.org/wiki/Topology_optimization#Design-dependent_loads}{Wikipedia\texttt{/}topology optimization\texttt{/}examples\texttt{/}design-dependent loads}

\textsf{Fig. A sketch of the design problem. The aim of the design problem is to spatially distribute 2 materials, Material A \& Material B, to maximize a performance measure such as cooling power or electric power output.} \textsf{Fig. Design evolution for an off-diagonal thermoelectric generator. The design solution of an optimization problem solved for electric power output. The performance of the device has been optimized by distributing \href{https://en.wikipedia.org/wiki/Skutterudite}{Skutterudite} (yellow) \& \href{https://en.wikipedia.org/wiki/Bismuth_telluride}{bismuth telluride} (blue) with a density-based topology optimization methodology. The aim of the optimization problem is to maximize the electric power output of the thermoelectric generator.} \textsf{Fig. Design evolution for a thermoelectric cooler. The aim of the design problem is to maximize the cooling power of the thermoelectric cooler.}

%------------------------------------------------------------------------------%

\section{\href{https://en.wikipedia.org/wiki/Water_supply_network}{Wikipedia\texttt{/}Water Supply Network}}
``A \textit{water supply network} or \textit{water supply system} is a system of engineered \href{https://en.wikipedia.org/wiki/Hydrologic}{hydrologic} \& \href{https://en.wikipedia.org/wiki/Hydraulic}{hydraulic} components that provide \href{https://en.wikipedia.org/wiki/Water_supply}{water supply}. A water supply system typically includes the following:
\begin{enumerate}
	\item A \href{https://en.wikipedia.org/wiki/Drainage_basin}{drainage basin} (see \href{https://en.wikipedia.org/wiki/Water_purification#Sources_of_drinking_water}{water purification -- sources of drinking water})
	\item A \href{https://en.wikipedia.org/wiki/Raw_water}{raw water} collection point (above or below ground) where the water accumulates, such as a \href{https://en.wikipedia.org/wiki/Lake}{lake}, a \href{https://en.wikipedia.org/wiki/River}{river}, or \href{https://en.wikipedia.org/wiki/Groundwater}{groundwater} from an \href{https://en.wikipedia.org/wiki/Underground_aquifer}{underground aquifer}. Raw water may be transferred using uncovered ground-level \href{https://en.wikipedia.org/wiki/Aqueduct_(watercourse)}{aqueducts}, covered \href{https://en.wikipedia.org/wiki/Tunnel}{tunnels}, or underground \href{https://en.wikipedia.org/wiki/Water_pipes}{water pipes} to water purification facilities.
	\item \href{https://en.wikipedia.org/wiki/Water_purification}{Water purification} facilities. Treated water is transferred using \href{https://en.wikipedia.org/wiki/Water_pipes}{water pipes} (usually underground).
	\item Water storage facilities such as \href{https://en.wikipedia.org/wiki/Reservoirs}{reservoirs}, \href{https://en.wikipedia.org/wiki/Water_tank}{water tanks}, or \href{https://en.wikipedia.org/wiki/Water_tower}{water towers}. Smaller water systems may store the water in \href{https://en.wikipedia.org/wiki/Cisterns}{cisterns} or \href{https://en.wikipedia.org/wiki/Pressure_vessel}{pressure vessels}. Tall buildings may also need to store water locally in pressure vessels in order for the water to reach the upper floors.
	\item Additional water pressurizing components such as \href{https://en.wikipedia.org/wiki/Pumping_station}{pumping stations} may need to be situated at the outlet of underground or aboveground reservoirs or cisterns (if gravity flow is impractical).
	\item A pipe network for distribution of water to consumers (which may be private houses or industrial, commercial, or institution establishments) \& other usage points (such as \href{https://en.wikipedia.org/wiki/Fire_hydrant}{fire hydrants})
	\item Connections to the \href{https://en.wikipedia.org/wiki/Sanitary_sewer}{sewers} (underground pipes, or aboveground \href{https://en.wikipedia.org/wiki/Ditch}{ditches} in some developing countries) are generally found downstream of the water consumers, but the sewer system is considered to be a separate system, rather than part of the water supply system.
\end{enumerate}
Water supply networks are often run by \href{https://en.wikipedia.org/wiki/Public_utility}{public utilities} of the \href{https://en.wikipedia.org/wiki/Water_industry}{water industry}.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network}{Wikipedia\texttt{/}water supply network}

\subsection{Water abstraction \& raw water transfer}
``\href{https://en.wikipedia.org/wiki/Raw_water}{Raw water} (untreated) is from a \href{https://en.wikipedia.org/wiki/Surface_water}{surface water} source (such as an intake on a \href{https://en.wikipedia.org/wiki/Lake}{lake} or a \href{https://en.wikipedia.org/wiki/River}{river}) or from a \href{https://en.wikipedia.org/wiki/Groundwater}{groundwater} source (such as a \href{https://en.wikipedia.org/wiki/Water_well}{water well} drawing from an underground \href{https://en.wikipedia.org/wiki/Aquifer}{aquifer}) within the \href{https://en.wikipedia.org/wiki/Drainage_basin}{watershed} that provides the \href{https://en.wikipedia.org/wiki/Water_resource}{water resources}.

The raw water is transferred to the water purification facilities using uncovered aqueducts, covered tunnels or underground \href{https://en.wikipedia.org/wiki/Water_pipes}{water pipes}.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Water_abstraction_and_raw_water_transfer}{Wikipedia\texttt{/}water supply network\texttt{/}water abstraction \& raw water transfer}

\subsection{Water treatment}
``Main article: \href{https://en.wikipedia.org/wiki/Water_treatment}{Wikipedia\texttt{/}water treatment}. Virtually all large systems must treat the water; a fact that is tightly regulated by global, state \& federal agencies, such as the \href{https://en.wikipedia.org/wiki/World_Health_Organization}{World Health Organization} (WHO) or the \href{https://en.wikipedia.org/wiki/United_States_Environmental_Protection_Agency}{United States Environmental Protection Agency} (EPA). Water treatment must occur before the product reaches the consumer \& afterwards (when it is discharged again). Water purification usually occurs close to the final delivery points to reduce pumping costs \& the chances of the water becoming contaminated after treatment.

Traditional surface water treatment plants generally consists of 3 steps: clarification, filtration \& disinfection. Clarification refers to the separation of particles (dirt, organic matter, etc.) from the water stream. Chemical addition (i.e., alum, ferric chloride) destabilizes the particle charges \& prepares them for clarification either by setting or floating out of the water stream. Sand, anthracite or activated carbon filters refine the water stream, removing smaller particulate matter. While other methods of disinfection exist, the preferred method is via chroline addition. Chlorine effectively kills bacteria \& most viruses \& maintains a residual to protect the water supply through the supply network.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Water_treatment}{Wikipedia\texttt{/}water supply network\texttt{/}water treatment}

\subsection{Water distribution network}
\textsf{Fig. USA Not Combined City Water System.} ``Main article: \href{https://en.wikipedia.org/wiki/Water_distribution_system}{Wikipedia\texttt{/}water distribution system}. The product, delivered to the point of consumption, is called \href{https://en.wikipedia.org/wiki/Potable_water}{potable water} if it meets the \href{https://en.wikipedia.org/wiki/Water_quality}{water quality} standards required for human consumption.

The water in the supply network is maintained at positive \href{https://en.wikipedia.org/wiki/Pressure}{pressure} to ensure that water reaches all parts of the network, that a sufficient flow is available at every take-off point \& to ensure that untreated water in the ground cannot enter the network. The water is typically pressurized by pumping the water into storage tanks constructed at the highest local point in the network. 1 network may have several such \href{https://en.wikipedia.org/wiki/Service_reservoir}{service reservoirs}.

In small domestic systems, the water may be pressurized by a \href{https://en.wikipedia.org/wiki/Pressure_vessel}{pressure vessel} or even by an \href{https://en.wikipedia.org/wiki/Water_well}{underground cistern} (the latter however does need additional pressurizing). This eliminates the need of a water-tower or any other heightened water reserve to supply the water pressure.

These systems are usually owned \& maintained by local governments, such as cities, or other public entities, but are occasionally operated by a commercial enterprise (see \href{https://en.wikipedia.org/wiki/Water_privatization}{water privatization}). Water supply networks are part of the master planning of communities, counties, \& municipalities. Their planning \& design requires the expertise of \href{https://en.wikipedia.org/wiki/Urban_planner}{city planners} \& \href{https://en.wikipedia.org/wiki/Civil_engineering}{civil engineers}, who must consider many factors, such as location, current demand, further growth, leakage, pressure, pipe size, pressure loss, fire fighting flows, etc. -- using \href{https://en.wikipedia.org/wiki/Pipe_network_analysis}{pipe network analysis} \& other tools.

As water passes through the distribution system, the water quality can degrade by chemical reactions \& biological processes. \href{https://en.wikipedia.org/wiki/Corrosion}{Corrosion} of metal pipe materials in the distribution system can cause the release of metals into the water with undesirable aesthetic \& health effects. Release of \href{https://en.wikipedia.org/wiki/Iron}{iron} from unlined iron pipes can result in customer reports of ``red water'' at the tap. Release of \href{https://en.wikipedia.org/wiki/Copper}{copper} from \href{https://en.wikipedia.org/wiki/Domestic_water_system}{copper pipes} can result in customer reports of ``blue water'' \&\texttt{/}or a metallic taste. Release of \href{https://en.wikipedia.org/wiki/Lead}{lead} can occur from the \href{https://en.wikipedia.org/wiki/Solder}{solder} used to join copper pipe together or from \href{https://en.wikipedia.org/wiki/Brass}{brass} \href{https://en.wikipedia.org/wiki/Plumbing_fixture}{fixtures}. Copper \& lead levels at the consumer's tap are regulated to protect consumer health.

Utilities will often adjust the chemistry of the water before distribution to minimize its corrosiveness. The simplest adjustment involves control of \href{https://en.wikipedia.org/wiki/PH}{pH} \& \href{https://en.wikipedia.org/wiki/Alkalinity}{alkalinity} to produce a water that tends to passivate corrosion by depositing a layer of \href{https://en.wikipedia.org/wiki/Calcium_carbonate}{calcium carbonate}. \href{https://en.wikipedia.org/wiki/Corrosion_inhibitors}{Corrosion inhibitors} are often added to reduce release of metals into the water. Common corrosion inhibitors added to the water are \href{https://en.wikipedia.org/wiki/Phosphates}{phosphates} \& \href{https://en.wikipedia.org/wiki/Silicates}{silicates}.

Maintenance of a biologically safe drinking water is another goal in water distribution. Typically, a chlorine based \href{https://en.wikipedia.org/wiki/Disinfectant}{disinfectant}, such as \href{https://en.wikipedia.org/wiki/Sodium_hypochlorite}{sodium hypochlorite} or \href{https://en.wikipedia.org/wiki/Monochloramine}{monochloramine} is added to the water as it leaves the treatment plant. Booster stations can be placed within the distribution system to ensure that all areas of the distribution system have adequate sustained levels of \href{https://en.wikipedia.org/wiki/Disinfection}{disinfection}.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Water_distribution_network}{Wikipedia\texttt{/}water supply network\texttt{/}water distribution network}

\textsf{Fig. The \href{https://en.wikipedia.org/wiki/Central_Arizona_Project_Aqueduct}{Central Arizona Project Aqueduct} transfers untreated water.} \textsf{Fig. Most (treated) water distribution happens through underground pipes.} \textsf{Fig. Pressurizing the water is required between the small water reserve \& the end-user.}

\subsubsection{Topologies}
``Like electric power lines, roads, \& microwave radio networks, water systems may have a \href{https://en.wikipedia.org/wiki/Loop_(graph_theory)}{loop} or \href{https://en.wikipedia.org/wiki/Graph_theory}{branch} network topology, or a combination of both. The piping networks are circular or rectangular. If any 1 section of water distribution main fails or needs repair, that section can be isolated without disrupting all users on the network.

Most systems are divided into zones. Factors determining the extent or size of a zone can include hydraulics, \href{https://en.wikipedia.org/wiki/Telemetry#Water_management}{telemetry} systems, history, \& population density. Sometimes systems are designed for a specific area then are modified to accommodate development. Terrain affects hydraulics \& some forms of telemetry. While each zone may operate as a stand-alone system, there is usually some arrangements to interconnect zones in order to manage equipment failures or system failures.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Topologies}{Wikipedia\texttt{/}water supply network\texttt{/}water distribution network\texttt{/}topologies}

\subsection{Water network maintenance}
``Water supply networks usually represent the majority of assets of a water utility. Systematic documentation of maintenance works using a \href{https://en.wikipedia.org/wiki/Computerized_maintenance_management_system}{computerized maintenance management system} (CMMS) is a key to a successful operation of a water utility.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Water_network_maintenance}{Wikipedia\texttt{/}water supply network\texttt{/}water network maintenance}

\subsection{Sustainable urban water supply}

\subsubsection{Population growth}

\subsubsection{Water scarcity}

\subsubsection{Governmental issues}

\subsection{Optimizing the water supply network}
``The yield of a system can be measured by either its value or its net benefit. For a water supply system, the true value or the net benefit is a reliable water supply service having adequate quantity \& good quality of the product. E.g., if the existing water supply of a city needs to be extended to supply a new \href{https://en.wikipedia.org/wiki/Municipality}{municipality}, the impact of the new branch of the system must be designed to supply the new needs, while maintaining supply to the old system.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Optimizing_the_water_supply_network}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network}

\subsubsection{Single-objective optimization}
``The design of a system is governed by multiple criteria, one being cost. If the benefit is \textit{fixed}, the \href{https://en.wikipedia.org/wiki/Least-cost_routing}{least cost} design results in maximum benefit. However, the least cost approach normally results in a \textit{minimum capacity} for a water supply network. A minimum cost model usually searches for the least cost solution (in pipe sizes), while satisfying the hydraulic constraints such as: required output pressures, maximum \href{https://en.wikipedia.org/wiki/Pipe_flow}{pipe flow} rate \& pipe flow velocities. The cost is a function of pipe diameters; therefore the \href{https://en.wikipedia.org/wiki/Process_optimization}{optimization} problem consists of finding a minimum cost solution by optimizing pipe sizes to provide the minimum acceptable capacity.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Single-objective_optimization}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}single-objective optimization} 

\subsubsection{Multi-objective optimization}
``However, according to the authors of the paper entitled, ``Method for optimizing design \& rehabilitation of water distribution systems'', ``the least capacity is not a desirable solution to a sustainable water supply network in a long term, due to the uncertainty of the future demand''. It is preferable to provide extra pipe capacity to cope with unexpected demand growth \& with water outages. The problem changes from a single objective optimization problem (minimizing cost), to a multi-objective optimization problem (minimizing cost \& maximizing flow capacity).'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Multi-objective_optimization}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}multi-objective optimization}

\subsubsection{Weighted sum method}
``To solve a multi-objective optimization problem, it is necessary to convert the problem into a single objective optimization problem, by using adjustments, such as a weighted sum of \href{https://en.wikipedia.org/wiki/Goal}{objectives}, or an $\varepsilon$-constraint method. The weighted sum approach gives a certain weight to the different objectives, \& then factors in all these weights to form a single objective function that can be solved by single factor optimization. This method is not entirely satisfactory, because the weights cannot be correctly chosen, so this approach cannot find the optimal solution for all the original objectives.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Weighted_sum_method}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}weighted sum method}

\subsubsection{The constraint method}
``The 2nd approach (the constraint method), chooses 1 of the objective functions as the single objective, \& the other objective functions are treated as constraints with a limited value. However, the optimal solution depends on the pre-defined constraints limits.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#The_constraint_method}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}the constraint method}

\subsubsection{Sensitivity analysis}
``The multiple objective optimization problems involve computing the \href{https://en.wikipedia.org/wiki/Tradeoff}{tradeoff} between the costs \& benefits resulting in a set of solutions that can be used for sensitivity analysis \& tested in different scenarios. But there is no single optimal solution that will satisfy the global optimality of both objectives. As both objectives are to some extent contradictory, it is not possible to improve 1 objective without sacrificing the other. It is necessary in some cases use a different approach. (e.g., \href{https://en.wikipedia.org/wiki/Pareto_analysis}{Pareto Analysis}), \& choose  the best combination.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Sensitivity_analysis}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}sensitivity analysis}

\subsubsection{Operational constraints}
``Returning to the cost objective function, it cannot violate any of the operational constraints. Generally this cost is dominated by the energy cost for pumping. ``The operational constraints include the standards of \href{https://en.wikipedia.org/wiki/Customer_service}{customer service}, such as: the minimum delivered pressure, in addition to the physical constraints such as the maximum \& the minimum water levels in storage tanks to prevent overtopping \& emptying respectively.''

In order to optimize the operational performance of the water supply network, at the same time as minimizing the energy costs, it is necessary to predict the consequences of different pump \& valve settings on the behavior of the network.

Apart from Linear \& Nonlinear Programming, there are other methods \& approaches to design, to manage \& operate a water supply network to achieve sustainability -- e.g., the adoption of \href{https://en.wikipedia.org/wiki/Appropriate_technology}{appropriate technology} coupled with effective strategies for operation \& maintenance. These strategies must include effective management models, technical support to the householders \& industries, sustainable financing mechanisms, \& development of reliable \href{https://en.wikipedia.org/wiki/Supply_chain}{supply chains}. All these measures must ensure the following: system working lifespan; maintenance cycle; continuity of functioning; down time for repairs; water yield \& water quality.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Operational_constraints}{Wikipedia\texttt{/}water supply network\texttt{/}optimizing the water supply network\texttt{/}operational constraints}

\subsection{Sustainable development}

\subsection{Future approaches}
``There is great need for a more sustainable water supply systems. To achieve sustainability several factors must be tackled at the same time: climate change, rising energy cost, \& rising populations. All of these factors provoke change \& put pressure on management of available water resources.

An obstacle to transforming conventional water supply systems, is the amount of time needed to achieve the transformation. More specifically, transformation must be implemented by municipal \href{https://en.wikipedia.org/wiki/Legislation}{legislation} bodies, which always need short-term solutions too. Another obstacle to achieving sustainability in water supply systems is the insufficient practical experience with the technologies required, \& the missing know-how about the organization \& the transition process.

Possible ways to improve this situation is simulating of the network, implementing \href{https://en.wikipedia.org/wiki/Pilot_project}{pilot projects}, learning from the costs involved \& the benefits achieved.'' -- \href{https://en.wikipedia.org/wiki/Water_supply_network#Future_approaches}{Wikipedia\texttt{/}water supply network\texttt{/}future approaches}

%------------------------------------------------------------------------------%

\part{Optimal Control}

\chapter{\cite{Lions1971}. Optimal Control of Systems Governed by PDEs}

\section*{Introduction}
\textbf{1.} ``The development of a theory of optimal control (deterministic\footnote{\textbf{deterministic} [a] (\textit{philosophy}) connected with the belief that people are not free to choose what they are like or how they behave, because these things are decided by their environment \& other things over which they have no control.}) requires the following initial data:
\begin{itemize}
	\item[(i)] a \textit{control} $u$ belonging to some set $\mathcal{U}_{\rm ad}$ (the set of `admissible\footnote{\textbf{admissible} [a] that can be allowed or accepted according to a set of rules, especially in a court of law, \textsc{opposite}: \textbf{inadmissible}.} controls') which is at our disposition\footnote{\textbf{disposition} [n] \textbf{1.} [countable, uncountable] the natural qualities of a person's character; \textbf{2.} [countable] a tendency to behave in a particular way, or to have a particular opinion; \textbf{3.} [countable, uncountable] \textbf{disposition (of something)} (\textit{specialist}) the way something is placed or arranged; the fact of something being placed somewhere; \textbf{4.} [countable, uncountable] (\textit{law}) a formal act of giving property or money to somebody.},
	\item[(ii)] for a given control $u$, the state $y(u)$ of the system which is to be controlled is given by the solution of an equation \textbf{(*)} $\Lambda y(u) =$ given function of $u$, where $\Lambda$ is an operator\footnote{\textbf{operator} [n] \textbf{1.} (often in compounds) a person or company that runs a particular business; \textbf{2.} (often in compounds) a person who operates equipment or a machine; \textbf{3.} (\textit{mathematics}) a symbol or function which represents an operation in mathematics, e.g., $\times,+$.} (assumed known) which specifies\footnote{\textbf{specify} [v] to identify somebody\texttt{/}something clearly \& definitely; to state a fact or something that is required clearly \& exactly.} the system to be controlled ($\Lambda$ is the `model\footnote{\textbf{model} [n] \textbf{1.} a simple description, especially a mathematical one, of a group of complex systems or processes, used for understanding or explaining how something works; \textbf{2.} a way of doing something that others can copy or refer to; \textbf{3.} an object that is a copy of something, usually smaller than the original object; \textbf{4.} \textbf{model of something} a perfect example of something; \textbf{5.} a particular design or type of product; \textbf{6.} (in fashion \& art) somebody who sits, stands or moves around in order to  display clothes or so that somebody else can draw, paint or photograph them; [v] \textbf{1.} to create or use a description (especially a mathematical one), a computer program, a diagram or a copy of something, in order to explain or calculate something; \textbf{2.} \textbf{model something} to show somebody how to do something, especially how to behave well, \textsc{synonym}: \textbf{simulate}; \textbf{model something on\texttt{/}after something} [phrasal verb] [usually passive] to make something so that it is like something else; to base something on something else.}' of the system\footnote{\textbf{system} [n] \textbf{1.} [countable] an organized way of doing something; an organized set of ideas or theories; \textbf{2.} [countable] a group of things that work together in a particular way or for a particular purpose; \textbf{3.} [countable] a human or animal body, or a part of it, when it is being thought of as the organs \& processes that make it function; \textbf{4.} (\textbf{the system}) [singular] (\textit{rather informal, usually disapproving}) the rules or people that control a country or an organization, especially when they seem to be unfair because you cannot change them.}),
	\item[(iii)] the observation\footnote{\textbf{observation} [n] \textbf{1.} [uncountable, countable] the act of watching somebody\texttt{/}something carefully for a period of time, especially to learn something; \textbf{2.} [uncountable] the ability to notice things, especially important details; \textbf{3.} [countable] \textbf{observation (about\texttt{/}on something)} a comment, especially based on something you have seen, heard or read, \textsc{synonym}: \textbf{remark}.} $z(u)$ which is a function of $y(u)$ (assumed to be known exactly; we consider only deterministic problems in this book),
	\item[(iv)] the ``cost function'' $J(u)$ (``economic\footnote{\textbf{economic} [a] \textbf{1.} [only before noun] connected with the trade, industry \& development of wealth of a country, an area or a society; \textbf{2.} producing enough profit to continue; not costing much money, \textsc{synonym}: \textbf{profitable}.} function'') which is defined in terms of a numerical function $z\to\Phi(z)\ge 0$ on the ``space of observations'' by \textbf{(**)} $J(u) = \Phi(z(u))$. It is required to find (problem of the Calculus of Variations\footnote{\textbf{variation} [n] \textbf{1.} [countable, uncountable] a change or difference, especially in the amount or level of something, usually within particular limits; \textbf{2.} [uncountable] (\textit{biology}) the fact of a living thing occurring in more than 1 different color or form; \textbf{3.} [countable] \textbf{variation (on something)} a thing that is different from other things in the same general group.}) $\inf J(u)$, $u\in\mathcal{U}_{\rm ad}$.
\end{itemize}
The objectives of the theory are
\begin{itemize}
	\item[(i)] to obtain necessary (or possibly necessary \& sufficient\footnote{\textbf{sufficient} [a] enough for a particular purpose; as much as you need. In logic, a \textbf{sufficient condition} of a statement is a condition that, if true, makes the statement true. It is often combined with a \textbf{necessary condition}, which must be true in order for the statement to be true, \textsc{opposite}: \textbf{insufficient}.}) conditions for $u$ to be an extremum (or minimum),
	\item[(ii)] to study the structure \& properties of the equations expressing these conditions (where the `model' $\Lambda$ naturally intervenes\footnote{\textbf{intervene} [v] \textbf{1.} [intransitive] to become involved in a situation in order to improve it or stop it from getting worse; \textbf{2.} [intransitive] to happen in the time between events; \textbf{3.} [intransitive] to exist or be found in the space between things; \textbf{4.} [intransitive] to happen in a way that delays something or prevents it from happening.}),
	\item[(iii)] to obtain constructive\footnote{\textbf{constructive} [a] having a useful \& helpful effect rather than being negative or with no purpose.} algorithms\footnote{\textbf{algorithm}  [n] a process or set of rules to be followed when solving a particular problem, especially by a computer.} amenable\footnote{\textbf{amenable} [a] \textbf{amenable to (doing) something} that you can treat in a particular way.} to numerical computations for the approximation of a (the) control $u\in\mathcal{U}_{\rm ad}$ which determines the $\inf$ (such a control is termed an ``optimal\footnote{\textbf{optimal} [a] [usually before noun] (also \textbf{optimum}) the best possible; producing the best possible results, \textsc{synonym}: \textbf{ideal}.} control'').
\end{itemize}
\textbf{2.} Clearly the development of such a theory depends on the model $\Lambda$ in a fundamental manner\footnote{\textbf{manner} [n] \textbf{1.} [singular] the way that something is done or happens; \textbf{2.} [singular] the way that somebody behaves towards other people; \textbf{3.} (\textbf{manners}) [plural] behavior that is considered to be polite in a particular society or culture; \textbf{4.} (\textbf{manners (of somebody\texttt{/}something)}) [plural] the habits \& customs of a particular group of people; \textbf{all manner of somebody\texttt{/}something} [idiom] many different types of people or things;\textbf{in the manner of somebody\texttt{/}something} [idiom] in a style that is typical of somebody\texttt{/}something.}. The theory described in the works of Pontryagin--Boltyanskii--Gamkrelidze--Mischenko [1] \& Hestenes [1] is concerned with the study of points (i) \& (ii) of \textbf{1} in the case where $\Lambda$ is a family of ordinary differential (or with delay\footnote{\textbf{delay} [n] \textbf{1.} [countable] a period or time by which something is slow or late; the period of time between 2 things happening; \textbf{2.} [uncountable] a situation in which something does not happen when it should; [v] \textbf{1.} [transitive] to not do something until a later time; \textbf{2.} [transitive, usually passive] if an event is delayed, it happens at a later time than is normal or expected.} or integro-differential) operators.

In a variety of applications, due to the complexity\footnote{\textbf{complexity} [n] \textbf{1.} [uncountable] the state of being formed of many parts; the state of being difficult to understand; \textbf{2.} (\textbf{complexities}) [plural] \textbf{complexity of something} the features of a problem or situation that are difficult to understand.} of the system to be controlled, it is often advantageous\footnote{\textbf{advantageous} [a] good or helpful to somebody in a particular situation, \textsc{synonym}: \textbf{beneficial}, \textsc{opposite}: \textbf{disadvantageous}.} to discard\footnote{\textbf{discard} [v] to get rid of something that you no longer want or need.} the above-mentioned mathematical model in favor of a model described by a family of partial differential operators (e.g., cf. Butkovskii [1], Wang [1] \& the bibliography\footnote{\textbf{bibliography} [n] (plural \textbf{bibliographies}) the list of books, etc. that have been used by somebody writing an article, essay, etc.; a list of books or articles about a particular subject or by a particular author.} of these works). It is this situation that we propose\footnote{\textbf{propose} [v] \textbf{1.} to suggest a plan or an idea for people to consider \& decide on; \textbf{2.} to suggest an explanation of something for people to consider.} to investigate in this book\footnote{We hasten to add that only very partial results have been obtained in a number of directions.}\,\footnote{\textbf{hasten} [v] \textbf{1.} [intransitive] \textbf{hasten to do something} to say or do something without delay; \textbf{2.} [transitive] \textbf{hasten something} (\textit{formal}) to make something happen sooner or more quickly; \textbf{3.} [intransitive] \textbf{$+$ adv.\texttt{/}prep.} (\textit{literary}) to go or move somewhere quickly, \textsc{synonym}: \textbf{hurry}.}. We thus consider systems whose state $y(u)$ is given by the solution of a \textit{PDE} to which we must add appropriate \textit{boundary conditions}\footnote{Control may be exercised through the boundary condition, which in fact is the situation generally encountered in practice.} \& in the case of evolution\footnote{\textbf{evolution} [n] [uncountable] \textbf{1.} (\textit{biology}) the gradual development of living things over many years as they adapt to changes in their environment; \textbf{2.} the gradual development of something.} equations \textit{initial conditions}.

\textbf{3.} It is clear that unless we wish to restrict\footnote{\textbf{restrict} [v] \textbf{1.} to limit or control the size, amount or range of something; \textbf{2.} to limit something to a particular time, place or group; \textbf{3.} \textbf{restrict somebody (from something\texttt{/}from doing something)} to not allow somebody to do something or to go somewhere; \textbf{4.} \textbf{restrict yourself\texttt{/}somebody\texttt{/}something (to something\texttt{/}to doing something)} to allow yourself or somebody to have, do or consider only a limited amount of something or to do only a particular kind of activity; \textbf{5.} \textbf{restrict something\texttt{/}somebody} to stop something\texttt{/}somebody from moving freely, \textsc{synonym}: \textbf{impede}.} ourselves to results which are purely\footnote{\textbf{purely} [adv] only; completely.} formal\footnote{\textbf{formal} [a] \textbf{1.} following strict rules of how to do something; suitable for an official occasion, \textsc{opposite}: \textbf{informal}; \textbf{2.} (of speech or writing) suitable for official or serious situations, \textsc{opposite}: \textbf{informal}; \textbf{3.} (of education or training) received in a school, college or university rather than gained just through practical experience, \textsc{opposite}: \textbf{informal}; \textbf{4.} concerned with the form or structure of something rather than its content; \textbf{5.} concerned only with following rules.}, the minimization\footnote{\textbf{minimization} [n] (\textit{British English also} \textbf{minimisation}) [uncountable, countable, usually singular] the act of reducing something, especially something bad, to the lowest possible level.} of (**) presupposes\footnote{\textbf{presuppose} [v] \textbf{1.} to accept that something is true \& argue a case or take action on that basis, before it has been proved to be true, \textsc{synonym}: \textbf{assume, presume}; \textbf{2.} \textbf{presuppose something} to require something or accept something as needing to exist.} that the BVP (*) is formulated\footnote{\textbf{formulate} [v] \textbf{1.} \textbf{formulate something} to  create or prepare something carefully, giving particular attention to the details; \textbf{2.} \textbf{formulate something} to express your ideas in carefully chosen words.} \& solved in a precise\footnote{\textbf{precise} [a] \textbf{1.} clear \& accurate, \textsc{synonym}: \textbf{exact}; \textbf{2.} [only before noun] used to emphasize that something happens at a particular time or in a particular way; \textbf{to be (more) precise} [idiom] used to show that you are giving more detailed \& accurate information about something you have just mentioned.} mathematical setting. The results that are needed in this direction are proved in this book for the case where $\Lambda$ is an operator which is elliptic or parabolic or hyperbolic or well-posed in the sense of Petrovsky. In order not to overburden\footnote{\textbf{overburden} [v] [usually passive] \textbf{overburden somebody\texttt{/}something (with something)} to give somebody\texttt{/}something more work, worry, etc. than they can deal with.} this work we have restricted ourselves to comparatively\footnote{\textbf{comparatively} [adv] \textbf{1.} when measured or judged by how similar or different something is to something else, \textsc{synonym}: \textbf{else}; \textbf{2.} connected with studying things to discover how they are similar or different.} simple examples. However the techniques we have used are quite general \& hence more general problems can be solved using the same techniques. We refer the reader to \cite[Chap. 6]{Lions_Magenes1972} where extensions to more general cases can be found.

Once we have in our possession\footnote{\textbf{possession} [n] \textbf{1.} [uncountable] the state of having or owning something; \textbf{2.} [countable, usually plural] something that you own or have with you at a particular time; \textbf{3.} [countable] a country that is controlled or governed by another country; \textbf{4.} [uncountable] the state of having illegal drugs or weapons with you at a particular time; \textbf{5.} [uncountable] the situation when somebody's mind is believed to be controlled by an evil spirit.} a good theory for the solution of (*), it remains to obtain \& analyze the necessary (or necessary \& sufficient in favorable cases) conditions for (**) to have a minimum. In this manner we are led to a number of BVPs which appear to be novel\footnote{\textbf{novel} [n] a story long enough to fill a complete book, in which the characters \& events are usually imaginary; [a] different from anything known before; new \& interesting.} in character. These problems however have a striking analogy\footnote{\textbf{analogy} [n] (plural \textbf{analogies}) [countable, uncountable] a comparison of 1 thing with another thing that has similar features, usually in order to explain it; a feature that is similar.} with ``multiphase'' \& ``unilateral\footnote{\textbf{unilateral} [a] \textbf{1.} [usually before noun] done by 1 member of a group or organization without the agreement of the other members; \textbf{2.} (\textit{medical}) involving only 1 side of an organ or the body.}'' problems of mechanics\footnote{\textbf{mechanics} [n] \textbf{1.} [uncountable] the science of movement \& force; \textbf{2.} [plural] \textbf{mechanics of something} the way something works or is done.} -- in particular in plasticity\footnote{\textbf{plasticity} [n] [uncountable] \textbf{1.} (\textit{specialist}) the quality of being easily made into different shapes; \textbf{2.} (\textit{biology}) the ability of a living thing to adapt to changes in its environment or differences between its various habitats.}.

\textbf{4.} We now give a brief analysis of the contents of the various chapters.

In Chap. 1 we study amongst other things, the minimization of positive definite\footnote{\textbf{definite} [a] \textbf{1.} clearly stated or decided; sure or certain; \textbf{2.} clearly true or real; having a clear meaning; \textbf{3.} having an exact online or form that can be recognized easily.} or semi-definite quadratic\footnote{\textbf{quadratic} [a] (\textit{mathematics}) involving an unknown quantity that is multiplied by itself once only.} forms defined on a closed, convex subset of a Hilbert space. Applications to unilateral problems are given. These unilateral problems are prototypes\footnote{\textbf{prototype} [n] \textbf{1.} the 1st design of something from which other forms are copied or developed; \textbf{2.} \textbf{prototype (of something)} the 1st, original or typical form of something.} of problems which we encounter in the sequel\footnote{\textbf{sequel} [n] \textbf{1.} \textbf{sequel (to something)} a book, film, play, etc. that continues the story of an earlier one; \textbf{2.} [usually singular] \textbf{sequel (to something)} something that happens after an earlier event or as a result of an earlier event.}.

In Chap. 2 we study the optimal control of systems governed by elliptic equations. While in Chaps. 3--4 we examine the parabolic \& hyperbolic or well-posed in the sense of Petrovsky cases. In each of these chapters we 1st consider the case of a linear system with a quadratic cost function \& study the ``unilateral problem'' which this leads to. In Chaps. 3--4 we study in detail the ``feedback problem'' \& the related integro-differential equation of Riccati type. We then study existence theorems for simple nonlinear systems (given the present state of the art of nonlinear PDEs, a general theory in this sense appears to be outside our reach for the moment) \& 1st order necessary conditions.

Finally, in Chap. 5, we present various procedures of regularization, approximation \& penalization. These procedures may be utilized in the numerical solution of optimal control problems which we have studied.

The chapter headings are the following:
\begin{itemize}
	\item Chap. 1. Minimization of functions \& unilateral BVPs.
	\item Chap. 2. Control of systems governed by elliptic PDEs.
	\item Chap. 3. Control of systems governed by parabolic PDEs.
	\item Chap. 4. Control of systems governed by hyperbolic PDEs or by equations well-posed in the sense of Petrovsky.
	\item Chap. 5. Regularization, approximation \& penalization. Bibliography.
\end{itemize}
Each chapter begins with a detailed plan indicating the scope of the chapter \& closes with bibliographic notes \& indications on problems which are unsolved (of which there are many) or on aspects which have not been considered in this book. The whole subject is clearly in a process of evolution.

The contents of the book have developed from a course given at the Faculty of Sciences, University of Paris since the academic year 1965--1966. An abbreviated version of the book was presented in a summer course at the University of California, Los Angeles in Aug 1967 (the course was organized by A. V. Balakrishnan).'' -- Paris, Nov 1969, J. L. Lions, \cite[pp. 1--3]{Lions1971}

\section*{Principal Notations}
``${\bf x} = (x_1,\ldots,x_n)$ denotes the \textit{space} variable; ${\bf x}$ ranges in an open set $\Omega\subset\mathbb{R}^n$ with boundary $\Gamma$. $t$ denotes time; in general $t\in(0,T)$, $T < \infty$. We set $Q\coloneqq(0,T)\times\Omega$, $\Sigma = (0,T)\times\Gamma$. The \textit{controls} (or commands\footnote{\textbf{command} [n] \textbf{1.} [uncountable] \textbf{command (of somebody\texttt{/}something)} control \& authority over a situation or a group of people; \textbf{2.} [singular, uncountable] \textbf{command (of something)} your knowledge of something; your ability to do or use something, especially a language; \textbf{3.} [countable] an order given to a person or an animal; \textbf{4.} [countable] an instruction causing a computer to perform a function; \textbf{at your command} [idiom] if you have a skill or an amount of something at your command, you are able to use it well \& completely; [v] \textbf{1.} [transitive] (of somebody in a position of authority) to tell somebody to do something, \textsc{synonym}: \textbf{order}; \textbf{2.} [transitive, intransitive] \textbf{command (somebody\texttt{/}something)} to be in charge of a group of people in the army, navy, etc.; \textbf{3.} [transitive, no passive] (not used in the progressive tenses) \textbf{command something} to deserve \& get something because of the special qualities you have; \textbf{4.} [transitive, no passive] (not used in the progressive tenses) \textbf{command something} to be in a strong enough position to have or get something; \textbf{5.} [transitive, no passive] (not used in the progressive tenses) \textbf{command something} to have something available fo ruse; \textbf{6.} [transitive, no passive] (not used in the progressive tenses) \textbf{command something} to be in a position from where you can see or control something.}) are, in general, denoted by $u,v,w,\ldots$; they are generally taken to be in a space $\mathcal{U}$ (quite generally a Hilbert space on $\mathbb{R}$); $\mathcal{U}_{\rm ad}$ ($=$ set of \textit{admissible} controls) is a \textit{closed, convex subset of $\mathcal{U}$}.

The \textit{state} of the system is denoted by $y(v)$; in the \textit{elliptic} case (Chap. 2) $y(v)$ is a function of ${\bf x}\in\Omega$, $y({\bf x},v)$; in the \textit{evolution} case (Chaps. 3--4) $y(v)$ is a function of ${\bf x}\in\Omega$ \& $t\in(0,T)$: $y(t,{\bf x};v)$. The \textit{observation} is denoted by $z(v) = Cy(v)$ (we do not study the case where there is noise present). The \textit{cost function} (or \textit{criterion}, or \textit{economic function}) is denoted by $J(v)$. The $u\in\mathcal{U}_{\rm ad}$ s.t. $J(u)\le J(v)$, $\forall v\in\mathcal{U}_{\rm ad}$ are the optimal controls. $p(v)$ denotes the \textit{adjoint state}.

\textsc{Main function spaces used.}
\begin{itemize}
	\item $C^k(\Omega) =$ space of $k$-times continuously differentiable functions on $\overline{\Omega}$, $k$ integer $\ge 0$.\footnote{Clearly we have analogous notation for $Q,\Gamma,\Sigma$. All functions considered are real-valued.}
	\item $\mathcal{D}(\Omega) =$ space of infinitely differentiable functions in $\Omega$, with \textit{compact support in $\Omega$}, endowed with the inductive limit topology of L. Schwartz [1].
	\item $\mathcal{D}'(\Omega) =$ dual space of $\mathcal{D}(\Omega) =$ space of distributions on $\Omega$.\footnote{In general, $X'$ denotes the dual of $X$.}
	
	If $X$ is a Banach space, $\mathcal{D}'((0,T);X)$ denotes the space of distributions on $(0,T)$ with values in $X$ (cf. Schwartz [3] \& brief recapitulation\footnote{\textbf{recapitulation} [n] [countable, uncountable] (\textit{formal}) (also \textbf{recap}) the act of repeating or giving a summary of what has already been said, decided, etc.} in Chap. 3, Sect. 1.1).
	\item $L^2(\Omega) =$ space (equivalence class) of functions square integrable on $\Omega$.
	\item $H^m(\Omega) =$ (Sobolev [1] space of order $m$) $=$ space of functions $\varphi$ s.t. $\varphi\in L^2(\Omega)$, $\partial_{x_i}\varphi\in L^2(\Omega),\ldots,D^\alpha\varphi\in L^2(\Omega)$, $\forall\alpha$, $|\alpha|\le m$, $\alpha = (\alpha_1,\ldots,\alpha_m)$, $|\alpha| = \sum_{i=1}^n \alpha_i$.
	\item $H_0^m(\Omega) = \{\varphi|\varphi\in H^m(\Omega),\ D^\alpha\varphi = 0\mbox{ on }\Gamma,\ |\alpha|\le m - 1\}$.
	\item $H^s(\Omega) =$ \textit{Fractional Sobolev space} of order $s$ on $\Omega$, $=$ space of restrictions on $\Omega$ of functions of $H^s(\mathbb{R}^n)$ defined (by Fourier Transforms) in Chap. 1, (3.12).
	\item $L^2(S;E) =$ space (equivalence class) of functions defined on $S$ (locally compact measure space with measure $\mu\ge 0$) with values in a Hilbert space $E$ \& s.t. $\int_S \|f(t)\|_E^2\,{\rm d}\mu(t)\le\infty$. We use primarily $L^2(0,T;E)$, ${\rm d}\mu(t) = {\rm d}t$.
	\item $L^\infty(S;E) =$ space (equivalence class) of functions $f$ defined on $S$ with values in $E$ \& essentially bounded: $\|f(t)\|_E\le\|f\|_{L^\infty(S,E)} < \infty$, a.e.'' -- \cite[pp. 4--5]{Lions1971}
\end{itemize}

\section{Minimization of Functions \& Unilateral BVPs}

\subsection{Minimization of Coercive Forms}

\subsubsection{Notation}
``Let $\mathcal{U}$ be a real Hilbert space. The elements of $\mathcal{U}$ will be denoted by $u,v,w,\ldots$. In the applications we have in mind in the following chapters. $\mathcal{U}$ will be the space of controls.

In this chapter $\|\cdot\|$ will denote the norm on $\mathcal{U}$; in general, if there is possible ambiguity, the norm in the space $X$ will be denoted by $\|u\|_X$. For the moment, we shall assume that the following data is given:
\begin{itemize}
	\item[(i)] a continuous bilinear form on $\mathcal{U}$, which is symmetric, $u,v\to\pi(u,v)$, $\pi(u,v) = \pi(v,u)$, $\forall u,v\in\mathcal{U}$,
	\item[(ii)] a continuous linear form on $\mathcal{U}$, $v\to L(v)$,
	\item[(iii)] a closed, convex set $\mathcal{U}_{\rm ad}$ in $\mathcal{U}$.
\end{itemize}
In the applications considered in the sequel $\mathcal{U}_{\rm ad}$ will be the set of admissible controls. The quadratic functional \textbf{(1.1)} $J(v) = \pi(v,v) - 2L(v)$ is required to be minimized over the set $\mathcal{U}_{\rm ad}$.'' -- \cite[p. 6]{Lions1971}

\subsubsection{The Case when $\pi$ is Coercive}
``$\pi$ is said to be \textit{coercive} on $\mathcal{U}$ if \textbf{(1.2)}
\begin{align*}
	\pi(v,v)\ge c\|v\|^2,\ \forall v\in\mathcal{U},\,c > 0.
\end{align*}
We then have

\begin{theorem}
	Let $\pi(u,v)$ be a continuous symmetric bilinear form on $\mathcal{U}$ satisfies (1.2). Then there exists a unique element $u\in\mathcal{U}_{\rm ad}$ s.t. $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$.
\end{theorem}

\begin{proof}
	See \cite[pp. 7--]{Lions1971}
\end{proof}

\begin{example}
	Let us consider $\pi(u,v) = (u,v) =$ scalar product in $\mathcal{U}$, $L(v) = (g,v)_\mathcal{U}$, where $g$ is a given element in $\mathcal{U}$. Then, $J(v) = \|g - v\|_\mathcal{U}^2 - \|g\|_\mathcal{U}^2$ \& the unique element $u\in\mathcal{U}_{\rm ad}$ s.t. $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$ is characterized by $\|g - u\|_\mathcal{U}\le\|g - v\|_\mathcal{U}$, $\forall v\in\mathcal{U}_{\rm ad}$; $u$ is thus the projection of $g$ on $\mathcal{U}_{\rm ad}$.
\end{example}
\paragraph{Analysis of the Proof of \cite[Theorem 1.1]{Lions1971}.} An analysis of the way the assumptions of Theorem 1.1 come into play in the proof of the theorem suggests the following remarks:

\begin{remark}
	Theorem 1.1 is true if we assume that the bilinear form $\pi(u,v)$ is defined on $\mathcal{U}_{\rm ad}\times\mathcal{U}_{\rm ad}$ \& satisfies (1.2), $\forall v\in\mathcal{U}_{\rm ad}$.
\end{remark}
The fact that the function $v\to J(v)$ is a quadratic form does not enter in any essential way in  the proof of Theorem 1.1.

\begin{remark}
	Let $v\to J(v)$ be a convex function from $\mathcal{U}_{\rm ad}\to\mathbb{R}$, s.t. \textbf{(1.10)--(1.11)}
	\begin{align*}
		J(v)&\to+\infty\mbox{ as }\|v\|\to+\infty,\ v\in\mathcal{U}_{\rm ad},\\
		v&\to J(v)\mbox{ is strongly l.s.c.}
	\end{align*}
	Then there exists $u\in\mathcal{U}_{\rm ad}$ s.t. \textbf{(1.12)} $J(u) = \inf_v J(v)$.
\end{remark}
This remarks also applies to functions $v\to J(v)$ defined on $\mathcal{U}_{\rm ad}\subset\mathcal{U}$, where $\mathcal{U}$ is, e.g., a reflexive Banach space.

With hypotheses (1.10), (1.11) only, we do not necessarily have uniqueness; clearly we have uniqueness if we assume that the function $v\to J(v)$ is strictly convex.

\begin{remark}
	Assumption (1.10) is necessary to prove that every minimizing sequence is bounded (cf. 1.5). If $\mathcal{U}_{\rm ad}$ is also bounded then we may dispense\footnote{\textbf{dispense} [v] \textbf{1.} to provide something, usually something that is intended to help people; \textbf{2.} \textbf{dispense something} to prepare medicine \& give it to people; \textbf{3.} \textbf{dispense something} (of a machine) to provide money, food, drink, etc.; \textbf{dispense with somebody\texttt{/}something} [phrasal verb] to not use or stop using somebody\texttt{/}something; to get rid of somebody\texttt{/}something.} with Assumption (1.10).'' -- \cite[pp. 6--8]{Lions1971}
\end{remark}

\subsubsection{Characterization of the Minimizing Element. Variational Inequalities}
\begin{theorem}
	Let the assumptions of Theorem 1.1 remain valid. The minimizing element $u$ of $\mathcal{U}_{\rm ad}$ is characterized by \textbf{(1.13)} $\pi(u,v - u)\ge L(v - u)$, $\forall v\in\mathcal{U}_{\rm ad}$.
\end{theorem}

\begin{proof}
	See \cite[p. 9]{Lions1971}.
\end{proof}
``Inequalities of the type given by (1.13) are termed ``\textit{variational inequalities}''.

\begin{remark}
	Let $\mathcal{U}$ be a Hilbert space over $\mathbb{C}$ (instead of $\mathbb{R}$) \& let $\pi(u,v)$ be a sesquilinear hermitian form, i.e., $\pi(u,v) = \overline{\pi(v,u)}$, $\forall u,v\in\mathcal{U}$. Assuming that (1.2) is satisfied, Theorem 1.1 remains valid without any change. Replacing (1.13) by \textbf{(1.18)}
	\begin{align*}
		\operatorname{Re}\pi(u,v - uu)\ge\operatorname{Re}L(v - u),\ \forall v\in\mathcal{U}_{\rm ad},
	\end{align*}
	Theorem 1.2 remains valid.
\end{remark}

\begin{remark}[The Case $\mathcal{U}_{\rm ad} = \mathcal{U}$\footnote{In control problems this corresponds to the \fbox{case where there are no constraints}.}]
	If $\mathcal{U}_{\rm ad} = \mathcal{U}$, in (1.13) we may take $v = u\pm\varphi$, where $\varphi$ is any element of $\mathcal{U}$ \& (1.13) becomes equivalent to \textbf{(1.19)}
	\begin{align*}
		\pi(u,\varphi) = L(\varphi),\ \forall\varphi\in\mathcal{U}.
	\end{align*}
	This is the \emph{Euler equation} of the problem.
\end{remark}

\begin{remark}[The Case $\mathcal{U}_{\rm ad} = \mbox{Cone}$]
	Let us suppose \textbf{(1.20)} $\mathcal{U}_{\rm ad} =$ closed convex cone with vertex at the origin. Then (1.13) is equivalent to \textbf{(1.21)}
	\begin{equation*}
		\left\{\begin{split}
			\pi(u,v)&\ge L(v),\ \forall v\in\mathcal{U}_{\rm ad},\\
			\pi(u,u) &= L(u).
		\end{split}\right.
	\end{equation*}
	In fact, in (1.13) we may replace $v$ by $v + u$ which gives the 1st inequality in (1.21): putting $r = 0$ in (1.13), we obtain $\pi(u,v)\le L(u)$ \& hence the inequality $\pi(u,v)\le L(u)$. Conversely, it is obvious that (1.21) implies (1.13).
\end{remark}

\begin{remark}[The case of a functional $v\to J(v)$ which is not necessarily quadratic]
	Suppose that the function (or functional) $v\to J(v)$ is differentiable\footnote{Cf. J. Dieudonn\'e [1], Chap. 8, Sect. 1.} The proof of Theorem 1.2 is also applicable to
	
	\begin{theorem}
		Assume that the function $v\to J(v)$ is strictly convex, differentiable \& satisfies (1.10) (the last hypothesis may be omitted if $\mathcal{U}_{\rm ad}$ is bounded). Then the unique element $u$ in $\mathcal{U}_{\rm ad}$ satisfying $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$ is characterized by \textbf{(1.22)} $J'(u)\cdot(v - u)\ge 0$, $\forall v\in\mathcal{U}_{\rm ad}$.
	\end{theorem}
\end{remark}

\subsubsection{Alternative Form of Variational Inequalities}
The following results are very useful in a technical sense:

\begin{theorem}
	Let all the hypotheses of Theorem 1.3 be satisfied. Then the characterization (1.22) is equivalent to: \textbf{(1.23)} $J'(v)\cdot(v - u)\ge 0$, $\forall u\in\mathcal{U}_{\rm ad}$.
\end{theorem}

\begin{proof}
	See \cite[p. 11]{Lions1971}.
\end{proof}
1st assume that the following result, which is important in its own right, is true:

\begin{theorem}
	Assume that the function $v\to J(v):\mathcal{U}\to\mathbb{R}$ is convex \& differentiable. Then the derivative $v\to J'(v):\mathcal{U}\to\mathcal{U}'$ is monotone, i.e., \textbf{(1.24)} $(J'(v) - J'(w))\cdot(v - w)\ge 0$, $\forall v,w\in\mathcal{U}$.
\end{theorem}

\begin{proof}
	See \cite[p. 11]{Lions1971}.
\end{proof}

\begin{remark}
	Summarizing: under the hypotheses of Theorem 1.3, we have \emph{3 equivalent formulations} of the problem:
	\begin{itemize}
		\item[(i)] the definition of the problem (when the minimum obtains): $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$, $u\in\mathcal{U}_{\rm ad}$,
		\item[(ii)] $J'(u)\cdot(v - u)\ge 0$, $\forall v\in\mathcal{U}_{\rm ad}$, $u\in\mathcal{U}_{\rm ad}$,
		\item[(iii)] $J'(v)\cdot(v - u)\ge 0$, $\forall u\in\mathcal{U}_{\rm ad}$, $v\in\mathcal{U}_{\rm ad}$.
	\end{itemize}
\end{remark}

\subsubsection{Function $f$ being the Sum of a Differentiable \& Non-Differentiable Function}
If we assume that the function $v\to J(v)$ is coercive, lower semi-continuous in the weak topology \& strictly convex, then there exists a $u\in\mathcal{U}_{\rm ad}$ s.t. $J(u)\le J(v)$, $\forall u\in\mathcal{U}_{\rm ad}$. In this case it is clear that we cannot apply criteria (ii) \& (iii) of Remark 1.8. However, these criteria are still applicable to the differentiable part of $J$. More precisely, we have the following result:

\begin{theorem}
	Consider the function \textbf{(1.26)} $J(v) = J_1(v) + J_2(v)$ where we assume that the functions $J_i(v)$, $i = 1,2$, are continuous, convex, \& lower semi-continuous in the weak topology. Further let $J(v)\to+\infty$ as $\|v\|\to+\infty$, $v\in\mathcal{U}_{\rm ad}$. We assume that the function $v\to J_1(v)$ is differentiable, but $J_2$ is not necessarily differentiable. Finally assume that $J$ is strictly convex. Then the unique element $u\in\mathcal{U}_{\rm ad}$ s.t. $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$ is characterized by \textbf{(1.27)}
	\begin{align*}
		J_1'(u)\cdot(v - u) + J_2(v) - J_2(u)\ge 0,\ \forall u\in\mathcal{U}_{\rm ad}.
	\end{align*}
\end{theorem}

\begin{proof}
	See \cite[pp. 12--13]{Lions1971}.
\end{proof}

\begin{remark}
	Putting $J_2 = 0$, it is clear that Theorem 1.6 contains Theorems 1.3 \& 1.4.
\end{remark}

\begin{remark}
	Suppose that $J$ is of the form \textbf{(1.28)} $J(v) = J_0(v) + J_1(v) + J_2(v)$, where the $J_i$'s satisfy the same hypotheses as in Theorem 1.6 \& the functions $J_0$ \& $J_1$ are differentiable. Then the unique element $u$ s.t. $J(u) = \inf_{v\in\mathcal{U}_{\rm ad}} J(v)$ is characterized by 1 of the following equivalent conditions: \textbf{(1.29)--(1.30)}
	\begin{align*}
		J_0'(u)\cdot(v - u) + J_1'(u)\cdot(v - u) + J_2(v) - J_2(u)&\ge 0,\ \forall v\in\mathcal{U}_{\rm ad},\\
		J_0'(u)\cdot(v - u) + J_1'(v)\cdot(v - u) + J_2(v) - J_2(u)&\ge 0,\ \forall v\in\mathcal{U}_{\rm ad}.
	\end{align*}
\end{remark}

\begin{remark}
	In case we only have existence of the minimizing element $u$ of $\mathcal{U}_{\rm ad}$ but not necessarily uniqueness, any 1 of the variational inequalities we have obtained characterizes the set of elements in $\mathcal{U}_{\rm ad}$ determining the minimum.
\end{remark}
In applications to control problems an element $u\in\mathcal{U}_{\rm ad}$ which determines the minimum is termed ``optimal control''.

\begin{remark}
	All the preceding results, without any change in their proofs are true when $\mathcal{U}$ is a reflexive Banach space.
\end{remark}

\subsubsection{The Convexity Hypothesis on $\mathcal{U}_{\rm ad}$}
So far we have assumed that $\mathcal{U}_{\rm ad}$ is \textit{convex}. The following development shows how we may obtain a (simple) necessary condition for extremality in case $\mathcal{U}_{\rm ad}$ is assumed to be only \textit{closed} in $\mathcal{U}$.

\begin{definition}
	Let $\mathcal{U}_{\rm ad}$ be closed \& let $u\in\mathcal{U}_{\rm ad}$. Define, \textbf{(1.31)}
	\begin{align*}
		\mathcal{C}(\mathcal{U}_{\rm ad};u)\coloneqq\left\{w|w\in\mathcal{U};\mbox{ there exists } u_n\in\mathcal{U}_{\rm ad}\mbox{ \& }\lambda_n > 0,\mbox{ s.t. } u_n\to u\mbox{ \& }\lambda_n(u_n - u)\to w\mbox{ in }\mathcal{U}\right\}.
	\end{align*}
\end{definition}
It may be easily verified that \textbf{(1.32)}
\begin{align*}
	\mathcal{C}(\mathcal{U}_{\rm ad};u)\mbox{ is a closed cone with its vertex at }\{0\}.
\end{align*}
We then have

\begin{theorem}
	Let $v\to J(v)$ be a function which is differentiable \& let $u$ be an element (assumed to exist) of $\mathcal{U}_{\rm ad}$ s.t. $J(u)\le J(v)$, $\forall v\in\mathcal{U}_{\rm ad}$. Then \textbf{(1.33)} $J'(v)\cdot w\ge 0$, $\forall w\in\mathcal{C}(\mathcal{U}_{\rm ad};u)$.
\end{theorem}

'' -- \cite[pp. 9--]{Lions1971}

\subsection{A Direct Solution of Certain Variational Inequalities}

\subsection{Examples}

\subsection{A Comparison Theorem}

\subsection{Non Coercive Forms}

\section{Control of Systems Governed by Elliptic PDEs}

\subsection{Control of Elliptic Variational Problems}

\subsection{1st Applications}

\subsection{A Family of Examples with $N = 0$ \& $\mathcal{U}_{\rm ad}$ Arbitrary}

\subsection{Observation on the Boundary}

\subsection{Control \& Observation on the Boundary. Case of the Dirichlet Problem}

\subsection{Constraints on the State}

\subsection{Existence Results for Optimal Controls}

\subsection{1st Order Necessary Conditions}

\section{Control of Systems Governed by Parabolic PDEs}

\section{Control of Systems Governed by Hyperbolic Equations or by Equations which are well Posed in the Petrowsky Sense}

\section{Regularization, Approximation \& Penalization}

\subsection{Regularization}

\subsubsection{Parabolic Regularization}

\subsubsection{Approximation in Terms of Systems of Cauchy--Kowaleska Type}

\subsubsection{Penalization}

%------------------------------------------------------------------------------%

\chapter{\cite{Troltzsch2010}. Optimal Control for PDEs}

\section*{Preface}
``The sections dealing with gradient methods were shortened in order to make space for \textit{primal-dual active set strategies}; the exposition of the latter now leads to the systems of linear equations to be solved.'' -- \cite[Preface to the English edition, p. xi]{Troltzsch2010}

``The mathematical optimization of process governed by PDEs has seen considerable progress in the past decade. Ever faster computational facilities \& newly developed numerical techniques have opened the door to important practical applications in fields e.g. fluid flow, microelectronics\footnote{\textbf{microelectronics} [n] [uncountable] the design, production \& use of very small electronic circuits.}, crystal\footnote{\textbf{crystal} [n] \textbf{1.} [countable] a small piece of a substance with many even sides, that is formed naturally when the substance becomes solid; in chemistry, a \textbf{crystal} is any solid that has its atoms, ions or molecules arranged in an ordered, symmetrical way; \textbf{2.} [uncountable] a clear mineral, e.g. quartz, used in making decorative objects.} growth, vascular\footnote{\textbf{vascular} [a] [usually before noun] (\textit{medical}) connected with or containing veins.} surgery\footnote{\textbf{surgery} [n] \textbf{1.} [uncountable, countable] medical treatment of injuries or diseases that involves cutting open a person's body, sewing up wounds, etc.; \textbf{2.} [countable] (\textit{British English}) a place where a doctor sees patients; \textbf{3.} [countable] (\textit{British English}) a time during which a doctor, an MP or another professional person is available to see people.}, \& cardiac\footnote{\textbf{cardiac} [a] [only before noun] (\textit{medical}) connected with the heart or heart disease; if somebody has a \textbf{cardiac arrest}, their heart suddenly stops temporarily or permanently.} medicine, to name just a few. As a consequence, the communities of numerical analysts \& optimizers have taken a growing interest in applying their methods to optimal control problems involving PDEs; at the same time, the demand from students for this expertise has increased, \& there is a growing need for textbooks that provide an introduction to the fundamental concepts of the corresponding mathematical theory.'' [$\ldots$] ``$\ldots$ the comprehensive text by J.-L. Lions \cite{Lions1971} covers much of the theory of linear equations \& convex cost functionals.''

\cite{Troltzsch2010} focuses ``on basic concepts \& notions e.g.:
\begin{itemize}
	\item Existence theory for linear \& semilinear PDEs
	\item Existence of optimal controls
	\item Necessary optimality conditions \& adjoint equations
	\item 2nd-order sufficient optimality conditions
	\item Foundation of numerical methods
\end{itemize}
In this connection, we will always impose constraints on the control functions, \& sometimes also on the state of the system under study. In order to keep the exposition to a reasonable length, we will not address further important subjects such as \textit{controllability, Riccati equations, discretization, error estimates}, \& \textit{Hamilton--Jacobi--Bellman theory}.

The 1st part of the textbook deals with convex problems involving quadratic cost functionals \& linear elliptic or parabolic equations. While these results are rather standard \& have been treated comprehensively in \cite{Lions1971}, they are well suited to facilitating the transition to problems involving semilinear equations. In order to make the theory more accessible to readers having only minor knowledge of these fields, some basic notions from functional analysis \& the theory of linear elliptic \& parabolic PDEs will also be provided.

The focus of the exposition is on nonconvex problems involving semilinear equations. Their treatment requires new techniques from analysis, optimization, \& numerical analysis, which to a large extent can presently be found only in original papers. In particular, fundamental results due to E. Casas \& J.-P. Raymond concerning the boundedness \& continuity of solutions to semilinear equations will be needed.

This textbook is mainly devoted to the analysis of the problems, although numerical techniques will also be addressed. Numerical methods could easily fill another book. Our exposition is confined to brief introductions to the basis ideas, in order to give the reader an impression of how the theory can be realized numerically. Much attention will be paid to revealing hidden mathematical difficulties that, as experiences shows, are likely to be overlooked.'' -- \cite[Preface to the German edition, pp. xiii--xiv]{Troltzsch2010}

\section{Introduction \& Examples}

\subsection{What is Optimal Control?}
``The mathematical theory of optimal control has in the past few decades rapidly developed into an important \& separate field of applied mathematics. 1 area of application of this theory lies in aviation\footnote{\textbf{aviation} [n] [uncountable] the activity of designing, building \& flying aircraft.} \& space technology: aspects of optimization come into play whenever the motion of an aircraft or a space vessel\footnote{\textbf{vessel} [n] \textbf{1.} a tube that carries blood through the body of a person or an animal, or liquid through the parts of a plant; \textbf{2.} (\textit{formal}) a large ship or boat; \textbf{3.} (\textit{formal}) a container used for holding liquids, e.g. a bowl or cup.} (which can be modeled by ODEs) has to follow a trajectory\footnote{\textbf{trajectory} [n] (plural \textbf{trajectories}) (\textit{specialist}) \textbf{1.} the curved part of something that has been fired, hit or thrown into the air; \textbf{2.} the way in which a person, an event or a process develops over a period of time, often leading to a particular result.} that is ``optimal'' in a sense to be specified.'' -- \cite[Sect. 1.1: \textit{What is optimal control?}, p. 1]{Troltzsch2010}

All the essential features of an \textit{optimal control problem}:
\begin{itemize}
	\item a \textit{cost functional} to be minimized,
	\item an IVP for an ODE in order to determine the \textit{state} $y$,
	\item a \textit{control function} $u$, \&
	\item various constraints that have to be obeyed.
\end{itemize}
``The control $u$ may be freely chosen within the given constraints, while the state is uniquely determined by the differential equation \& the initial conditions. We have to choose $u$ in such a way that the cost function is minimized. Such controls are called \textit{optimal}.'' [$\ldots$] ``The optimal control of ODEs is of interest not only for aviation \& space technology. In fact, it is also important in fields e.g. robotics\footnote{\textbf{robotics} [n] [uncountable] the science of designing \& operating robots.}, movement sequences in sports, \& the control of chemical processes \& power plants, to name just a few of the various applications. In many cases, however, the processes to be optimized can no longer be adequately modeled by ODEs; instead, PDEs have to be employed for their description. E.g., heat conduction\footnote{\textbf{conduction} [n] [uncountable] (\textit{physics}) the process by which heat or electricity passes along or through a material.}, diffusion\footnote{\textbf{diffusion} [n] [uncountable] \textbf{1.} the spreading of something more widely; \textbf{2.} the mixing of substances by the natural movement of their particles; \textbf{3.} the spreading of elements of culture from 1 region or group to another.}, electromagnetic\footnote{\textbf{electromagnetic} [a] (\textit{physics}) in which the electrical \& magnetic properties of something are related.} waves, fluid flows, freezing processes, \& many other physical phenomenon\footnote{\textbf{phenomenon} [n] (plural \textbf{phenomena} a fact or an event in nature or society, especially one that is not fully understood.)} can be modeled by PDEs.

In these fields, there are numerous interesting problems in which a given cost functional has to be minimized subject to a differential equation \& certain constraints being satisfied. The difference from the above problem ``merely'' consists of the fact that a PDE has to be dealt with in place of an ordinary one.'' -- \cite[pp. 2--3]{Troltzsch2010}

\cite{Troltzsch2010} discusses, ``through examples in the form of mathematically simplified case studies, the optimal control of heating processes, 2-phase problems, \& fluid flows''. \cite{Troltzsch2010} focuses ``on linear \& semilinear elliptic \& parabolic PDEs, since a satisfactory regularity theory is available for the solutions to such equations. This is not the case for hyperbolic equations. Also, the treatment of quasilinear PDEs is considerably more difficult, \& the theory of their optimal control is still an open field in many respects.'' [$\ldots$] ``$\ldots$ the Hilbert space setting suffices as a functional analytic framework in the case of linear-quadratic theory.'' -- \cite[p. 3]{Troltzsch2010}

\subsection{Examples of Convex Problems}

\subsubsection{Optimal boundary heating}
See \cite[Subsect. 1.2.1, pp. 3--5]{Troltzsch2010}.

\begin{example}[Optimal boundary heating]
	Consider a body heated or cooled which occupies the spatial domain $\Omega\subset\mathbb{R}^3$. Apply to its boundary $\Gamma$ a \emph{heat source} $u$ (the \emph{control}), which is constant in time but depends on the location ${\bf x}$ on the boundary, i.e., $u = u({\bf x})$. Aim: choose the control in such a way that the corresponding \emph{temperature distribution} $y = y({\bf x})$ in $\Omega$ (the \emph{state}) is the best possible approximation to a desired stationary temperature distribution $y_\Omega = y_\Omega({\bf x})$:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Gamma |u({\bf x})|^2\,{\rm d}s({\bf x}),
	\end{align*}
	subject to the \emph{state equation}:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and the \emph{pointwise control constraints} $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ on $\Gamma$. ``Such pointwise bounds for the control are quite natural, since the available capacities for heating or cooling are usually restricted. The constant $\lambda\ge 0$ can be viewed as a measure of the energy costs needed to implement the control $u$. From the mathematical viewpoint, this term also serves as a \emph{regularization parameter}; it has the effect that possible optimal controls show improved regularity properties.'' [$\ldots$] ``The function $\alpha$ represents the \emph{heat transmission coefficient} from $\Omega$ to the surrounding medium. The functional $J$ to be minimized is called the \emph{cost functional}. The factor $\frac{1}{2}$ appearing in it has no influence on the solution of the problem. It is introduced just for the sake of convenience: it will later cancel out a factor 2 arising from differentiation. We seek an optimal control $u = u({\bf x})$ together with the associated state $y = y({\bf x})$. The minus sign in front of the Laplacian $\Delta$ appears to be unmotivated at 1st glance. It is introduced because $\Delta$ is not a \emph{coercive operator}, while $-\Delta$ is.'' -- \cite[p. 4]{Troltzsch2010}
\end{example}
``Observe that in the above problem the cost functional is quadratic, the state is governed by a linear elliptic PDE, \& the control acts on the boundary of the domain.'': thus have a \textit{linear-quadratic elliptic boundary control problem}.

\begin{remark}[Notations used in \cite{Troltzsch2010}]
	Denote the element of surface area by $ds$ \& the outward unit normal to $\Gamma$ at ${\bf x}\in\Gamma$ by $\nu({\bf x})$\footnote{NQBH: I prefer to use ${\bf n}({\bf x})$, with ``n'' stands for ``normal'', naturally \& obviously.}.
\end{remark}

\begin{remark}
	``The problem is strongly simplified. Indeed, in a realistic model Laplace's equation $\Delta y = 0$ has to be replaced by the stationary heat conduction equation $\nabla\cdot(a\nabla y) = 0$, where the coefficient $a$ can depend on ${\bf x}$ or even on $y$. If $a = a(y)$ or $a = a({\b f x},y)$, then the PDE is quasilinear. In addition, it will in many cases be more natural to describe the process by a time-dependent PDE.'' -- \cite[p. 4]{Troltzsch2010}
\end{remark}

\begin{example}[Optimal heat source]
	Similarly, the control can act as a \emph{heat source in the domain} $\Omega$. Problems of this kind arise if the body $\Omega$ is heated by electromagnetic induction or by microwaves. Assuming at 1st that the boundary temperature vanishes, we obtain the following problem:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Omega |u({\bf x})|^2\,{\rm d}{\bf x},
	\end{align*}
	subject to
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			y &= 0,&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ in $\Omega$. Here, the coefficient $\beta = \beta({\bf x})$ is prescribed. Observe that by the special choice $\beta = \chi_{\Omega_{\rm c}}$ (where $\chi_E$ denotes the characteristic function of a set $E$), it can be achieved that $u$ acts only in a subdomain $\Omega_{\rm c}\subset\Omega$. This problem is a \emph{linear-quadratic elliptic control problem with distributed control}. It can be more realistic to prescribe an exterior temperature $y_a$ rather than assume that the boundary temperature vanishes. Then a better model is given by the state equation
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(y_a - y),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
\end{example}

\subsubsection{Optimal nonstationary boundary control}
See \cite[pp. 5--6]{Troltzsch2010}. ``Let $\Omega\subset\mathbb{R}^3$ represent a potato that is to be roasted over a fire for some period of time $T > 0$.'' Denote its temperature by $y = y(t,{\bf x})$, with $(t,x)\in[0,T]\times\Omega$. ``Initially, the potato has temperature $y_0 = y_0({\bf x})$, \& we want to serve it at a pleasant palatable\footnote{\textbf{palatable} [a] \textbf{1.} (of food or drink) having a pleasant or acceptable taste; \textbf{2.} \textbf{palatable (to somebody)} pleasant or acceptable to somebody, \textsc{opposite}: \textbf{unpalatable}.} temperature $y_\Omega$ at the final time $T$.'' Write $Q\coloneqq(0,T)\times\Omega$, $\Sigma\coloneqq(0,T)\times\Gamma$. Then problem reads as follows:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y(T,{\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_0^T\int_\Gamma |u(t,{\bf x})|^2\,{\rm d}\Gamma\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_t - \Delta y &= 0,&&\mbox{ in } Q,\\
		\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Sigma,\\
		y(0,{\bf x}) &= y_0({\bf x}),&&\mbox{ in }\Omega,
	\end{split}\right.
\end{equation*}
\& $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ on $\Sigma$. By continued turning of the spit\footnote{\textbf{spit} [n] \textit{in}\texttt{/}\textit{from mouth} \textbf{1.} [uncountable] the liquid produced in your mouth, \textsc{synonym}: \textbf{saliva}; \textbf{2.} [countable, usually singular] the act of spitting liquid or food out of your mouth; \textit{piece of land} \textbf{3.} [countable] a long, thin piece of land that sticks out into the sea, a lake, etc.; \textit{for cooking meat} \textbf{4.} [countable] a long, thin, straight piece of metal that you put through meat to hold \& turn it while you cook it over a fire.}, we produce $u(t,{\bf x})$. The heating process has to be described by the \textit{nonstationary heat equation}, which is a parabolic differential equation: thus have to deal with a \textit{linear-quadratic parabolic boundary control problem}.

\subsubsection{Optimal vibrations}
``Suppose that a group of pedestrians crosses a bridge, trying to excite\footnote{\textbf{excite} [v] \textbf{1.} to make somebody feel a particular emotion or react in a particular way, \textsc{synonym}: \textbf{arouse}; \textbf{2.} \textbf{excite somebody} to make somebody feel very pleased, interested or enthusiastic, especially about something that is going to happen; \textbf{3.} \textbf{excite somebody\texttt{/}something} to make somebody\texttt{/}something nervous, upset or active \& unable to relax; \textbf{4.} \textbf{excite something} to produce a state of increased energy or activity in a physical or biological system, \textsc{synonym}: \textbf{stimulate}; \textbf{5.} \textbf{excite something} (\textit{physics}) to bring something to a state of higher energy.} oscillations\footnote{\textbf{oscillation} [n] \textbf{1.} [countable, uncountable] \textbf{oscillation (of something)} a regular movement between 1 position \& another; \textbf{2.} [countable] \textbf{oscillation (between A \& B)} a repeated change between different states, ideas, etc.; \textbf{3.} [countable] (\textit{specialist} regular variation in size, strength or position around a central point or value, especially of an electrical current or electric field.)} in it. This can be modeled (strongly abstracted) as follows: let $\Omega\subset\mathbb{R}^2$ denote the domain of the bridge, $y = y(t,{\bf x})$ its \textit{transversal\footnote{\textbf{transversal} [n] a line that intersects a system of lines.} displacement\footnote{\textbf{displacement} [n] \textbf{1.} [uncountable] the act of displacing somebody\texttt{/}something; the process of being displaced; \textbf{2.} [uncountable, singular] \textbf{displacement (of something)} (\textit{physics}) the distance between the final \& initial ($=$ 1st) positions of an object which has moved.}}, $u = u(t,{\bf x})$ the \textit{force density} acting in the vertical direction, \& $y_{\rm d} = y_{\rm d}(t,{\bf x})$ a \textit{desired evolution of the transversal vibrations\footnote{\textbf{vibration} [n] [countable, uncountable] \textbf{1.} \textbf{vibration (of something)} a continuous shaking movement; \textbf{2.} \textbf{vibration (of something)} (\textit{physics}) oscillation in a substance about its equilibrium state.}}. We then obtain the optimal control problem:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_0^T\int_\Omega |y(t,{\bf x}) - y_{\rm d}(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t + \frac{\lambda}{2}\int_0^T\int_\Omega |u(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_{tt} - \Delta y &= u,&&\mbox{ in } Q,\\
		y(0) &= y_0,&&\mbox{ in }\Omega,\\
		y_t(0) &= y_1,&&\mbox{ in }\Omega,\\
		y &= 0,&&\mbox{ on }\Sigma,
	\end{split}\right.
\end{equation*}
and $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ in $Q$. This is a \textit{linear-quadratic hyperbolic control problem with distributed control}.'' [$\ldots$] ``Interesting control problems for oscillating elastic networks have been treated by Lagnese et al. \textbf{[LLS94]}. An elementary introduction to the controllability of oscillations can be found in \textbf{[Kra95]}.

In the linear-quadratic case, the theory of hyperbolic problems has many similarities to the parabolic theory studied in \cite{Troltzsch2010}. However, the treatment of semilinear hyperbolic problems is much more difficult, since the smoothing properties of the associated solution operators are weaker. As a consequence, many of the techniques presented in \cite{Troltzsch2010} fail in the hyperbolic case.'' -- \cite[pp. 6--7]{Troltzsch2010}

\subsection{Examples of Nonconvex Problems}
``However, linear models do not suffice for many real-world phenomena. Instead, one often needs quasilinear or, much simpler, semilinear equations. Recall that a 2nd-order equation is called \textit{semilinear} if the main parts (i.e., the expressions involving highest-order derivatives) of the differential operators considered in the domain \& on the boundary are linear w.r.t. the desired solution. For such equations, the theory of optimal control is well developed.

\fbox{Optimal control problems with semilinear state equations are, as a rule, nonconvex, even if the cost functional is convex.} ``Associated optimal control problems can be obtained by prescribing a cost functional \& suitable constraints.'' -- \cite[p. 7]{Troltzsch2010}

\subsubsection{Problems involving semilinear elliptic equations}

\begin{example}[Heating with radiation boundary condition]
	If the heat radiation of the heated body is taken into account, then we obtain a problem with a nonlinear Stefan--Boltzmann boundary condition. If this case, the control $u$ is given by the temperature of the surrounding medium:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u^4 - y^4),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
	The nonlinearity $y^4$ occurs in the boundary condition, while the heat conduction equation itself is linear.
\end{example}

\begin{example}[Simplified superconductivity]
	
\end{example}

\begin{example}[Control of stationary flows]
	
\end{example}

\subsubsection{Problems involving semilinear parabolic equations}

\subsection{Basic Concepts for the Finite-Dimensional Case}

\section{Linear-Quadratic Elliptic Control Problems}

\section{Linear-Quadratic Parabolic Control Problems}

\section{Optimal Control of Semilinear Elliptic Equations}

\section{Optimal Control of Semilinear Parabolic Equations}

\section{Optimization Problems in Banach Spaces}

\subsection{The Karush--Kuhn--Tucker Conditions}

\subsubsection{Convex problems}

\paragraph{The Lagrange multiplier rule.} ``The formal Lagrange method, which was employed repeatedly in the previous chapters, has a rigorous mathematical foundation. In this section, we introduce the basics of this theory needed for understanding problems with state constraints. The corresponding proofs \& further results can be found in texts dealing with optimization in general spaces. The theory of convex problems is described in Balakrishnan [Bal65], Barbu \& Precupanu [BP78], \& Ekeland \& Temam [ET74]; nonconvex differentiable problems are treated in, e.g., Ioﬀe \& Tihomirov [IT79], Jahn [Jah94], Luenberger [Lue69], \& Tr\"oltzsch [Tr\"o84b].

There are numerous books dealing with the theory \& numerical treatment of nonlinear differentiable finite-dimensional optimization problems. In this connection, we refer the interested reader to Alt [Alt02], Gill et al. [GMW81], Grossmann \& Terno [GT97b], Kelley [Kel99], Luenberger [Lue84], Nocedal \& Wright [NW99], Polak [Pol97], \& Wright [Wri93], to name just a few.

In the following, we generally assume that $U$ \& $Z$ are real Banach spaces, $G:U\to Z$ is in general a nonlinear mapping, \& $C\subset U$ is a nonempty \& convex set.

\begin{definition}[Convex cone]
	A convex set $K\subset Z$ is said to be a \emph{convex cone} if $\lambda z\in K$ whenever $z\in K$ \& $\lambda > 0$.
\end{definition}
Any convex cone induces a partial ordering $\ge_K$ in the space $Z$:

\begin{definition}
	Let $K\subset Z$ be a convex cone. We write $z\ge_K 0$ iff $z\in K$. Analogously, we write $z\le_K 0$ iff $-z\in K$.
\end{definition}
The elements in $K$ are said to be \textit{nonnegative}. Note, however, that nonnegativity in the sense of this definition does not imply the usual nonnegativity in the set of real numbers, as the following example shows.

\begin{example}
	Let $Z = \mathbb{R}^3$, \& let $K = \{z\in\mathbb{R}^3;z_1 = 0,\ z_2\le 0,\ z_3\ge 0\}$. Then $K$ is evidently a convex cone, but $z\ge_K 0$ implies nonnegatively only for $z_3$.
\end{example}
The next definition enables us to introduce a notion of ``nonnegativity'' also in dual spaces. This notion will be needed for defining Lagrange multipliers, because they are elements of dual spaces.

\begin{definition}[Dual cone]
	Let $K\subset Z$ be a convex cone. Then the set $K^+ = \{z^\star\in Z^\star;\langle z^\star,z\rangle_{Z^\star,Z}\ge 0,\ \forall z\in K\}$ is called the \emph{dual cone} of $K$.
\end{definition}

\begin{example}
	\begin{itemize}
		\item[(i)] Let $Z = L^2(\Omega)$ with a bounded domain $\Omega\subset\mathbb{R}^N$, \& let $K = \{z\in L^2(\Omega);z({\bf x})\ge 0\mbox{ for a.e. }{\bf x}\in\Omega\}$. Here, we have $Z = Z^\star$ by the Riesz representation theorem \& $K^+ = K$ according to Exercise 6.1.
		\item[(ii)] Let $Z$ be a Banach space \& let $K = \{0\}$. Then $z\ge_K 0$ iff $z = 0$, \& thus $K^+ = Z^\star$; in fact, for any $z^\star\in Z^\star$ we have $\langle z^\star,0\rangle_{Z^\star,Z} = 0\ge 0$.
		\item[(iii)] If $K = Z$, then all elements of $Z$ are nonnegative. Hence, $K^+ = \{0\}$ with the zero functional $0\in Z^\star$.
	\end{itemize}
\end{example}
Below we consider the following optimization problem in a Banach space: \textbf{(6.1)}
\begin{align*}
	\min f(u),\ G(u)\le_K 0,\ u\in C.
\end{align*}
The constraints in (6.1) are viewed differently: as a ``complicated'' inequality $G(u)\le_K 0$, which is to be eliminated by means of a Lagrange multiplier, \& a ``simple'' constraint $u\in C$, which is accounted fr explicitly. This motivates the following definition.

\begin{definition}[Lagrange function]
	The function $L:U\times Z^\star\to\mathbb{R}$, \textbf{(6.2)} $L(u,z^\star) = f(u) + \langle z^\star,G(u)\rangle_{Z^\star,Z}$, is called the \emph{Lagrange function}. Any $(\overline{u},z^\star)\in U\times K^+$ satisfying the chain of inequalities \textbf{(6.3)} $L(\overline{u},v^\star)\le L(\overline{u},z^\star)\le L(u,z^\star)$, $\forall u\in C$, $\forall v^\star\in K^+$ is called a \emph{saddle point} of $L$. If this is the case, $z^\star$ is said to be a \emph{Lagrange multiplier} associated with $\overline{u}$.
\end{definition}
In the previous chapters, when dealing with the optimal control of PDEs we denoted the Lagrangian by $\mathcal{L}$. To facilitate the distinction, we use the letter $L$ here. The existence of saddle points is most easily shown for \textit{convex} optimization problems.

\begin{definition}
	Let $U$ be a Banach space, \& let the convex cone $K\subset Z$ induce the partial ordering $\ge_K$ in the Banach space $Z$. An operator $G:U\to Z$ is said to be \emph{convex} (w.r.t. $\le_K$) if
	\begin{align*}
		G(\lambda u + (1 - \lambda)v)\le_K\lambda G(u) + (1 - \lambda)G(u),\ \forall u,v\in U,\ \forall\lambda\in(0,1).
	\end{align*}
\end{definition}
Evidently, every linear operator is convex. In the following, we write the strict inequality $z <_K 0$ iff $-z$ is an \textit{interior point} of $K$, i.e., $z <_K 0\Leftrightarrow-z\in\operatorname{int}K$.

\begin{theorem}
	Suppose that a convex functional $f:U\to\mathbb{R}$, a convex operator $G:U\to Z$, \& a solution $\overline{u}$ to the problem (6.1) are given. Moreover, let there exist some $\widetilde{u}\in C$ s.t. $G(\widetilde{u}) <_K 0$, i.e., \textbf{(6.4)} $-G(\widetilde{u})\in\operatorname{int} K$. Then there is some $z^\star\in K^+$ s.t. $(\overline{u},z^\star)$ is a saddle point of the Lagrangian $L$. In addition, we have the complementary slackness condition \textbf{(6.5)} $\langle z^\star,G(\overline{u})\rangle_{Z^\star,Z} = 0$.
\end{theorem}
The proof of the above theorem can be found in, e.g., Luenberger [Lue69]. In the literature, the condition (6.4) is usually referred to as the \textit{Slater condition}. It can only be satisfied if the cone $K$ has nonempty interior. This excludes, e.g., the case $K = \{0\}$, which corresponds to the equality constraint $G(u) = 0$. In this case, the above theorem fails to apply, but other existence results concerning Lagrange multipliers are available. The lack of interior points is a much more serious problem in the following situation.

\begin{example}
	Consider the natural nonnegative cone in $Z = L^2(0,1)$, $K = \{z(\cdot)\in L^2(0,1);z(x)\ge 0\mbox{ for a.e. }x\in(0,1)\}$. Quite unexpectedly, we have $\operatorname{int}K = \emptyset$. How can this be possible? One is tempted to believe that, e.g., $z(x)\equiv 1$ is an interior point of $K$. Unfortunately, this is not true. In fact, the sequence $\{v_n\}_{n=1}^\infty\subset L^2(\Omega)$ with
	\begin{equation*}
		v_n(x) = \left\{\begin{split}
			&1&&\mbox{in }\left[0,1 - \frac{1}{n}\right),\\
			-&1&&\mbox{in }\left[1 - \frac{1}{n},1\right],
		\end{split}\right.
	\end{equation*}
	while obviously converging to $z$ w.r.t. the $L^2$ norm, is not contained in $K$. Consequently, $z\notin\operatorname{int} K$. This undesired behavior is simply a consequence of the fact that the $L^2$ norm, \& likewise any other $L^p$ norm with $1\le p < \infty$, measures an integral \& not the maximal absolute value of a function. This fact constitutes a major obstacle in the treatment of optimization problems in function spaces.
\end{example}

\begin{theorem}
	Suppose that the mappings $f$ \& $G$ in Theorem 6.1 are G\^ateaux differentiable at $\overline{u}$. Then we have the variational inequality $D_uL(\overline{u},z^\star)(u - \overline{u})\ge 0$, $\forall u\in C$.
\end{theorem}
Here \& in the following, $D_u$ again denotes the partial G\^ateaux or Fr\'echet derivative w.r.t. $u$. The assertion is an immediate consequence of the saddle point condition (6.3), which implies that $\overline{u}$ solves the problem without the constraint $G(u)\le_K 0$, namely $L(\overline{u},z^\star) = \min_{u\in C} L(u,z^\star)$. The associated variational inequality reads, in explicit form,
\begin{align*}
	f'(\overline{u})(u - \overline{u}) + \langle z^\star,G'(\overline{u})(u - \overline{u})\rangle_{Z^\star,Z},\ \forall u\in C,
\end{align*}
or, equivalently,
\begin{align*}
	\langle f'(\overline{u}) + G'(u)^\star z^\star,u - \overline{u}\rangle_{U^\star,U}\ge 0,\ \forall u\in C.
\end{align*}
In the unconstrained case where $C = U$, we get the equation $f'(\overline{u}) + G'(\overline{u})^\star z^\star = 0\in U^\star$.

\textbf{Examples.} We illustrate the application \& limitations of the above theorems by means of simple examples that do not involve PDEs.

\paragraph{1-sided box constraints in $L^2(0,1)$.} Let $u_d\in L^2(0,1)$ be given. We consider the minimization problem \textbf{(6.6)}
\begin{align*}
	\min f(u)\coloneqq\frac{1}{2}\int_0^1 |u(x) - u_d(x)|^2\,{\rm d}x\mbox{ subject to } u(x)\le 0\mbox{ for a.e. } x\in(0,1).
\end{align*}
The above problem is a special case of problem (6.1), with the specifications $U = Z = L^2(0,1)$ \& $G = I$ (the identity mapping). The associated convex cone $K$ is the set of almost-everywhere nonnegative elements of $L^2(0,1)$, \& we have $C = U$. The problem has a unique minimizer $\overline{u}$, namely, $\overline{u}(x) = \min\{u_d(x),0\}$. We investigate whether there exists an associated Lagrange multiplier. The corresponding Lagrangian function reads
\begin{align*}
	L(u,\mu) = f(u) + (\mu,G(u))_{L^2(0,1)} = \int_0^1 \left(\frac{1}{2}(u(x) - u_d(x))^2 + \mu(x)u(x)\right)\,{\rm d}x.
\end{align*}
Here, by the Riesz representation theorem, the functional $z^\star\in Z^\star$ has been identified with some function $\mu\in L^2(0,1)$. We search for a Lagrange multiplier $\mu\in L^2(0,1)$. Since $\operatorname{int}K = \emptyset$, Theorem 6.1 does not apply. Instead, the Lagrange multiplier is constructed using a pointwise approach. To this end, recall that, owning to Lemma 2.21 on p. 63, we have the variational inequality
\begin{align*}
	\int_0^1 (\overline{u}(x) - u_d(x))(u(x) - \overline{u}(x))\,{\rm d}x\ge 0,\ \forall u(\cdot)\le 0.
\end{align*}
This can only be true if the implications
\begin{align*}
	\overline{u}(x) < 0&\Rightarrow\overline{u}(x) - u_d(x) = 0,\\
	\overline{u}(x) = 0&\Rightarrow\overline{u}(x) - u_d(x)\le 0,
\end{align*}
are valid a.e. But then $\overline{u}(x) - u_d(x)$ must be nonpositive a.e. Since we have used arguments of this kind repeatedly in Chap. 2, we do not explain this in detail here. We now define $\mu(x)\coloneqq-f'(\overline{u})(x) = -(\overline{u}(x) - u_d(x))$. Then, owing to the above implications, we have $\mu\ge 0$ as well as $\mu(x)\overline{u}(x) = 0$ for a.e. $x\in(0,1)$, which is the \textit{pointwise form of the complementary slackness condition} (6.5). Finally, it follows from the definition of $\mu$ that $\mu = -f'(\overline{u})$, i.e., $f'(\overline{u}) + \mu = 0$, which, in turn, is equivalent to the equation $D_uL(\overline{u},\mu) = 0$. Hence, the function $\mu$ defined above is a Lagrange multiplier.

\paragraph{2-sided box constraints in $L^2(0,1)$.} We now consider the above minimization problem with the same functional $f$ as in (6.6), but this time with constraints from both above \& below: \textbf{(6.7)}
\begin{align*}
	\min f(u)\mbox{ subject to } -1\le u(x)\le 1\mbox{ for a.e. } x\in(0,1).
\end{align*}
Again, we put $C = U = L^2(0,1)$, \& we cast the constraints in the form $u(x) - 1\le 0$, $-u(x) - 1\le 0$. We then have to choose $Z = L^2(0,1)\times L^2(0,1)$ \& $K = L^2(0,1)+\times L^2(0,1)_+$, where $L^2(0,1)_+$ denotes the set of a.e. nonnegative elements of $L^2(0,1)$. The convex operator $G:L^2(0,1)\to L^2(0,1)\times L^2(0,1)$ is defined by $G(u)\coloneqq(u(\cdot) - 1,-u(\cdot) - 1)^\top$.

Although the function $\widetilde{u}(x)\equiv 0$ obeys both inequalities strictly, we again have $\operatorname{int}K = \emptyset$ \& thus cannot employ Theorem 6.1. However, the construction used in Sect. 1.4.7 works. The Lagrangian is now given by
\begin{align*}
	L(u,\mu) = L(u,\mu_a,\mu_b) = \frac{1}{2}\|u - u_d\|_{L^2(0,1)}^2 + (-u - 1,\mu_a)_{L^2(0,1)} + (u - 1,\mu_b)_{L^2(0,1)}.
\end{align*}
We make the pointwise definitions \textbf{(6.8)} $\mu_a(x) = (f'(x))_+ = (\overline{u}(x) - u_d(x))_+$, $\mu_b(x) = (f'(x))_- = (\overline{u}(x) - u_d(x))_-$, where, as usual, $z_+ = \frac{z + |z|}{2}$ \& $z_- = \frac{|z| - z}{2}$. Obviously, $\mu_a$ \& $\mu_b$ are nonnegative. The reader will be asked in Exercise 6.2 to check that the arguments from Sect. 1.4.7 carry over almost unchanged to give $D_uL(\overline{u},\mu) = f'(\overline{u}) + \mu_b - \mu_a = 0$ \& the slackness conditions $(-\overline{u} - 1,\mu_a)_{L^2(0,1)} = (\overline{u} - 1,\mu_b)_{L^2(0,1)} = 0$. Consequently, $\mu_a$ \& $\mu_b$ are Lagrange multipliers for $\overline{u}$.

If we assume $u_d\in L^\infty(0,1)$, then both multipliers belong to $L^\infty(0,1)$. This nice byproduct of the pointwise construction follows from the fact that $\overline{u} - u_d\in L^\infty(0,1)$.

\begin{remark}
	The problem with 2-sided constraints could also be considered in the space $L^\infty(0,1)$, since in this case every admissible control $u$ is automatically bounded \& measurable. Moreover, the cone $K$ of nonnegative functions in $L^\infty(0,1)$ has interior points, \& $\widetilde{u}(x)\equiv 0$ satisfies the Slater condition. Theorem 6.1 then yields the existence of Lagrange multipliers $\mu_a,\mu_b\in L^\infty(0,1)^\star$. However, we do not gain much benefit from this result, since $L^\infty(0,1)^\star$ is a space of continuous linear functionals that need not even measures.
\end{remark}

\subsubsection{Differentiable problems}

\paragraph{Lagrange multiplier rules \& constraint qualifications.} We now investigate the problem (6.1) without assuming $f$ \& $G$ to be convex. We consider $\min f(u)$, $G(u)\le_K 0$, $u\in C$, where $C$ is still convex. Instead of convexity, we postulate the Fr\'echet differentiability of $f$ \& $G$. We use the same Lagrangian function $L = L(u,z^\star)$ as in Sect. 6.1.1, but, in view of the nonconvexity, we can no longer expect a saddle point property to be valid. Therefore, Lagrange multipliers are defined in a slightly different way.

\begin{definition}[Local solution]
	Let $\overline{u}\in U$ be admissible. We call $\overline{u}$ a \emph{local solution} of the minimization problem (6.1) if there is some $\varepsilon > 0$ s.t. $f(\overline{u})\le f(u)$, $\forall u\in C$ with $G(u)\le_K 0$ \& $\|u - \overline{u}\|_U\le\varepsilon$.
\end{definition}

\begin{definition}[Lagrange multiplier]
	Let $\overline{u}$ be a local solution to the problem (6.1). Then any $z^\star\in K^+$ satisfying the conditions \textbf{(6.9)--(6.10)}
	\begin{align*}
		D_uL(\overline{u},z^\star)(u - \overline{u})&\ge 0,\ \forall u\in C,\\
		\langle z^\star,G(\overline{u})\rangle_{Z^\star,Z} &= 0
	\end{align*}
	is called a \emph{Lagrange multiplier} associated with $\overline{u}$.
\end{definition}
In order that the existence of such a Lagrange multiplier be guaranteed, a so-called \textit{constraint qualification} must be postulated. Since such a condition involves the locally optimal control itself, it usually cannot be verified without knowledge of this function. There are various constraint qualifications. A rather general one, which suffices for our purposes, is the \textit{Zowe--Kurcyusz condition} (see Zowe \& Kurcyusz [ZK79]).

\begin{definition}
	Suppose that $\overline{u}\in C$ with $G(\overline{u})\le_K 0$ is given. We call the sets
	\begin{align*}
		C(\overline{u})\coloneqq\{\alpha(u - \overline{u});\alpha\ge 0,\ u\in C\},\ K(\overline{z})\coloneqq\{\beta(z - \overline{z});\beta\ge 0,\ z\in K\}
	\end{align*}
	the \emph{conical hulls} to $C$ \& $K$ at $\overline{u}$ \& $\overline{z}$, respectively. The condition \textbf{(6.11)}
	\begin{align*}
		G'(\overline{u})C(\overline{u}) + K(-G(\overline{u})) = Z
	\end{align*}
	is called the \emph{Zowe--Kurcyusz constraint qualification}.
\end{definition}
The above relation is obviously equivalent to saying that for any $z\in Z$ the equation \textbf{(6.12)} $\alpha G'(\overline{u})(u - \overline{u}) + \beta(v + G(\overline{u})) = z$ is solvable with suitable $u\in C$, $v\ge_K 0$, $\alpha\ge 0$, \& $\beta\ge 0$. Recall that $v\ge_K 0$ iff $v\in K$.

\begin{theorem}
	Let $\overline{u}$ be a local solution to problem (6.1), \& let $f$ \& $G$ be continuously Fr\'echet differentiable in an open neighborhood of $\overline{u}$. If the constraint qualification (6.11) holds, then there exists a Lagrange multiplier $z^\star\in Z^\star$ associated with $\overline{u}$. Moreover, the set of Lagrange multipliers associated with $\overline{u}$ is bounded.
\end{theorem}
The proof of this multiplier rule is due to Zowe \& Kurcyusz [ZK79]. From (6.9) it follows that \textbf{(6.13)}
\begin{align*}
	\langle f'(\overline{u}) + G'(\overline{u})^\star z^\star,u - \overline{u}\rangle_{U^\star,U}\ge 0,\ \forall u\in C.
\end{align*}

\begin{remark}
	Sometimes it is difficult or even meaningless to establish $G'(\overline{u})^\star$ in explicit form. Then (6.13) is replaced by the equivalent inequality
	\begin{align*}
		f'(\overline{u})(u - \overline{u}) + \langle z^\star,G'(\overline{u})(u - \overline{u})\rangle_{Z^\star,Z}\ge 0,\ \forall u\in C.
	\end{align*}
\end{remark}

\begin{example}
	Of particular interest is the minimization problem with both equality \& set constraints: \textbf{(6.14)} $\min f(u)$, $G(u)$, $u\in C$, where $f,G$, \& $C$ are defined as before. In this special case, the constraint qualification (6.11) reads \textbf{(6.15)} $G'(\overline{u})C(\overline{u}) = Z$. If it is satisfied, then a Lagrange multiplier $z^\star\in Z^\star$ exists s.t. the variational inequality (6.13) is valid. The complementary slackness condition (6.10) is meaningless for equality constraints.
	
	In Sect. 6.1.3, we will apply this result to the special case of $G(u) = Ay - Bv = 0$, where $A:Y\to Y^\star$ is a continuously invertible operator representing an elliptic differential operator, $y$ denotes the state, \& $v\in V_{\rm ad}\subset V$ is the control.
	
	In this case, we have $Z\coloneqq Y^\star$, $U\coloneqq Y\times V$, \& $C\coloneqq Y\times V_{\rm ad}$. The constraint qualification is always satisfied, since the equation $G'(\overline{u})(u - \overline{u}) = A(y - \overline{y}) + B(v - \overline{v}) = z$ is solvable for any $z\in Z = Y^\star$ with $v = \overline{v}$ \& $y = A^{-1}z + \overline{y}$. The element $u - \overline{u} = (y - \overline{y},\overline{v} - \overline{v})$ belongs to the cone $C(\overline{u})$.
\end{example}

\paragraph{Discussion of the Zowe--Kurcyusz constraint qualification.} In the following, we illustrate the application of condition (6.11) for various types of constraints, 1st in the general situation, \& then for pointwise constraints in function spaces.

\paragraph{Pure equality constraints $G(u) = 0$.} With $C = U$ \& $K = \{0\}$, (6.11) becomes \textbf{(6.16)} $G'(\overline{u})U = Z$. In other words, the operator $G'(\overline{u})$ must be surjective. This surjectivity requirement comes from the classical Lagrange multiplier rule for equality constraints. The relation (6.13) attains the form \textbf{(6.17)} $f'(\overline{u}) + G'(\overline{u})^\star z^\star = 0$.

\paragraph{Inequality constraints.} Let the constraints be given as in (6.1). If the minimizer $\overline{u}$ satisfies $G(\overline{u}) <_K 0$, i.e., if $-G(\overline{u})\in\operatorname{int}K$, then the constraint qualification (6.11) is fulfilled (Exercise 6.3). Since the constraint is not active, this case is not interesting.

The following \textit{linearized Slater condition} is sufficient for the Zowe--Kurcyusz constraint qualification (6.11) to hold: \textbf{(6.18)}
\begin{align*}
	\boxed{\exists\widetilde{u}\in C:\ G(\overline{u}) + G'(\overline{u})(\widetilde{u} - \overline{u}) <_K 0.}
\end{align*}
This is easily seen: the Zowe--Kurcyusz condition postulates for any $z\in Z$ the existence of constants $\alpha\ge 0$, $\beta\ge 0$ \& elements $k\in K$, $u\in C$ s.t. the equation $\alpha G'(\overline{u})(u - \overline{u}) + \beta(k + G(\overline{u})) = z$ is valid. To show this, put $\alpha = \beta$, $u = \widetilde{u}$, \& $\overline{z} = G(\overline{u}) + G'(\overline{u})(\widetilde{u} - \overline{u})$. Then the above equation reduces to $\alpha(\overline{z} + k) = z$ \&, since $K$ is a cone, to $\alpha\overline{z} + q = z$, with $q\in K$. Now we choose $\alpha$ so large that $z - \alpha\overline{z}\ge_K 0$. This is possible, because by (6.18) $\overline{z}$ lies in the interior of $-K$. With this, we satisfy the above condition with the choice $q = z - \alpha\overline{z}\ge_K 0$.

If both $K$ \& $C$ have interior points, then (6.18) is equivalent to the following condition (cf. Penot [Pen82]): \textbf{(6.19)} $\exists h\in\operatorname{int}C(\overline{u})$: $G(\overline{u}) + G'(\overline{u})h <_K 0$.

\paragraph{Equality \& inequality constraints.} Suppose the the constraints have the form $G_1(u) = 0$, $G_2(u)\le_K 0$, $u\in C$. Then the following condition is sufficient for (6.11) to hold (cf. [HPUU09], Lemma 1.14): $G_1'(\overline{u})$ is surjective, \& \textbf{(6.20)} $\exists h\in C(\overline{u})$: $G_1'(\overline{u})h = 0$, $G_2(\overline{u}) + G_2'(\overline{u})h <_K 0$.

As the following examples will show, the applicability of the Zowe--Kurcyusz constraint qualification to inequality constraints in function spaces is essentially restricted to cones of nonnegative functions with nonempty interior.

\paragraph{1-sided box constraints for $u$.} We begin our analysis with a problem involving 1-sided constraints: \textbf{(6.21)}
\begin{align*}
	\min f(u)\coloneqq\int_\Omega \psi(x,u(x))\,{\rm d}x,\ u(x)\le u_b(x)\mbox{ for a.e. } x\in\Omega.
\end{align*}
Here, $u_b\in L^\infty(\Omega)$ is given, \& the function $\psi$ is sufficiently smooth \& satisfies a suitable growth condition in order to guarantee that the given integral functional $f$ be continuous differentiable in $U = L^2(\Omega)$. The above minimization problem is of the form $\min f(u)$, $G(u) <_K 0$, with $G(u)(x)\coloneqq u(x) - u_b(x)$. As an affine continuous operator, $G$ is differentiable from $U$ into $Z = U$. The cone $K$ is given by the set of a.e. nonnegative elements of $L^2(\Omega)$.

In this case, the Zowe--Kurcyusz constraint qualification (6.11) is satisfied: in view of $C = L^2(\Omega)$, we have $C(\overline{u}) = L^2(\Omega)$. \& since $G'(\overline{u})$ is the identity mapping, for any $z\in L^2(\Omega)$ there is some $u\in L^2(\Omega) = C(\overline{u})$ s.t. $G'(\overline{u})u = z$: one simply chooses $u = z$.

Consequently, Theorem 6.3 may be applied in $L^2(\Omega)$, where, in view of the Riesz representation theorem, every $z^\star\in L^2(\Omega)^\star$ can be identified with some $\mu\in L^2(\Omega)$. Hence, for any local solution $\overline{u}$ there exists some a.e. nonnegative multiplier $\mu\in L^2(\Omega)$ s.t. $f'(\overline{u}) + G'(\overline{u})^\star\mu = 0$. We may identify $f'(\overline{u})$ with the function $\psi_u(\cdot,\overline{u}(\cdot))\in L^2(\Omega)$, \& $G'(\overline{u})^\star$ is the identity operator in $L^2(\Omega)$. We therefore find that $\psi_u(x,\overline{u}(x)) + \mu(x) = 0$, $\mu(x)\ge 0$, for a.e. $x\in\Omega$.

In this example, the Zowe--Kurcyusz condition was applicable even though the cone of nonnegative functions in $L^2(\Omega)$ had empty interior. This is in a certain sense an exceptional case. Alternatively, we could have constructed the multiplier directly as in (6.8) by setting $\mu(x) = (\psi_u(x,\overline{u}(x)))_-$.

\paragraph{2-sided box constraints for $u$.} We consider the same problem as above, but this time with the 2-sided control constraints $u_a(x)\le u(x)\le u_b(x)$ for a.e. $x\in\Omega$, with bounded \& measurable functions $u_a\le u_b$. We fit these constraints into the abstract framework of (6.1) by choosing the operator $G$ to be of the form $G(u) = (u_a - u,u - u_b)^\top$.

Evidently, $G$ is a continuously differentiable mapping from $L^2(\Omega)$ into $L^2(\Omega)\times L^2(\Omega)$. However, the Zowe--Kurcyusz constraint qualification cannot be directly satisfied in the form (6.11), as can be shown with a little effort. Again, we have the problem that the cone of nonnegative functions in $L^2(\Omega)$ has empty interior. It would also not be helpful to work in $L^\infty(\Omega)$ instead, since then we would at best obtain measures as multipliers for the control constraints. As in (6.8), a possible way out is to define Lagrange multipliers by $\mu_a(x)\coloneqq\psi_u(x,\overline{u}(x))_+$, $\mu_b(x)\coloneqq\psi_u(x,\overline{u}(x))_-$, with which the Karush--Kuhn--Tucker conditions are fulfilled.

\paragraph{2nd-order optimality conditions.} The scope of the Karush--Kuhn--Tucker theory in Banach spaces also encompasses 2nd-order necessary \& sufficient optimality conditions. For illustration, we only discuss the problem (6.14): $\min f(u)$, $G(u) = 0$, $u\in C$, additionally assuming that $f$ \& $G$ are twice continuously Fr\'echet differentiable. Suppose that $\overline{u}$ satisfies, together with $z^\star\in Z^\star$, the 1st-order necessary condition \textbf{(6.22)}
\begin{align*}
	f'(\overline{u})(u - \overline{u}) + \langle z^\star,G'(\overline{u})(u - \overline{u})\rangle_{Z^\star,Z}\ge 0,\ \forall u\in C.
\end{align*}
Moreover, let there exist some $\delta > 0$ s.t. \textbf{(6.23)}
\begin{align*}
	L''(\overline{u},z^\star)[u,u]\coloneqq f''(\overline{u})[u,u] + \langle z^\star,G''(\overline{u})[u,u]\rangle_{Z^\star,Z}\ge\delta\|u\|_U^2
\end{align*}
for all $u\in C(\overline{u})$ s.t. \textbf{(6.24)} $G'(\overline{u})u = 0$.

\begin{lemma}
	If $\overline{u}$ is admissible for problem (6.14) \& the conditions (6.22)--(6.24) are fulfilled, then $\overline{u}$ is locally optimal for (6.14).
\end{lemma}
These 2nd-order sufficient optimality conditions follow from general results due to Maurer \& Zowe [MZ79, Mau81]. The lemma applies only to problems in which the 2-norm discrepancy\footnote{\textbf{discrepancy} [n] (plural \textbf{discrepancies}) a difference between 2 or more things that should be the same.} does not play a role. Since we have not provided any further information concerning the structure of the set $C$, we are not in a position to define \& make use of strongly active constraints. The conditions above are thus too restrictive. In the case of inequality constraints of the form $G(u)\le_K 0$, 1st-order sufficient optimality conditions can also be employed; see [MZ79]. For PDEs with state constraints, refer to [CDlRT08]. In the case of pointwise constraints in function spaces, usually strongly active sets in the sense of Dontchev et al. [DHPY95] are used for this purpose.

\subsubsection{A semilinear elliptic problem}
Let $\Omega\subset\mathbb{R}^N$, $N\le 3$, be a bounded Lipschitz domain. For given $v\in L^2(\Omega)$, we consider the elliptic BVP
\begin{equation*}
	\left\{\begin{split}
		-\Delta y + y + y^3 &= v,&&\mbox{in }\Omega,\\
		\partial_{\bf n}y &= 0,&&\mbox{on }\Gamma.
	\end{split}\right.
\end{equation*}
As shown on pp.181--183, this problem is easy to handle in the state space $Y = H^1(\Omega)$. Introducing the mapping $A:Y\to Y^\star$ generated by the elliptic operator $-\Delta + I$, the \textit{Nemytskii operator} $\Phi:Y\to V = L^2(\Omega)$, $y(\cdot)\mapsto y(\cdot)^3$, \& the embedding operator $B:L^2(\Omega)\to Y^\star$, we can transform the above BVP into the equation $Ay + B\Phi(y) = Bv$ in $Y^\star$.

In the following, we are going to demonstrate how Theorem 6.3 \& Lemma 6.4 can be applied to a corresponding optimal control problem. To this end, we study the minimization of
\begin{align*}
	J(y,v)\coloneqq\frac{1}{2}\|y - y_\Omega\|_{L^2(\Omega)}^2 + \frac{\lambda}{2}\|v\|_{L^2(\Omega)}^2,
\end{align*}
subject to the above elliptic state problem \& to the control constraint $-1\le v(x)\le 1$ for almost every $x\in\Omega$. With the embedding operator $E_Y:H^1(\Omega)\to L^2(\Omega)$ \& the admissible set
\begin{align*}
	V_{\rm ad} = \{v\in L^2(\Omega);-1\le v(x)\le 1\mbox{ for a.e. } x\in\Omega\},
\end{align*}
we obtain the problem \textbf{(6.25)}
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\|E_Yy - y_\Omega\|_{L^2(\Omega)}^2 + \frac{\lambda}{2}\|v\|_{L^2(\Omega)}^2,
\end{align*}
subject to \textbf{(6.26)}
\begin{align*}
	Ay + B(\Phi(y) - v) = 0,\ v\in V_{\rm ad}.
\end{align*}
Obviously, this is a special case of the problem (6.14), $\min J(u)$, $G(u) = 0$, $u\in C$, with the specifications $U\coloneqq Y\times V$, $u\coloneqq(y,v)$, $G:Y\to Y^\star$, $G(u)\coloneqq Ay + B(\Phi(y) - v)$, \& $C\coloneqq Y\times V_{\rm ad}$.

\paragraph{1st-order necessary conditions.} \texttt{skipped \cite[pp. 336--337]{Troltzsch2010} $\ldots$}

\begin{remark}
	In applying the general result Theorem 6.3 in function spaces, usually a compromise has to be made between 2 conflicting restraints: in order that the constraint qualification be valid that, at the same time, the nonlinearities be differentiable, the range space $Z$ should not be too large; on the other hand, $Z$ also should not be too small, since otherwise the dual space $Z^\star$ becomes too large in the sense that it contains functions of low regularity that can no longer be interpreted as (weakly differentiable) solutions to adjoint problems.
\end{remark}

\paragraph{2nd-order sufficient conditions.} Since  the functional $J$ \& the Neymytskii operator $\Phi$ are twice continuously Fr\'echet differentiable in $H^1(\Omega)\times L^2(\Omega)$ \& $H^1(\Omega)$, respectively, so is the Lagrangian. Thus, in view of Lemma 6.4, the following condition is sufficient for local optimality: the pair $(\overline{u},\overline{v})$ satisfies both the 1st-order necessary conditions \& the definiteness condition
\begin{align*}
	L''(\overline{y},\overline{v},p)[(y,v),(y,v)]\ge\delta\left(\|y\|_{H^1(\Omega)}^2 + \|v\|_{L^2(\Omega)}^2\right)
\end{align*}
for all pairs $(y,v)$ satisfying the BVP
\begin{equation*}
	\left\{\begin{split}
		-\Delta y + y + 3\overline{y}^2y &= v,&&\mbox{in }\Omega,\\
		\partial_{\bf n}y &= 0,&&\mbox{on }\Gamma.
	\end{split}\right.
\end{equation*}
Then $\overline{v}$ is locally optimal in the sense of the norm of $L^2(\Omega)$. The above definiteness condition is already valid if we merely have, with a modified $\delta$, $L''(\overline{y},\overline{v},p)[(y,v),(y,v)]\ge\delta\|v\|_{L^2(\Omega)}^2$. The explicit expression for the 2nd derivative $L''$ is
\begin{align*}
	L''(\overline{y},\overline{v},p)[(y,v),(y,v)] = \|y\|_{L^2(\Omega)}^2 + \lambda\|v\|_{L^2(\Omega)}^2 - 6\int_\Omega p\overline{y}y^2\,{\rm d}x.
\end{align*}

\subsection{Control Problems with State Constraints}
``State constraints naturally arise in many applications. A typical example is that of heating problems in which the temperature is forbidden to exceed or fall short of certain prescribed threshold values. Such problems raise interesting, \& in parts still unsolved, mathematical questions. Here, we shall only briefly address some basic ideas in order to enable the reader to consult the relevant literature for a more in-depth study. For a comprehensive treatment of the elliptic case, we refer the reader to Neittaanm\"aki et al. [NST06]. For simplicity, we confine ourselves to elliptic problems; the theory for parabolic problems is quite similar.

The necessary optimality conditions to be proved below may also be derived from Pontryagin's maximum principle for state-constrained elliptic problems; for this purpose, the maximum condition is transformed into a variational inequality. In the case of boundary controls, the corresponding maximum principle was proved by Alibert \& Raymond [AR97] \& by Casas [Cas93]. The same applies to state-constrained parabolic problems, which were treated in Casas [Cas97] \& in Raymond \& Zidani [RZ99]. However, the proof of Pontryagin's maximum principle is very technical, while the optimality conditions to be presented here can be obtained much more simply by means of the Lagrange method in Banach spaces. This technique was employed also in the works of Casas [Cas86] \& Tr\"oltzsch [Tr\"o84b]. In the following, we apply it to derive 1st-order necessary conditions. We do not pursue 2nd-order sufficient conditions, referring the reader to the papers [CTU00] and [RT00]. Thus far, 2nd-order sufficient conditions for problems with pointwise state constraints in the whole domain could only be shown for low-dimensional domains; see Casas et al. [CDlRT08].'' -- \cite[Sect. 6.2, pp. 338--339]{Troltzsch2010}

\subsubsection{Convex problems}

\paragraph{An elliptic problem with pointwise state constraints.} Let $\Omega\subset\mathbb{R}^N$ denote a bounded Lipschitz domain. We consider the optimal control problem \textbf{(6.28)}
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\|y - y_\Omega\|_{L^2(\Omega)}^2 + \frac{\lambda}{2}\|u\|_{L^2(\Omega)}^2,
\end{align*}
subject to \textbf{(6.29)}
\begin{equation*}
	\left\{\begin{split}
		-\Delta y + y &= u,&&\mbox{in }\Omega,\\
		\partial_{\bf n}y &= 0,&&\mbox{on }\Gamma,
	\end{split}\right.
\end{equation*}
\& the constraints \textbf{(6.30)}
\begin{align*}
	u_a(x)\le u(x)&\le u_b(x)\mbox{ for a.e. } x\in\Omega,\\
	y(x)&\le 0,\ \forall x\in\overline{\Omega}.
\end{align*}

p. 339

\section{Supplementary Results on PDEs}

%------------------------------------------------------------------------------%

\chapter{Shape Optimization}

\section{Introduction}
``Shape Optimization was introduced around 1970 by Jean C\'ea \cite{Cea_Gioan_Michel1973}, who understood, after several engineering studies [127, 12, 35, 110, 102, 83, 84, 7],\footnote{(see refs. in \cite{Moubachir_Zolesio2006})}, the future issues in the context of optimization problems. At that time, he proposed a list of open problems at the French National Colloquium in Numerical Analysis. These new problems were formulated in terms of minimization of functionals (referred as \textit{open loop control} or \textit{passive control}) governed by partial differential BVPs where the control variable was the geometry of a given boundary part [103, 76]. From the beginning, the terminology \textit{shape optimization} was not connected to the structural mechanical sciences in which elasticity \& optimization of the compliance played a central role. Furthermore, these research studies were mainly addressed in the context of the numerical analysis of the FEMs.

At the same time, there was some independent close results concerning fluid mechanics by young researchers e.g. O. Pironneau [123, 124, 78], Ph. Morice [107] \& also several approaches related to perturbation theory by P.R. Garabedian [74, 75] \& D.D Joseph [91, 92].

Very soon, it appeared that the shape control of BVPs was at the crossroads of several disciplines such as PDE analysis, non-autonomous semi-group theory, numerical approximation (including FEMs), control \& optimization theory, geometry \& even physics. Indeed several classical modeling in both structural \& fluid mechanics (among other fields) needed to be extended. An illustrative example concerns a very \textit{popular} problem in the 80's concerning the thickness optimization of a plate modeled by the classical Kirchoff biharmonic equation. This kind of solid model is based on the assumption that the thickness undergoes only small variations. Therefore, many pioneering works were violating the validity of this assumption, leading to strange results, e.g., the work presented in the Iowa NATO Study [85] stating the existence of optimal beams having \textit{zero cross section} values.

In the \textit{branch} which followed the passive control approach, we shall mention the work of G. Chavent [32, 34] based on the theory of distributed system control introduced by J.-L. Lions \cite{Lions1971}. Those results did not address optimization problems related to the domain but instead related to the coefficients inside the PDE. At that time, it was hoped that the solution of elliptic problems would be continuous w.r.t. the weak convergence of the coefficients. It appeared that this property was not achieved by this class of problem\footnote{Indeed, in his thesis [33], G. Chavent referred to such a result to appear in a work by F. Murat [113]. That paper [111] appeared but as a counterexample to the expected continuity property. He showed on a 1D simple example that with weak \textit{oscillating} convergence of the coefficients, the associated solution was converging to another problem in which the new coefficients were related to the limit of the \textit{inverse} coefficients associated to the original problem [112, 114].} At that point a main \textit{bifurcation} arose with the homogenization approach [10] which up to some point was considered as a part of the \textit{Optimal Design} theory.

The mathematical analysis of shape optimization problems began with the correct definition of derivatives of functionals \& functions w.r.t. the domain, together with the choice of tangential space to the family of shapes. Following the very powerful theory developed by J. Ne\v{c}as [117], the role of bilipschitzian mapping was emphasized for Sobolev spaces defined in moving domains based on the Identity perturbation method [115, 106, 134]. Concerning the large domain deformation viewpoint the previous approach led to the incremental domain evolution methods [143].

After 1975, the 2nd author introduced [145] an asymptotic analysis for domain evolution using classical geometrical flows which are intrinsic tools for manifolds evolutions \& gave existence results for the so-called \textit{shape differential equation} (see also [79]). At that period, applications focused more on sensitivity analysis problems than on asymptotic analysis of domains evolution. In 1972, A.M. Micheletti introduced in parallel [105, 104] a metric based on the Identity perturbation method thanks to the use of differentiable mappings, in order to study eigenvalues perturbation problems. The associated topology was extended by M. Delfour et. al [52] \& turns out to be the same as the one induced by the continuity along flow field deformations [147].

The systematic use of flow mapping \& intrinsic geometry through the fundamental role of the oriented distance function [47, 50] led to the revised analysis of the elastic shell theory [48, 49, 25, 26, 27, 28], of the boundary layer theory [3] or of the manifold derivation tools [53].

The use of both Bounded Variation (BV) analysis \& the notion of Cacciapoli sets led to the 1st compactness method for domain sequences \& several extensions to more regular boundaries were done through the use of different concepts such as \textit{fractal boundaries, density parameter} [23, 20, 21, 19] or \textit{Sobolev domains} [50].

At that point, an other important \textit{bifurcation point} in that theory occurred with the relaxation theory \& the Special Bounded Variation (SBV) analysis which was particularly well adapted for image segmentation problem [6]. At the opposite, the capacity constraint for Dirichlet boundary conditions led to a fine analysis initiated in [18] \& is still going on for cracks analysis.

The method of large evolution based on the flow mapping (known from 1980 as the \textit{speed method} [150]) turns to be the natural setting for weak evolution of geometry allowing topological changes through the convection of either characteristic functions or oriented distance functions.'' -- \cite[Chap. 1, pp. 1--3]{Moubachir_Zolesio2006}

\subsection{Classical \& moving shape analysis}
``The classical shape analysis investigates the effects of perturbations of the geometry in terms of continuity, differentiability \& optimization of quantities related to the state of a system defined in that geometry. In this case, the geometry is usually perturbed thanks to a map involving a scalar parameter usually referred to as a fictitious time. On the contrary, the moving shape analysis deals with systems that are intrinsically defined on a moving geometry. Hence, we shall deal with sensitivity analysis w.r.t. a continuous famil of shapes over a given time period. In this context, if we consider the geometry in a space-time configuration, the moving shape analysis may also be referred to as a \textit{non-cylindrical shape analysis}\footnote{The notion of tube (non-cylindrical evolution domains) was also independently introduced by J.P. Aubin via the concept of \textit{abstract mutations} [8].}.

A 1st issue in this analysis is to model the evolution of the geometry. This is a common topic with the classical shape analysis. There exists many ways to build families of geometries. E.g., a domain can be made variable by considering its image by a family of diffeomorphisms parametrized by the time parameter as it happens frequently in mechanics for the evolution of continuous media. This way of defining the motion of domains avoids a priori the modification of the underlying topology. This change of topology can be allowed by using the characteristic function of families of sets or the level set of a space-time scalar function.'' Refer to \cite{Delfour_Zolesio2001, Delfour_Zolesio2011} for a complete review on this topic. ``In Chap. 2, we shall deal with the particular problem of defining in a weak manner the convection of a characteristic function in the context of the \textit{speed method} developed in Zol\'esio's PhD thesis [147].

In numbers of applications, we shall consider a state variable associated to a system which is a solution of a PDE defined inside the moving domain over a given time period. Hence, we need to analyze the solvability of this non-cylindrical PDE system before going further. Here, again this topic has been already studied since it enters the classical shape analysis problem while introducing a perturbed state defined in the moving domain parametrized by the fictitious time parameter. Furthermore, this solvability analysis has been performed in numbers of mathematical problems involving moving domains.'' Refer to [135, 51] for some particular results in the context of the classical shape analysis. Also refer to the extensive literature concerning the analysis of PDE systems defined in moving domains, e.g., [96, 126, 132, 62, 130, 88, 128, 70, 100, 11].

``Contrary to the last topic, very few references exist for the sensitivity analysis w.r.t. the perturbation of the evolution of the moving geometry. Early studies have been conducted in [90, 151, 158, 141, 120, 43, 142, 2] for specific hyperbolic \& parabolic linear problems. An important step was performed in [154, 155] where Zol\'esio established the derivative of integrals over a moving domain w.r.t. its associated Eulerian velocity. These results were applied in order to study variational principles for an elastic solid under large displacements \& the incompressible Euler equation. This work was generalized in [58, 59].'' -- \cite[Chap. 1, Sect. 1.1, pp. 3--4]{Moubachir_Zolesio2006}

\subsection{Fluid-Structure Interaction Problems}
``A general fluid--solid model consists of an elastic solid either surrounded by a fluid (aircrafts, automobiles, bridge decks, $\ldots$) or surrounding a fluid flow (pipelines, arteries, reservoir tanks, $\ldots$). Here the motion of the interface between the fluid \& the solid is part of the unknown of the coupled system. It is a free boundary problem that can be solved by imposing continuity properties through the moving interface (e.g., the kinematic continuity of the velocities \& the kinetic continuity of the normal stresses). This model has been intensively studied in the last 2 decades on the level of its mathematical solvability [87, 54, 82, 39, 80, 131, 15, 9, 138, 41], its numerical approximation [89, 55, 119, 118, 122, 95, 67], its stability [73, 38, 64, 65] \& more recently on its controllability [66, 109]. In this lecture note, we will restrict ourselves to viscous Newtonian incompressible fluid flows described by the NSEs in space dimension 2 or 3. The case of a compressible Newtonian fluid can be incorporated in the present framework with the price of a heavier mathematical analysis (solvability, non-differentiability around shocks $\ldots$).''

\textbf{Goal.} ``To solve inverse or control problems based on the previous general fluid-solid model. As an example, we think to decrease the drag of a car inside the atmospheric air flow by producing specific vibrations on its body using smart materials such as piezoelectrical layers. In this example, the control variable can be chosen as the electrical energy input evolution inside the piezoelectrical device \& the objective is to decrease the drag which is a function of the coupled fluid-structure state (the air \& the body of the car) \& this state depends on the control variable. In order to build a control law for the electrical input, we need to characterize the relationship between the drag function \& the control variable on the level of its computation \& its variations.

As an other example, we can think of the problem of aeroelastic stability of structures. Both authors have been dealing with such a problem in the context of the stability analysis against wind loads of bridge decks. In [108], it has been suggested that such a problem can be set as the inverse problem consisting in recovering the smallest upstream wind speed that leads to the worst bridge deck vibrations. In this example, the decision variable can be chosen as the upstream wind speed \& the objective is to increase a functional based on the vibration amplitude history of the bridge deck during a given characteristic time period which is a function of the coupled fluid-structure state (the wind flow \& the bridge deck) which is also a function of the decision variable. Again, in order to recover the wind speed history, we need to characterize the relationship between the objective functional \& the decision variable on the level of its computation \& its variations.

In order to characterize the sensitivity of the objective functional w.r.t. the control variable, it is obvious that we need to characterize the sensitivity of the coupled fluid-structure state w.r.t. the control variable. Here we recall that the coupled fluid-structure state is the solution of a system of PDEs that are coupled through continuity relations defined on the moving interface (the fluid-structure interface). The key point towards this sensitivity analysis is to investigate the sensitivity of the fluid state, which is an Eulerian quantity, w.r.t. the motion of the solid, which is a Lagrangian quantity. This task falls inside the moving shape analysis framework described earlier. Indeed the fluid state is the solution of system of nonlinear PDEs defined in a moving domain. The boundary of this moving domain is the solid wall. Then using the tools developed in [59], it has been possible to perform in [58] the moving shape sensitivity analysis in the case of a Newtonian incompressible fluid inside a moving domain driven by the non-cylindrical NSEs.

All the previous results use a parametrization of the moving domain based on the Lagrangian flow o a given velocity field. Hence, the design variable is the Eulerian velocity of the moving domain, allowing topology changes while using the associated level set formulation. In [13, 14], the author used a non-cylindrical identity perturbation technique. It consists in perturbating the space-time identity operator by a family of diffeomorphism. Then, this family is chosen as the design parameter. It is a Lagrangian description of the moving geometry, which a priori does not allow topology changes but which leads to simpler sensitivity analysis results which are are still comparable with the one obtained by the non-cylindrical \textit{speed method}. In [57], the authors came back to the dynamical shape control of the Navier-Stokes \& recovered the results obtained in [58] using the Min-Max principle allowing to avoid the state differentiation step w.r.t. the velocity of the domain.

Now, we come back to the original problem consisting in the sensitivity analysis of the coupled fluid-structure state w.r.t. the control variable. Using the chain rule, the derivative of the coupled state w.r.t. the control variable involves the partial derivative of the fluid state w.r.t. the motion of the fluid-structure interface already characterized in [58, 57]. Hence, again using a Lagrangian penalization technique, already used \& justified in [45, 46], it has been possible to perform in [109] the sensitivity analysis of a simple fluid-structure interaction problem involving a rigid solid within an incompressible flow of a Newtonian fluid w.r.t. the upstream velocity field. As already mentioned, this simple model is particularly suited for bridge deck aeroelastic stability analysis [121].'' -- \cite[Chap. 1, Sect. 1.2, pp. 4--6]{Moubachir_Zolesio2006}
\begin{itemize}
	\item ``\cite[Chap. 2]{Moubachir_Zolesio2006} furnishes a simple illustration to some of the moving shape analysis results reported in the core of the lecture note. We deal with a simple inverse problem arising in phase change problems consisting in recovering the moving interface at the isothermal interface between a solid \& liquid phase from measurements of the temperature on a insultated fixed part of the solid boundary. We use a least-square approach \& we show how to compute the gradient of the least-square functional w.r.t. the velocity of the moving interface. It involves an adjoint state problem together with an adjoint transverse state, which is the novelty of the moving shape analysis compared to the classical one.
	\item In \cite[Chap. 3]{Moubachir_Zolesio2006}, we consider the weak Eulerian evolution of domains through the convection, generated by a non-smooth vector field ${\bf V}$, of measurable sets. The introduction of transverse variations enables the derivation of functionals associated to evolution tubes. We also introduce Eulerian variational formulations for the minimal curve problem. These formulations involve a geometrical adjoint state $\lambda$ which is backward in time \& is obtained thanks to the use of the so-called \textit{transverse field} ${\bf Z}$.
	\item In \cite[Chap. 4]{Moubachir_Zolesio2006}, we recall the concept of shape differential equation developed in [145, 147]. Here, we present a simplified version \& some applications in 2D which enable us to reach the time asymptotic result. Furthermore, we introduce the associated level set formulation whose speed vector version was already contained in [149].
	\item In \cite[Chap. 5]{Moubachir_Zolesio2006}, we deal with a challenging problem in fluid mechanics which consists in the control of a Newtonian fluid flow thanks to the velocity evolution law of a moving wall. Here, the optimal control problem has to be understood as the open loop version, i.e., it consists in minimizing a given objective functional w.r.t. the velocity of the moving wall. This study is performed within the non-cylindrical Eulerian moving shape analysis described in Chaps. 2--3. We focus on the use of a Lagrangian penalization formulation in order to avoid the fluid state differentiation step.
	\item In \cite[Chap. 6]{Moubachir_Zolesio2006}, we introduce the Lagrangian moving shape analysis framework. It differs from the Eulerian one form the fact that the design variable is the diffeomorphism that parametrizes the moving geometry. The sensitivity analysis is simpler since it does not involve the transverse velocity field. We apply these tools in order to deal with the control of a Newtonian fluid flow thanks to the displacement evolution law of a moving wall.
	\item \cite[Chap. 7]{Moubachir_Zolesio2006} moves to inverse problems related to fluid-structure interaction systems. Here, we consider a 2D elastic solid with rigid displacements inside the incompressible flow of a viscous Newtonian fluid. We try to recover informations about the inflow velocity field from the partial measurements of the coupled fluid-structure state. We use a least-square approach together with a Lagrangian penalization technique. We derive the structure of the gradient w.r.t. the inflow velocity field of a given cost function. Using the Min-Max principle, the cost function gradient reduces to the derivative of the Lagrangian w.r.t. the inflow velocity at the saddle point. This saddle point is solution of 1st order optimality conditions. We use non-cylindrical Eulerian derivatives to compute the partial derivative of the Lagrangian functional w.r.t. the solid state variables, involved in the optimality system.
	\item In \cite[Chap. 8]{Moubachir_Zolesio2006} we extend the results of Chap. 7, to the case of an elastic solid under large displacements inside an incompressible fluid flow. The main difference with the previous case is the use of a non-cylindrical Lagrangian shape analysis for establishing the KKT system. It forms the adjoint counterpart of the sensitivity analysis conducted in [66].'' -- \cite[Chap. 1, Sect. 1.3, pp. 6--7]{Moubachir_Zolesio2006}
\end{itemize}
``$\ldots$ we shall describe the different steps encountered while designing a complex fluid-structure interaction system. Indeed, let us consider a mechanical system that consists of a solid \& a fluid interacting with each other. We would like to increase the performances of this system. These performances have to be quantitatively translated inside a cost function that we have to optimize w.r.t. some parameters that we will call the control variables. In the sequel, we will describe different control situations:
\begin{enumerate}
	\item \textit{Control of a fluid flow around a fixed body}: it consists in trying to modify the fluid flow pattern around a fixed body using a boundary control which can act e.g. by blowing or suctioning the fluid at some part of the solid boundary. The control law will be designed in order to match some efficiency goals using the minimization of a cost functional.
	\item \textit{Shape design of a fixed solid inside a fluid flow}: in this case, the control is the shape of the body. We would like to find the best shape satisfying some geometrical constraints that will optimize some cost functionals. This problem is somewhat classical in the aeronautical field, but it requires some subtle mathematical tools that we will quickly recall.
	\item \textit{Dynamical shape design of a solid inside a fluid flow}: the novelty compared to the last item is that the shape is moving \& we are looking for the best evolution of this shape that both satisfies some geometrical constraints \& optimizes some cost functionals. This is a rather natural technique in order to control a fluid flow pattern, but still its design requires some new mathematical tools that will be sketched in this introduction \& more detailed in the core of this lecture note.
	\item \textit{Control of an elastic solid inside a fluid flow}: this is the most complex \& most realistic situation where both the fluid \& the solid have their own dynamics which are coupled through the fluid-solid interface. Then, we would like to control or optimize the behavior of this coupled system thanks to boundary conditions. The mathematical analysis of this situation uses the whole framework introduced previously. This is a challenging problem, both on the mathematical point of view \& on the technological side. The goal of this book is to partially answer to some issues related to this problem.'' -- \cite[Chap. 1, Sect. 1.4, pp. 7--8]{Moubachir_Zolesio2006}
\end{enumerate}

\subsubsection{Control of a fluid flow around a fixed body}

\paragraph{The objective functional.} ``A common topic in the optimization \& control field of PDE systems is the choice of appropriate cost functionals, i.e., meeting both our objectives \& the mathematical requirements that guarantee the convergence to at least 1 optimum parameter. This functional can depend both on the state variables $({\bf u},p)$ \& on the control parameter ${\bf g}$.'' [$\ldots$] ``More generally, we can consider any cost functionals that are twice-differentiable w.r.t. their arguments.''-- \cite[Chap. 1, Subsect. 1.4.1, pp. 9--10]{Moubachir_Zolesio2006}

\paragraph{The control problem.} ``Our goal is now furnish the 1st-order optimality conditions associated to the optimization problem. These conditions are very useful since they are the basis in order to build both a rigorous mathematical analysis \& gradient-based optimization algorithms.

There exists 2 main methods in order to derive these conditions: the 1st one is based on the differentiability of the state variables w.r.t. the control parameter \& the 2nd one relies on the existence of Lagrangian multipliers.'' -- \cite[Chap. 1, Subsect. 1.4.1, p. 10]{Moubachir_Zolesio2006}

\paragraph{Sensitivity.} ``Let us consider a \textit{control point} ${\bf g}\in\mathcal{U}$, then the cost functional $j({\bf g})$ is Fr\'echet differentiable w.r.t. ${\bf g}$ \cite{Abergel_Temam1990}, [71] \& its directional derivative is given by \textbf{(1.9)}
\begin{align*}
	\langle j'({\bf g}),{\bf h}\rangle = \langle\partial_{({\bf u},p)}J[({\bf u},p)({\bf g})],({\bf u}',p')({\bf g};{\bf h})\rangle,\mbox{ where }({\bf u}',p')({\bf g};{\bf h})\coloneqq\frac{d}{d{\bf g}}({\bf u},p)({\bf g})\cdot{\bf h}
\end{align*}
stands for the directional derivative of $({\bf u},p)({\bf g})$ w.r.t. ${\bf g}$.'' [$\ldots$]

``Then the 1st-order optimality condition writes \textbf{(1.11)} $\langle j'({\bf g},{\bf h})\rangle = 0$, $\forall{\bf h}\in\mathcal{U}$. I.e., the set of optimal controls is contained in the set of critical points for the cost function $j({\bf g})$. However, we would like to obtain an expression of this condition avoiding the direction ${\bf h}\in\mathcal{U}$. To this end, we introduce the \textit{adjoint variable} $({\bf v},\pi)$ solution of the \textit{adjoint linearized Navier--Stokes system} \textbf{(1.12)}. Consequently, we are able to identify the gradient of the cost function as the trace on $\Gamma^c$ of the \textit{adjoint normal stress tensor}, i.e., \textbf{(1.13)}
\begin{align*}
	\nabla j({\bf g}) = {}^\star\gamma_{(0,\tau)\times\Gamma^c}[\sigma({\bf v},\pi)\cdot{\bf n}].
\end{align*}
This formal proof provides the basic steps needed in order to build a gradient-based optimization method associated to the control problem $\min_{{\bf g}\in\mathcal{U}} j({\bf g})$.

An alternative approach consists in avoiding the derivation of the fluid state $({\bf u},p)$ w.r.t. the control ${\bf g}$ thanks to the introduction of a Lagrangian functional that includes not only the cost functional but also the state equation, \textbf{(1.14)}
\begin{align*}
	\mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g}) = J(\boldsymbol{\psi},r) + \langle e(\boldsymbol{\psi},r;{\bf g}),(\boldsymbol{\phi},q)\rangle,
\end{align*}
where $\langle e({\bf u},p;g),(\boldsymbol{\phi},q)\rangle$ stands for the weak form of the state equation NSEs (1.8), e.g.,
\begin{align*}
	\langle e(\boldsymbol{\psi},r;{\bf g}),(\boldsymbol{\phi},q)\rangle =&\, \int_{(0,\tau)\times\Omega^f} [-\boldsymbol{\psi}\cdot\partial_t\boldsymbol{\phi} + ({\rm D}\boldsymbol{\psi}\cdot\boldsymbol{\psi})\cdot\boldsymbol{\phi} - \nu\boldsymbol{\psi}\cdot\Delta\boldsymbol{\phi} + \boldsymbol{\psi}\cdot\nabla q - r\nabla\cdot\boldsymbol{\phi}] + \int_{(0,\tau)\times\Gamma^c} {\bf g}\cdot(\sigma(\boldsymbol{\phi},q)\cdot{\bf n})\,{\rm d}\Gamma\,{\rm d}t\\
	&+ \int_{(0,\tau)\times\partial D} {\bf u}_\infty\cdot(\sigma(\boldsymbol{\phi},q)\cdot{\bf n}) + \int_{\Omega^f} \boldsymbol{\psi}(\tau)\cdot\boldsymbol{\phi}(\tau) - \int_{\Omega^f} {\bf u}_0\cdot\boldsymbol{\phi}(0).
\end{align*}
Hence the control problem $\min_{{\bf g}\in\mathcal{U}} j({\bf g})$ is equivalent to the $\min$-$\max$ problem, \textbf{(1.15)}
\begin{align*}
	\min_{{\bf g}\in\mathcal{U}}\min_{(\boldsymbol{\psi},r)}\max_{(\boldsymbol{\phi},q)} \mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g}).
\end{align*}
For every control ${\bf g}\in\mathcal{U}$, it can be proven that the $\min$-$\max$ problem,
\begin{align*}
	\min_{(\boldsymbol{\psi},r)}\max_{(\boldsymbol{\phi},q)} \mathcal{L}(\boldsymbol{\psi},r,\boldsymbol{\phi},q;{\bf g})
\end{align*}
admits a unique saddle-point $({\bf u},p;{\bf v},\pi)$ which are solutions of the systems (1.8)--(1.12). Finally the 1st-order optimality for the problem (1.15) writes \textbf{(1.16)}
\begin{align*}
	\partial_{\bf g}\mathcal{L}({\bf u},p,{\bf v},\pi;{\bf g}) = 0
\end{align*}
which turns out to be equivalent to (1.13). Then, we can think to solve the optimality condition (1.11), using a continuous iterative method. Indeed let us introduce a scalar parameter $s\ge 0$, \& a \textit{control variable} ${\bf g}(s)$ that is differentiable w.r.t. $s$. Hence using the differentiability of $J({\bf g})$, we get
\begin{align*}
	J({\bf g}(r)) - J({\bf g}(0)) = \int_0^r \langle\nabla J({\bf g}(s)),{\bf g}'(s)\rangle_{\mathcal{U}^\star,\mathcal{U}}\,{\rm d}s.
\end{align*}
Let us choose the control s.t. \textbf{(1.17)}
\begin{align*}
	{\bf g}'(s) + \mathbb{A}^{-1}(s)\nabla J({\bf g}(s)) = 0,\ s\in(0,r),
\end{align*}
where $\mathbb{A}$ stands for an appropriate duality operator, then the functional writes
\begin{align*}
	J({\bf g}(r)) - J({\bf g}(0)) = -\int_0^r |\nabla J({\bf g}(s))|^2\,{\rm d}s.
\end{align*}
I.e., the control law (1.17) leads to a functional's decrease \& is referred to as a continuous gradient based optimization method. Using a discretization of the parameter $s$ leads to a standard gradient-based method such as the conjugate-gradient or the quasi-Newton method depending on the choice of $\mathbb{A}(s)$.'' -- \cite[Chap. 1, Subsect. 1.4.1, pp. 11--12]{Moubachir_Zolesio2006}

\subsubsection{Shape design of a fixed solid inside a fluid flow}
``We again consider the situation where a fixed solid is surrounded by a fluid flow. The shape control consists in finding the optimal shape of the solid that reduces some objective functional (e.g., the drag) under some perimeter, volume or curvature constraints. This optimization is an open-loop control since the shape of the obstacle is time-independent.''

\paragraph{The speed method.} ``Here the space of shapes is no more a linear space \& the associated differential calculus becomes more tricky. Our goal is to build \textit{gradient-based methods} in order to find the optimal shape, i.e., we would like to solve the following problem, \textbf{(1.18)} $\min_{\Omega\in\mathcal{A}} J(\Omega)$. In order to carry out the sensitivity analysis of functionals depending on the shape of the solid $\Omega$, we introduce a family of pertubated domains $\Omega_s\subset D$ parametrized by a scholar parameter $0\le s\le\varepsilon$. These domains are the images of the original domain $\Omega$ through a given family of smooth maps\footnote{Typically we have the following Lipschitz regularity assumptions:
\begin{align*}
	{\bf T}(\cdot,{\bf x})&\in\mathcal{C}^1([0,\varepsilon];\mathbb{R}^3),\ \forall{\bf x}\in D,\ \|{\bf T}(\cdot,{\bf x}) - {\bf T}(\cdot,{\bf y})\|_{\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3)}\le C\|{\bf x} - {\bf y}\|_{\mathbb{R}^3},\\
	{\bf T}^{-1}(\cdot,{\bf x})&\in\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3),\ \forall{\bf x}\in D,\ \|{\bf T}^{-1}(\cdot,{\bf x}) - {\bf T}^{-1}(\cdot,{\bf y})\|_{\mathcal{C}^0([0,\varepsilon];\mathbb{R}^3)}\le C\|{\bf x} - {\bf y}\|_{\mathbb{R}^3},
\end{align*}
where $C > 0$.} ${\bf T}_s:\overline{D}\to\overline{D}$, i.e. $\Omega_s = {\bf T}_s(\Omega)$, $\Gamma_s = {\bf T}_s(\Gamma)$.

2 major classes of such mappings are given by:
\begin{itemize}
	\item the \textit{identity perturbation method} ([116, 125]), ${\bf T}_s = {\rm I} + s\boldsymbol{\theta}$, where $\boldsymbol{\theta}:\overline{D}\to\overline{D}$.
	\item the \textit{speed method} [145] \cite{Pironneau1984}, where the transformation is the flow associated to a given velocity field ${\bf V}(s,{\bf x})$,
	\begin{equation*}
		\left\{\begin{split}
			\partial_s{\bf T}_s({\bf x}) &= {\bf V}(s,{\bf T}_s({\bf x})),&&(s,{\bf x})\in(0,\varepsilon)\times D,\\
			{\bf T}_{s=0}({\bf x}) &= {\bf x},&&{\bf x}\in D.
		\end{split}\right.
	\end{equation*}
	In order for $\overline{D}$ to be globally invariant under ${\bf T}_s({\bf V})$ we need to impose the following \textit{viability conditions}, ${\bf V}(s,{\bf x})\cdot{\bf n}({\bf x}) = 0$, ${\bf x}\in\partial D$.
\end{itemize}
Let us consider the family of functionals $J(\Omega_s)$ that depends on the shapes $\Omega_s$, e.g., the work to overcome the drag exerted by the fluid on the solid boundary, \textbf{(1.19)}
\begin{align*}
	J_{\rm drag}(\Omega) = \int_{(0,\tau)\times\Gamma} ({\bf u} - {\bf u}_\infty)\cdot\sigma({\bf u},p)\cdot{\bf n}\,{\rm d}\Gamma\,{\rm d}t.
\end{align*}
This functional depends on $\Omega$ not only because it is an integral over the boundary $\Gamma$, but also because it involves the solution $({\bf u},p)$ of the Navier--Stokes system, \textbf{(1.20)}, that depends on $\Omega$.

To perform our sensitivity analysis, we choose to work in the framework of the \textit{speed method}\footnote{which leads, at least for the 1st order terms, to the same results as the identity perturbation framework [51].} We define the Eulerian derivative of the shape functional $J(\Omega)$ at point $\Omega$ in the direction of the vector field ${\bf V}\in\mathcal{V}$ as the limit,
\begin{align*}
	dJ(\Omega;{\bf V}) = \lim_{s\downarrow 0} \frac{J(\Omega_s({\bf V})) - J(\Omega)}{s},
\end{align*}
where $\mathcal{V}$ is a linear space\footnote{e.g., $\mathcal{V}\coloneqq\{{\bf V}\in\mathcal{C}^0(0,\varepsilon;\mathcal{C}^1(D;\mathbb{R}^3)),\ \nabla\cdot{\bf V} = 0\mbox{ in } D,\ \langle{\bf V},{\bf n}\rangle = 0\mbox{ on }\partial D\}$.} If this limit exists \& is finite $\forall{\bf V}\in\mathcal{V}$ \& the mapping $\mathcal{V}\to\mathbb{R}$, ${\bf V}\mapsto dJ(\Omega;{\bf V})$ is linear \& continuous, then the functional $J(\Omega)$ is said to be \textit{shape differentiable}.

Actually if $J(\Omega)$ is shape differentiable, then its Eulerian derivative only depends on ${\bf V}(0)$ \& there exists a distribution ${\bf G}(\Omega)\in\mathcal{D}(D;\mathbb{R}^3)'$ that we call the \textit{shape gradient} s.t.
\begin{align*}
	dJ(\Omega;{\bf V}) = \langle{\bf G}(\Omega),V(0)\rangle,\ \forall{\bf V}\in\mathcal{V}.
\end{align*}
In the sequel, we shall use the notation $\nabla J(\Omega)\coloneqq{\bf G}(\Omega)$. In the case of smooth domain, the gradient is only supported on the boundary $\Gamma$ \& depends linearly on the normal vector field ${\bf n}$. This result, called the \textit{structure theorem}\footnote{Refer to \cite[Theorem 3.5]{Delfour_Zolesio2001} for the case of non-smooth domains.}, is recalled as follows,

\begin{theorem}[Shape derivative structure theorem]
	Let $J(\cdot)$ be a differentiable shape functional at every shape $\Omega$ of class $\mathcal{C}^{k+1}$ for $k\ge 0$ with shape gradient ${\bf G}(\Omega)\in\mathcal{D}(D;\mathbb{R}^3)'$. In this case, the shape gradient has the following representation,
	\begin{align*}
		{\bf G}(\Omega) = {}^\star\gamma_\Gamma(g{\bf n}),
	\end{align*}
	where $g(\Gamma)\in\mathcal{D}^{-k}(\Gamma)$ stands for a scalar distribution \& ${}^\star\gamma_\Gamma$ stands for the adjoint trace operator\footnote{i.e.,
	\begin{align*}
		\langle{}^\star\gamma_\Gamma(g{\bf n}),{\bf V}\rangle_{\mathcal{D}(D;\mathbb{R}^3)',\mathcal{D}(D;\mathbb{R}^3)} = \langle g,{\bf V}\cdot{\bf n}\rangle_{\mathcal{D}'(\Gamma),\mathcal{D}(\Gamma)}.
	\end{align*}}.
\end{theorem}
This result is easier to understand when $g(\Gamma)$ is integrable over $\Gamma$, that is to say, $g\in L^1(\Gamma)$. Indeed in this case, it means that the directional shape derivative can always be written as follows,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Gamma g{\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
\end{align*}

\paragraph{Basic shape derivative calculus.} The notion of Eulerian derivative for shape functionals can be extended to functions defined on Banach or Hilbert spaces built on smooth domains $\Omega$. Hence, a function $y\in H(\Omega)$ admits a \textit{material derivative} at $\Omega$ in the direction ${\bf V}\in\mathcal{V}$ if the following limit
\begin{align*}
	\dot{y}(\Omega;{\bf v})\coloneqq\lim_{s\to 0} \frac{1}{s}[y(\Omega_s({\bf V}))\circ{\bf T}_s({\bf V}) - y(\Omega)]
\end{align*}
admits a limit in the Hilbert space\footnote{e.g., $W^{m,p}(\Omega)$  or $L^2(0,\tau;W^{m,p}(\Omega))$.} $H(\Omega)$.

Endowed with the following definition, it is possible to derive the Eulerian shape derivative of the following functionals,
\begin{align*}
	J(\Omega) = \int_\Omega y(\Omega)\,{\rm d}\Omega.
\end{align*}
If $y(\Omega)$ is weakly shape differentiable in $L^1(\Omega)$, then the functional $J(\Omega)$ is shape differentiable \& its directional derivative writes,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega [\dot{y}(\Omega;{\bf V}) + y(\Omega)\nabla\cdot{\bf V}(0)]\,{\rm d}\Omega.
\end{align*}
In order to apply the structure theorem, it is useful to define the notion of shape derivative for functions. Hence, if $y\in H(\Omega)$ admits a material derivative $\dot{y}(\Omega;{\bf V})\in H(\Omega)$ \& $\nabla y\cdot{\bf V}(0)\in H(\Omega)$ for all ${\bf V}\in\mathcal{V}$, we define the \textit{shape derivative} as
\begin{align*}
	y'(\Omega;{\bf V}) = \dot{y}(\Omega;{\bf V}) - \nabla y(\Omega)\cdot{\bf V}(0).
\end{align*}
In this case, the Eulerian shape derivative of $J(\Omega)$ takes the following form,
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega [y'(\Omega;{\bf V}) + \nabla\cdot(y(\Omega){\bf V}(0))]\,{\rm d}\Omega.
\end{align*}
If $\Omega$ is class $\mathcal{C}^k$ with $k\ge 1$, then using the Stokes formula, we get
\begin{align*}
	dJ(\Omega;{\bf V}) = \int_\Omega y'(\Omega;{\bf V}) + \int_\Gamma y(\Omega){\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
\end{align*}

\begin{remark}
	In the case where $y(\Omega) = Y|_\Omega$, where $Y\in H(D)$ with $\Omega\subset D$, its shape derivative is zero since $\dot{y}(\Omega;{\bf V}) = \nabla Y\cdot{\bf V}$. Hence,
	\begin{align*}
		dJ(\Omega;{\bf V}) = \int_\Gamma y(\Omega){\bf V}\cdot{\bf n}\,{\rm d}\Gamma.
	\end{align*}
	This is a simple illustration of the structure theorem.
\end{remark}
In the case of functionals involving integration over the boundary $\Gamma$, we need to introduce the notion of \textit{material derivative} on $\Gamma$.

Let $z\in W(\Gamma)$ where $W(\Gamma)$ is an Hilbert space of functions (e.g., $W^{m,p}(\Gamma)$) defined over $\Gamma$. It is said that it admits a material derivative in the direction ${\bf V}\in\mathcal{V}$, if the following limit,
\begin{align*}
	\dot{z}(\Gamma;{\bf V})\coloneqq\lim_{s\to 0} \frac{1}{s}[z(\Gamma_s({\bf V}))\circ{\bf T}_s({\bf V}) - z(\Gamma)]
\end{align*}
admits a limit in the Hilbert space $W(\Gamma)$.

As a consequence of this definition, it is possible to derive the Eulerian shape derivative of the following functional,
\begin{align*}
	J(\Gamma) = \int_\Gamma z(\Gamma)\,{\rm d}\Gamma.
\end{align*}
If $z(\Gamma)$ is weakly shape differentiable in $L^1(\Omega)$, then the functional $J(\Gamma)$ is shape differentiable \& its directional derivative writes
\begin{align*}
	dJ(\Gamma;{\bf V}) = \int_\Gamma [\dot{z}(\Gamma;{\bf V}) + z(\Gamma)\operatorname{div}_\Gamma{\bf V}(0)]\,{\rm d}\Gamma,
\end{align*}
where
\begin{align*}
	\operatorname{div}_\Gamma{\bf V}\coloneqq\gamma_\Gamma[\nabla\cdot{\bf V} - ({\rm D}{\bf V}\cdot{\bf n})\cdot{\bf n}]
\end{align*}
stands for the \textit{tangential divergence}.

As in the previous case, it is also possible to introduce the notion of shape derivative for $z(\Gamma)$. Let $\Omega$ be of class $\mathcal{C}^k$ with $k\ge 2$. If $z\in W(\gamma)$ admits a material derivative $\dot{z}(\Gamma;{\bf V})\in W(\Gamma)$ \& $\nabla_\Gamma y\cdot{\bf V}(0)\in W(\Gamma)$ for all ${\bf V}\in\mathcal{V}$, we define the \textit{shape derivative} as
\begin{align*}
	z'(\Gamma;{\bf V}) = \dot{z}(\Gamma;{\bf V}) - \nabla_\Gamma z(\Gamma)\cdot{\bf V}(0)\mbox{ where }\nabla_\Gamma z = \nabla Z|_\Gamma - (\nabla Z\cdot{\bf n}){\bf n}
\end{align*}
stands for the \textit{tangential gradient} \& $Z$ is any smooth extension of $z$ inside $\Omega$.

Using the above definition, it is possible to transform the expression of the differential as follows,
\begin{align*}
	dJ(\Gamma;{\bf V}) = \int_\Gamma [z'(\Gamma;{\bf V}) + Hz(\Gamma){\bf V}(0)\cdot{\bf n}]\,{\rm d}\Gamma,
\end{align*}
where $H$ stands fro the \textit{mean curvature} of $\Gamma$.

\begin{remark}
	In the case where $z(\Gamma) = y(\Omega)|_\Gamma$, the Eulerian derivative takes the following form,
	\begin{align*}
		dJ(\Gamma;{\bf V}) = \int_\Gamma [y'(\Omega;{\bf V}) + (\nabla y(\Omega)\cdot{\bf n} + Hz(\Gamma){\bf V}(0)\cdot{\bf n})]\,{\rm d}\Gamma.
	\end{align*}
\end{remark}

\paragraph{Application to shape design.} Thanks to the framework introduced previously, it is possible to build a complete sensitivity analysis of shape functionals. Coming back to our optimal shape problem, we can state the following: the shape gradient for the tracking functional
\begin{align*}
	J(\Omega) = \int_{(0,\tau)\times\Omega} ({\bf u} - {\bf u}_d)^2\,{\rm d}{\bf x}\,{\rm d}t
\end{align*}
is given by \textbf{(1.21)}
\begin{align*}
	\nabla J(\Omega) = {}^\star\gamma_\Gamma[\sigma({\bf v},\pi)\cdot{\bf n}]
\end{align*}
where $({\bf u},p)$ is a solution of system (1.20) associated to the shape $\Omega$ \& $({\bf v},\pi)$ is solution of the adjoint system \textbf{(1.22).}

\paragraph{The associated shape differential equation.} Now as in the previous section, we can choose to solve the 1st-order optimality equation (1.21) using a continuous gradient-based method. I.e., we write
\begin{align*}
	J(\Omega_r({\bf V})) - J(\Omega_0) = \int_0^r \langle\nabla J(\Omega_s({\bf V})),{\bf V}(s)\rangle\,{\rm d}s.
\end{align*}
Then solving the equation \textbf{(1.23)}
\begin{align*}
	\nabla J({\bf V}(s)) + \mathbb{A}^{-1}(s)\cdot{\bf V}(s) = 0,\ s\in(0,+\infty)
\end{align*}
leads to a decrease of the functional $J(\Omega_s({\bf V}))$. The equation (1.23) is referred to as the \textit{shape differential equation} \& some of its properties are studied in \cite[Chap. 4]{Moubachir_Zolesio2006}. Notably, we study its solvability in the case of smooth shape functionals. We also prove some results concerning the asymptotic behavior of the solution of this equation, which hold essentially when the shape gradient has some continuity properties for an \textit{ad-hoc} shape topology\footnote{The Hausdorff-complementary topology.}.

\paragraph{The level-set framework.} In Chap. 4, we also relate the shape differential equation to the Hamilton--Jacobi equation involved in the level-set setting. The level-set setting consists in parametrizing the perturbed domain $\Omega_s$ as the positiveness set of a scalar function $\Phi:(0,\varepsilon)\times\overline{D}\to\mathbb{R}$,
\begin{align*}
	\Omega_s = \Omega_s(\Phi)\coloneqq\{{\bf x}\in D,\ \Phi(s,{\bf x}) > 0\},
\end{align*}
\& its boundary is the zero-level set,
\begin{align*}
	\Gamma_s = \Gamma_s(\Phi)\coloneqq\{{\bf x}\in D,\ \Phi(s,{\bf x}) = 0\}.
\end{align*}
This parametrization \& the one introduced in the \textit{speed method} can be linked thanks to the following identity,
\begin{align*}
	{\bf V}(s) = -\partial_s\Phi(s)\frac{\nabla\Phi(s)}{\|\nabla\Phi(s)\|^2}.
\end{align*}
Both frameworks are equivalent if $\Phi(s)$ belongs to set of functions without steps, i.e., $\|\nabla\Phi(s)\|$ is different from zero a.e. in $D$. We show how to build without step functions \& we study the shape differential equation in this setting.'' -- \cite[Chap. 1, Subsect. 1.4.2, pp. 13--19]{Moubachir_Zolesio2006}

\subsubsection{Dynamical shape design of a solid inside a fluid flow}
``$\ldots$ we consider that the shape of the solid is moving.'' \textbf{Goals.} to control this motion in order to optimize some objective functionals; to build gradient-based methods in order to find the optimal shape dynamic, i.e., we would like to solve the following problem, \textbf{(1.24)} $\min_{Q\in\mathcal{E}} J(Q)$ where $Q\in\mathcal{E}$ is a smooth evolution set, which means
\begin{align*}
	Q\coloneqq\bigcup_{t\in(0,\tau)} \{t\}\times\Omega_t,
\end{align*}
where $\Omega_t$ is a smooth domain of $\mathbb{R}^3$ with boundary $\Gamma_t$. The set,
\begin{align*}
	\Sigma\coloneqq\bigcup_{t\in(0,\tau)} \{t\}\times\Gamma_t
\end{align*}
stands for the \textit{non-cylindrical lateral boundary}. We call the set $Q$ a \textit{tube}.

\paragraph{The $\mathbb{R}^{d+1}$-approach.} ``The optimal control of moving domain is a problem which is relevant of classical (nonlinear) control theory as well as of classical shape theory. In fact on the pure theoretical level, the dynamical shape control theory can be viewed as an application of the shape optimization theory for space-time manifolds.'' \textsf{Fig. Non-cylindrical space-time domain.} ``Indeed the dynamical shape control consists in finding the optimal evolution of a spatial domain $\Omega_t$ in $\mathbb{R}^d$. Let us consider the mapping $\mathcal{S}:t\in\mathbb{R}\to\Omega_t\in\mathcal{P}(\mathbb{R}^d)$ where $\mathcal{P}(\mathbb{R}^d)$ stands for the set of parts inside $\mathbb{R}^d$. Usually we would like to minimize some cost functional,
\begin{align*}
	j(\mathcal{S}) = \int_0^\tau J(t,\mathcal{S}(t))\,{\rm d}t.
\end{align*}
Obviously, it is equivalent to the problem of finding the optimal tube
\begin{align*}
	Q = \bigcup_{0 < t < \tau} \{t\}\times\Omega_t\in\mathbb{R}^{d+1}.
\end{align*}
In fact the tube $Q$ is the graph in $\mathbb{R}\times\mathcal{P}(\mathbb{R}^d)\subset\mathbb{R}^{d+1}$ of the shape mapping $\mathcal{S}$. As for usual mappings defined from $\mathbb{R}$ in some space $E$, the graph $G\subset\mathbb{R}\times E$ \& of course any subset $G$ is not a graph. Now under simple conditions on that set $G$, it becomes a graph. In the same way, any subset $Q\in\mathbb{R}\times\mathcal{P}(\mathbb{R}^d)$ will not be a tube. Intuitively we would say that we require some \textit{causality} in the evolution of the set $\Omega_t$.

When the boundary of the set $\Omega_t$ is smooth enough\footnote{say there exists a tangent space.}, the idea is to avoid the normal field $\nu$ to the lateral boundary $\Sigma$ of the tube to be strictly vertical. To handle non-smooth situations, we adopt an Eulerian viewpoint that associates to each tube $Q$ the non-empty closed convex set of speed vector fields ${\bf V}$ which transport (in a weak sense) the characteristic function of the moving domain. When we consider the tube $Q$ as a subset of $\mathbb{R}^{d+1}$, the control problems becomes a usual shape optimization problem (as far as no real time consideration enters). The sensitivity analysis is then classically performed by considering \textit{horizontal} vector fields $\widetilde{\bf Z}(s,t,{\bf x}) = (0,{\bf Z}(s,t,{\bf x}))\in\mathbb{R}^{d+1}$ where $s$ is the \textit{perturbation parameter} of the tube.

Then the $(d + 1)$-dimensional shape optimization analysis fully applies \& the so-called \textit{Shape Differential Equation} furnishes descent direction, i.e., it furnishes the existence of a vector field ${\bf Z}^\star$ s.t., for some $\alpha > 0$,
\begin{align*}
	J(Q_s)\le J(Q) - \alpha\int_0^s \|{\bf Z}^\star(\sigma)\|^2\,{\rm d}\sigma,\ \forall s > 0.
\end{align*}
We show that the existence of that field ${\bf Z}^\star$ induces the existence of a usual vector field ${\bf V}(t,{\bf x})\in\mathbb{R}^d$ which builds that tube, i.e., $\Omega_t = {\bf T}({\bf V})(\Omega_0)$.

\paragraph{The $\mathbb{R}^d$-approach.} In order to carry out the sensitivity analysis of functionals depending on the tube $Q$, we assume that the domains are the images of the domain $\Omega_0\coloneqq\Omega_{t = 0}$ through a given family of smooth maps ${\bf T}_t:\overline{D}\to\overline{D}$, i.e., $\Omega_t = {\bf T}_t(\Omega_0)$, $\Gamma_t = {\bf T}_t(\Gamma_0)$. 2 major class of such mappings are given by:
\begin{itemize}
	\item the \textit{Lagrangian parametrization} ${\bf T}_t = \boldsymbol{\theta}(t,\cdot)$ where $\boldsymbol{\theta}:(0,\tau)\times\overline{D}\to\overline{D}$. In this case, the minimization problem (1.24) can be transformed as \textbf{(1.25)} $\min_{\boldsymbol{\theta}\in\Theta} J(Q(\boldsymbol{\theta}))$.
	\item the \textit{Eulerian parametrization}, where the transformation is the flow associated to a given velocity field ${\bf V}(t,{\bf x})$,
	\begin{equation*}
		\left\{\begin{split}
			\partial_t{\bf T}_t({\bf x}) &= {\bf V}(t,{\bf T}_t({\bf x})),&&(t,{\bf x})\in(0,\tau)\times D,\\
			{\bf T}_{t=0}({\bf x}) &= {\bf x},&&{\bf x}\in D.
		\end{split}\right.
	\end{equation*}
	In this case, the minimization problem (1.24) can be transformed as \textbf{(1.26)} $\min_{{\bf V}\in\mathcal{V}} J(Q({\bf V}))$.
\end{itemize}

\paragraph{Existence of tubes.} In the smooth case, the existence of tubes follows the Cauchy--Lipschitz theory on differential equations [147], \cite{Delfour_Zolesio2001}. In the non-smooth case, the Lipschitz regularity of the velocities ${\bf V}$ can be weakened using the equations satisfied by the characteristic functions $\xi(t,{\bf x})$ associated to the domain $\Omega_t({\bf V})$, \textbf{(1.27)}
\begin{equation*}
	\left\{\begin{split}
		\partial_t\xi + \nabla\xi\cdot{\bf V} &= 0,&&(0,\tau)\times D,\\
		\xi_{t=0} &= \chi_\Omega,&& D.
	\end{split}\right.
\end{equation*}
We shall consider velocity fields s.t. ${\bf V}\in L^1(0,\tau;L^2(D;\mathbb{R}^d))$ \& the divergence positive part $(\nabla\cdot{\bf V})^+\in L^1(0,\tau;L^\infty(D))$. In this case, using a Galerkin approximation \& some energy estimates, we are able to derive an existence result of solutions with initial data given in $H^{-1/2}(D)$. For the time being, no uniqueness result has been obtained for this smoothness level.

Actually, when the field ${\bf V}$ \& its divergence are simply $L^1$ functions, the notion of weak solutions associated to the convection problems (1.27) does not make sense. In this case, the correct modeling tool for shape evolution is to introduce the product space of elements $(\xi = \xi^2,{\bf V})$ equipped with a parabolic BV like topology for which the constraint (1.27) defines a closed subset $\mathcal{T}_\Omega$ which contains the weak closure of smooth elements
\begin{align*}
	\mathcal{T}_\Omega\coloneqq\{(\chi_\Omega\circ{\bf T}_t^{-1}({\bf V}),{\bf V});{\bf V}\in\mathcal{U}_{\rm ad}\}.
\end{align*}
This approach consists in handling characteristic functions $\xi = \xi^2$ which belongs to $L^1(0,\tau;\operatorname{BV}(D))$ together with vector fields ${\bf V}\in L^2(0,\tau;L^2(D,\mathbb{R}^d))$ solution of problem (1.27). For a given element $(\xi,{\bf V})\in\mathcal{T}_\Omega$, we consider the set of fields ${\bf W}$ s.t. $(\xi,{\bf W})\in\mathcal{T}_\Omega$, we consider the set of fields ${\bf W}$ s.t. $(\xi,{\bf W})\in\mathcal{T}_\Omega$. It forms a closed convex set, noted $\mathcal{V}_\xi$. Hence, we can define the unique minimal norm energy element ${\bf V}_\xi$ in the convex set $\mathcal{V}_\xi$. For a given tube $\xi$, the element ${\bf V}_\xi$ is the unique (with minimal norm) vector field associated to $\xi$ via the convection equation (1.27).

We choose to adopt a different point of view inspired by the optimization problems framework. Indeed, our final goal is to apply the weak set evolution setting to the control problem arising in various fields such as free boundary problems or image processing. The usual situation can be described as follows. Let us consider a given smooth enough functional $J(\xi,{\bf V})$. We would like to solve the following optimization problem \textbf{(1.28)} $\inf_{(\xi,{\bf V})\in\mathcal{T}_\Omega} J(\xi,{\bf V})$. The space $\mathcal{U}_{\rm ad}$ is a space of smooth velocities.

In most situations, such a problem does not admit solutions \& we need to add some regularization terms to ensure its solvability. Consequently, we shall introduce different penalization terms which furnish compactness properties of the minimizing sequences inside an ad-hoc weak topology involving bounded variation constraints. Then, the new problem writes \textbf{(1.29)}
\begin{align*}
	\inf_{(\xi,{\bf V})\in\mathcal{T}_\Omega} J(\xi,{\bf V}) + F(\xi,{\bf V}).
\end{align*}
The \textit{penalization term} $F(\xi,{\bf V})$ can be chosen using several approaches:
\begin{itemize}
	\item We can 1st consider the time-space perimeter of the lateral boundary $\Sigma$ of the tube, developed in [155]. This approach easily draws part of the variational properties associated to the bounded variation functions space framework. In particular, it uses the compactness properties of tube family with bounded perimeters in $\mathbb{R}^{d+1}$. Nevertheless, this method leads to heavy variational analysis developments.
	\item We can rather consider the time integral of the spatial perimeter of the moving domain which builds the tube, as introduced in [157]. We shall extend these results to the case of vector fields living in $L^2((0,\tau)\times D;\mathbb{R}^d)$. In this case, only existence results for solutions of the convection equation can be handled \& the uniqueness property is lost.
\end{itemize}

\paragraph{Tube derivative.} In this paragraph, we are interested in differentiability properties of integrals defined over moving domains,
\begin{align*}
	J(Q({\bf V})) = \int_{Q({\bf V})} f({\bf V})\,{\rm d}{\bf x}\,{\rm d}t.
\end{align*}
The transverse map $\mathcal{T}_\rho^t$ associated to 2 vector fields $({\bf V},{\bf W})\in\mathcal{U}$ is defined as follows,
\begin{align*}
	\mathcal{T}_\rho^t:\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\coloneqq\overline{\Omega_t({\bf V} + \rho{\bf W})}\\
	{\bf x}&\mapsto T_t({\bf V} + \rho{\bf W})\circ T_t({\bf V})^{-1}.
\end{align*}

\begin{remark}
	The transverse map allows us to perform sensitivity analysis on functions defined on the unperturbed domain $\Omega_t({\bf V})$.
\end{remark}
The following result states that the transverse map $\mathcal{T}_\rho^t$ can be considered as a dynamical flow w.r.t. the perturbation variable $\rho$. $\ldots$'' -- \cite[Chap. 1, Subsect. 1.4.3, pp. 19--23]{Moubachir_Zolesio2006} \texttt{[skipped pp. 23--31]}

\section{Inverse Stefan Problem}
``$\ldots$ we consider the identification of a moving boundary that represents the isothermal interface between a solid phase \& a liquid phase, from measurements on a fixed part of the solid boundary. This problem is referred in the literature as the \textit{inverse Stefan problem} [61, 144]. We make use of the \textit{transverse derivative concepts} introduced in [154, 155].'' -- \cite[Chap. 2, p. 33]{Moubachir_Zolesio2006}

\subsection{The inverse problem setting}
``For a given evolution of the \textit{melting interface}, we consider the solution of the heat equation (2.3) \& we consider its trace on the fixed boundary $\Sigma^s$.'' \textsf{Fig. 2.2. Non-cylindrical space-time domain.} ``On the mathematical viewpoint, we introduce the \textit{observation space} $\mathcal{O}\coloneqq L^2((0,\tau);L^2(\Gamma^s))$ \& the \textit{observation operator} \textbf{(2.5)} $\mathfrak{O}:\mathcal{U}_{\rm ad}\to\mathcal{O}$, ${\bf V}\mapsto\mathfrak{O}({\bf V})\coloneqq\gamma_{\Gamma^s}(y({\bf V}))$ where $y({\bf V})$ stands for the solution of (2.3) \& $\gamma_{\Gamma^s}$ is the zero order trace operator on $\Sigma^s$.

The inverse Stefan problem consists in recovering the evolution of the melting front $\Gamma^f(t)$ from the knowledge of the temperature on the fixed solid boundary $\Gamma^s$. I.e., for a given temperature $y_{\rm d}\in L^2((0,\tau);L^2(\Gamma^s))$, we look for ${\bf V}\in\mathcal{U}_{\rm ad}$ s.t. \textbf{(2.6)} $\mathfrak{O}({\bf V}) = y_{\rm d}$, in $\mathcal{O}$. It is a nonlinear ill-posed inverse problem that can be solved using a least-square minimization problem regularized thanks to a Tikhonov zero order term. Hence we look for the solution ${\bf V}$ of the following optimization problem \textbf{(2.7)}
\begin{align*}
	\min_{{\bf V}\in\mathcal{U}_{\rm ad}} \frac{1}{2}\|\mathfrak{O}({\bf V}) - y_{\rm d}\|_{\mathcal{O}}^2 + \frac{\alpha}{2}\|{\bf V}\|_{\mathcal{U}_{\rm ad}}^2,
\end{align*}
with $\alpha > 0$.'' -- \cite[Chap. 2, Sect. 2.2, p. 35]{Moubachir_Zolesio2006}

\subsection{The Eulerian derivative \& the transverse field}
``A possible choice in order to solve the above minimization problem is to use a gradient based method such as the \textit{conjugate gradient method}. Hence, we need to evaluate the gradient w.r.t. ${\bf V}$ of the functional \textbf{(2.13)} $j({\bf V})\coloneqq\frac{1}{2}\|\mathfrak{O}({\bf V}) - y_{\rm d}\|_{\mathcal{O}}^2$ where, for the sake of simpleness, we have dropped the regularizing term $\frac{\alpha}{2}\|{\bf V}\|_{\mathcal{U}_{\rm ad}}^2$. Let us choose a perturbation direction ${\bf W}\in\mathcal{U}_{\rm ad}$. We would like to compute the \textit{directional derivative} of $j$, \textbf{(2.14)}
\begin{align*}
	[{\rm D}_{\bf V}[j]({\bf V})]\cdot{\bf W}\coloneqq\lim_{\rho\to 0} \frac{1}{\rho}(j({\bf V} + \rho{\bf W}) - j({\bf V})).
\end{align*}
Then the goal is to evaluate the directional derivative of the element $y({\bf V})$ which is a solution of the moving heat equation (2.3). In order to do so, we write the associated variational formulation satisfied $y({\bf V})$, \textbf{(2.15)}
\begin{align*}
	\int_0^\tau\int_{\Omega_t({\bf V})} [\partial_ty({\bf V})\phi({\bf V}) + \nabla y({\bf V})\cdot\nabla\phi({\bf V})]\,{\rm d}{\bf x}\,{\rm d}t = 0,\ \forall\phi({\bf V})\in L^2((0,\tau);H_{0,\Gamma_t({\bf V})}^1(\Omega_t({\bf V}))),
\end{align*}
where we have set w.l.o.g., $(f,y_{\rm d},y_0) = (0,0,0)$ together with $\Omega_t({\bf V})\coloneqq\Omega^s(t)$ \& $\Gamma_t({\bf V})\coloneqq\Gamma^f(t)$. Looking at (2.15), it is clear that we need to establish how to differentiate the generic term $J({\bf V}) = \int_0^\tau\int_{\Omega_t({\bf V})} f({\bf V})\,{\rm d}{\bf x}\,{\rm d}t$ w.r.t. ${\bf V}$. To this end, we introduce the \textit{perturbated moving domain} $\Omega_t({\bf V} + \rho{\bf W})\coloneqq T_t({\bf V} + \rho{\bf W})(\Omega_0)$. This family generates a \textit{perturbed tube}
\begin{align*}
	Q({\bf V} + \rho{\bf W})\coloneqq\bigcup_{0\le t\le\tau} (\{t\}\times\Omega_t({\bf V} + \rho{\bf W}))
\end{align*}
as described in \textsf{Fig. 2.3. Perturbed tube.} Since the function $f({\bf V})$ is defined on the \textit{non-cylindrical reference tube} $Q({\bf V})$, it is natural to introduce the transformation between $Q({\bf V})$ \& $Q({\bf V} + \rho{\bf W})$. A canonical choice is furnished by
\begin{align*}
	\mathcal{T}^t(\rho;{\bf x}):\Omega_t({\bf V})&\to\Omega_t({\bf V} + \rho{\bf W})\\
	{\bf x}&\mapsto\mathcal{T}^t(\rho;{\bf x})\coloneqq[{\bf T}_t({\bf V} + \rho{\bf W})\circ{\bf T}_t({\bf V})^{-1}]({\bf x}).
\end{align*}
Hence, the perturbated functional can be written as follows,
\begin{align*}
	J({\bf V} + \rho{\bf W}) = \int_0^\tau\int_{\Omega_t({\bf V} + \rho{\bf W})} f({\bf V} + \rho{\bf W})\,{\rm d}{\bf x}\,{\rm d}t = \int_0^\tau\int_{\mathcal{T}_\rho^t(\Omega_t({\bf V}))} f({\bf V} + \rho{\bf W})\,{\rm d}{\bf x}\,{\rm d}t = \int_0^\tau\int_{\Omega_t({\bf V})} (\det{\rm D}\mathcal{T}_\rho^t)f({\bf V} + \rho{\bf W})\circ\mathcal{T}_\rho^t\,{\rm d}{\bf x}\,{\rm d}t,
\end{align*}
where we have performed a transport into the \textit{moving reference domain} $\Omega_t({\bf V})$. Now we shall need to differentiate the terms inside the integral w.r.t. $\rho$ at point $\rho = 0$. The easiest way to do so is to connect this problem to the classical shape derivative calculus handled inside the speed method framework [147, 135]. I.e., we need to identify a transverse velocity field that may generate the transverse map $\mathcal{T}^t(\rho;{\bf x})$ as the solution of a dynamical system w.r.t. the parameter $\rho\in[0,\rho_0]$. Actually, it can be proven that ${\bf T}({\bf V} + \rho{\bf W})$ is continuously differentiable\footnote{in $\mathcal{Z}_{\rm ad}\coloneqq\mathcal{C}^0([0,\tau];(\mathcal{C}^{k-1}(\overline{D}))^d)$.} w.r.t. $\rho$ \& that the transverse map $\mathcal{T}_\rho^t$ can be considered as the flow w.r.t. $\rho$ of the transverse vector field
\begin{align*}
	\mathcal{Z}(\rho;(t,{\bf x}))\coloneqq[\partial_\rho\mathcal{T}^t(\rho)]\circ\mathcal{T}^t(\rho)^{-1}({\bf x}) = [\partial_\rho{\bf T}({\bf V} + \rho{\bf W})]\circ{\bf T}({\bf V} + \rho{\bf W})^{-1}({\bf x}).
\end{align*}
p. 39

\textsf{Fig. 2.4. Transverse map.}

'' -- \cite[Chap. 2, Sect. 2.3, pp. 37--]{Moubachir_Zolesio2006}

\section{Dynamical Shape Control of NSEs}
\cite[Chap. 5]{Moubachir_Zolesio2006} ``deals with the analysis of an \textit{inverse dynamical shape problem} involving a fluid inside a moving domain. This type of inverse problem happens frequently in the design \& the control of many industrial devices such as aircraft wings, cable-stayed bridges, automobile shapes, satellite reservoir tanks \& more generally of systems involving fluid-solid interactions.

The control variable is the shape of the moving domain, \& the objective is to minimize a given cost functional that may be chosen by the designer.

On the theoretical level, early works concerning optimal control problems for general parabolic equations written in non-cylindrical domains have been considered in [43,29,30,142,2]. In [140,151,152], the stabilization of structures using the variation of the domain has been addressed. The basic principle is to define a map sending the non-cylindrical domain into a cylindrical one. This process leads to the mathematical analysis of non-autonomous PDE's systems.

Recently, a new methodology to obtain \textit{Eulerian derivatives} for non-cylindrical functionals has been introduced in [157, 156, 58]. This methodology was applied in [59] to perform dynamical shape control of the non-cylindrical NSEs where the evolution of the domain is the control variable. Hence the classical optimal shape optimization theory has been extended to deal with non-cylindrical domains.''

\textbf{Aim.} ``review several results on the dynamical shape control of the Navier--Stokes system \& suggest an alternative treatment using the Min-Max principle [45, 46]. Despite its lack of rigorous mathematical justification in the case where the Lagrangian functional is not convex, we shall show how this principle allows, at least formally, to bypass the tedious computation of the state differentiability w.r.t. the shape of the moving domain.'' -- \cite[Chap. 5, p. 109]{Moubachir_Zolesio2006}

\subsection{Problem Statement}
``Let us consider a moving domain $\Omega_t\in\mathbb{R}^d$. We introduce a diffeomorphic map sending a fixed reference domain $\Omega_0$ into the physical configuration $\Omega_t$ at time $t\ge 0$. W.l.o.g., we choose the reference configuration to be the physical configuration at initial time $\Omega_{t=0}$. Hence we define a map $T_t\in\mathcal{C}^1(\overline{\Omega_0})$ s.t. $\overline{\Omega_t} = T_t(\overline{\Omega_0})$, $\overline{\Gamma_t} = T_t(\overline{\Gamma_0})$. We set $\Sigma\coloneqq\bigcup_{0 < t < T} (\{t\}\times\Gamma_t)$, $Q\coloneqq\bigcup_{0 < t < T} (\{t\}\times\Omega_t)$. The map $T_t$ can be actually defined as the flow of a particular vector field, as described in the following lemma:

\begin{theorem}[ref. 147]
	$\overline{\Omega_t} = T_t(V)(\overline{\Omega_0})$, $\overline{\Gamma_t} = T_t(V)(\overline{\Gamma_0})$ where $T_t(V)$ is the solution of the following dynamical system:
	\begin{align*}
		T_t(V):\Omega_0&\to\Omega\\
		x_0&\mapsto x(t,x_0)\coloneqq T_t(V)(x_0)
	\end{align*}
	with \textbf{(5.1)}
	\begin{equation*}
		\left\{\begin{split}
			\frac{{\rm d}x}{{\rm d}\tau} &= V(\tau,x(\tau)),&&\tau\in[0,T],\\
			x(\tau = 0) &= x_0,&&\mbox{in }\Omega_0.
		\end{split}\right.
	\end{equation*}
\end{theorem}
The fluid filling $\Omega_t$ is assumed to be a viscous incompressible Newtonian fluid. Its evolution is described by its velocity ${\bf u}$ \& its pressure $p$. The couple $({\bf u},p)$ satisfies the classical NSEs written in non-conservative form \textbf{(5.2)}
\begin{equation*}
	\left\{\begin{split}
		\partial_t{\bf u} + {\rm D}{\bf u}\cdot{\bf u} - \nu\Delta{\bf u} + \nabla p &= 0,&&Q(V),\\
		\nabla\cdot{\bf u} &= 0,&&Q(V),\\
		{\bf u} &= V,&&\Sigma(V),\\
		{\bf u}(t = 0) &= {\bf u}_0,&&\Omega_0,
	\end{split}\right.
\end{equation*}
where $\nu$ stands for the kinematic viscosity. The quantity $\sigma({\bf u},p) = -p{\rm I} + \nu({\rm D}{\bf u} + {}^\star{\rm D}{\bf u})$ stands for the \textit{fluid stress tensor} inside $\Omega_t$, with $({\rm D}{\bf u})_{i,j} = \partial_ju_i$. We are interested in solving the following minimization problem: \textbf{(5.3)} $\min_{V\in\mathcal{U}} j(V)$ where $j(V) = J_V({\bf u}(V),p(V))$ with $({\bf u}(V),p(V))$ is a weak solution of problem (5.2) \& $J_V({\bf u},p)$ is a real functional of the following form: \textbf{(5.4)}
\begin{align*}
	J_V({\bf u},p) = \frac{\alpha}{2}\|\mathcal{B}{\bf u}\|_{Q(V)}^2 + \frac{\gamma}{2}\|\mathcal{K}V\|_{\Sigma(V)}^2,
\end{align*}
where $\mathcal{B}\in\mathcal{L}(\mathcal{H},\mathcal{H}^\star)$ is a general linear differential operator satisfying the following identity, \textbf{(5.5)}
\begin{align*}
	\langle\mathcal{B}{\bf u},{\bf v}\rangle + \langle{\bf u},\mathcal{B}^\star{\bf v}\rangle = \langle\mathcal{B}_\Sigma{\bf u},{\bf v}\rangle_{L^2(\Sigma)},
\end{align*}
where $\mathcal{H} = \{{\bf v}\in L^2(0,T;(H_0^1({\rm div},\Omega_t(V)))^d)\}$ \& $\mathcal{K}\in\mathcal{L}(\mathcal{U},L^2(\Sigma(V)))$ is a general linear differential operator satisfying the following identity, \textbf{(5.6)}
\begin{align*}
	\langle\mathcal{K}{\bf u},{\bf v}\rangle_{L^2(\Sigma)} + \langle{\bf u},\mathcal{K}^\star{\bf v}\rangle_{L^2(\Sigma)} = \langle\mathcal{K}_\Sigma{\bf u},{\bf v}\rangle_{L^2(\Sigma)}.
\end{align*}
The main difficulty in dealing with such a minimization problem is related to the fact that integrals over the domain $\Omega_t(V)$ depend on the control variable $V$. This point will be solved by using the Arbitrary Lagrange--Euler (ALE) map $T_t(V)$ introduced previously. The purpose of this chapter is to prove using several methods the following result,

\begin{theorem}[Main result]
	For $V\in\mathcal{U}$ \& $\Omega_0$ of class $\mathcal{C}^2$, the functional $j(V)$ possesses a gradient $\nabla j(V)$ which is supported on the moving boundary $\Gamma_t(V)$ \& can be represented by the following expression, \textbf{(5.7)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\varphi,\pi)\cdot{\bf n} + \alpha\mathcal{B}_\Sigma\mathcal{B}{\bf u} + \gamma[-\mathcal{K}^\star\mathcal{K}V + \mathcal{K}_\Sigma\mathcal{K}V],
	\end{align*}
	where $(\varphi,\pi)$ stands for the adjoint fluid state solution of the following system, \textbf{(5.8)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\varphi - {\rm D}\varphi\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\varphi - \nu\Delta\varphi + \nabla\pi &= -\alpha\mathcal{B}^\star\mathcal{B}{\bf u},&&Q(V),\\
			\nabla\cdot\varphi &= 0,&&Q(V),\\
			\varphi &= 0,&&\Sigma(V),\\
			\varphi(T) &= 0,&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.9)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with \textbf{(5.10)}
	\begin{align*}
		f = [-(\sigma(\varphi,\pi)\cdot{\bf n}) + \alpha\mathcal{B}_\Sigma\mathcal{B}{\bf u}]\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}\left[\alpha|\mathcal{B}{\bf u}|^2 + \gamma H|\mathcal{K}V|^2\right].
	\end{align*}
\end{theorem}

\begin{example}
	We set $(\mathcal{B},\mathcal{B}^\star,\mathcal{B}_\Sigma) = ({\rm I},-{\rm I},0)$, $(\mathcal{K},\mathcal{K}^\star,\mathcal{K}_\Sigma) = ({\rm I},-{\rm I},0)$. I.e., we consider the cost functional, \textbf{(5.11)}
	\begin{align*}
		J_V({\bf u},p) = \frac{\alpha}{2}\|{\bf u}\|_{L^2(Q(V))}^2 + \frac{\gamma}{2}\|V\|_{L^2(\Sigma(V))}^2.
	\end{align*}
	Then its gradient is given by \textbf{(5.12)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\boldsymbol{\varphi},\pi)\cdot{\bf n} + \gamma V,
	\end{align*}
	where $(\boldsymbol{\varphi},\pi)$ stands for the adjoint fluid state solution of the following system \textbf{(5.13)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\boldsymbol{\varphi} - {\rm D}\boldsymbol{\varphi}\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\boldsymbol{\varphi} - \nu\Delta\boldsymbol{\varphi} + \nabla\pi &= \alpha{\bf u},&&Q(V),\\
			\nabla\cdot\boldsymbol{\varphi} &= 0,&&Q(V),\\
			\boldsymbol{\varphi} &= {\bf 0},&&\Sigma(V),\\
			\boldsymbol{\varphi}(T) &= {\bf 0},&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.14)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with \textbf{(5.15)}
	\begin{align*}
		f = -\nu({\rm D}\boldsymbol{\varphi}\cdot{\bf n})\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}(\alpha + \gamma H)|V|^2.
	\end{align*}
\end{example}

\begin{example}
	We set $(\mathcal{B},\mathcal{B}^\star,\mathcal{B}_\Sigma) = (\operatorname{curl},\operatorname{curl},\land{\bf n})$, $(\mathcal{K},\mathcal{K}^\star,\mathcal{K}_\Sigma) = ({\rm I},-{\rm I},0)$, \textbf{(5.16)}
	\begin{align*}
		J_V({\bf u},p) = \frac{\alpha}{2}\|\operatorname{curl}{\bf u}\|_{L^2(Q(V))}^2 + \frac{\gamma}{2}\|V\|_{L^2(\Sigma(V))}^2.
	\end{align*}
	Then its gradient is given by \textbf{(5.17)}
	\begin{align*}
		\nabla j(V) = -\lambda{\bf n} - \sigma(\boldsymbol{\varphi},\pi)\cdot{\bf n} + \alpha(\operatorname{curl}{\bf u})\land{\bf n} + \gamma V,
	\end{align*}
	where $(\boldsymbol{\varphi},\pi)$ stands for the adjoint fluid state solution of the following system, \textbf{(5.18)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\boldsymbol{\varphi} - {\rm D}\boldsymbol{\varphi}\cdot{\bf u} + {}^\star{\rm D}{\bf u}\cdot\boldsymbol{\varphi} - \nu\Delta\boldsymbol{\varphi} + \nabla\pi &= -\alpha\Delta{\bf u},&&Q(V),\\
			\nabla\cdot\boldsymbol{\varphi} &= 0,&&Q(V),\\
			\boldsymbol{\varphi} &= {\bf 0},&&\Sigma(V),\\
			\boldsymbol{\varphi}(T) &= {\bf 0},&&\Omega_T,
		\end{split}\right.
	\end{equation*}
	\& $\lambda$ is the adjoint transverse boundary field, solution of the tangential dynamical system, \textbf{(5.19)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T),\\
			\lambda(T) &= 0,&&\Gamma_T(V),
		\end{split}\right.
	\end{equation*}
	with
	\begin{align*}
		f = [-\nu{\rm D}\boldsymbol{\varphi}\cdot{\bf n} + \alpha(\operatorname{curl}{\bf u})\land{\bf n}]\cdot({\rm D}V\cdot{\bf n} - {\rm D}{\bf u}\cdot{\bf n}) + \frac{1}{2}\left[\alpha|\operatorname{curl}{\bf u}|^2 + \gamma H|V|^2\right].
	\end{align*}
\end{example}
In the next section, we introduce several concepts closely related to shape optimization tools for moving domain problems. We also recall \textit{elements of tangential calculus} that will be used through this chapter. Then we treat successively the following points,
\begin{enumerate}
	\item In Sect. 5.5, we choose to prove the differentiability of the fluid state $({\bf u},p)$ w.r.t. the design variable $V$. The directional shape derivative $({\bf u}',p')(V)\cdot W$ is then used to compute the directional derivative $j'(V)\cdot W$ of the cost functional $j(V)$. Using the adjoint state $(\boldsymbol{\varphi},\pi)(V)$ associated to $({\bf u}',p')(V)$ \& the adjoint field $\Lambda$ associated to the \textit{transverse field} $Z_t$ introduced in sect. 5.3, we are able to furnish an expression of the gradient $\nabla j(V)$ which is a distribution supported by the moving boundary $\Gamma_t(V)$.
	\item In Sect. 5.6, we choose to bypass the computation of the state shape derivative $({\bf u}',p')(V)\cdot W$, by using a Min-Max formulation of problem (5.3) \& a transport technique. The state \& multiplier spaces are chosen in order to be independent on the scalar perturbation parameter used in the computation of the derivative of the Lagrangian functional w.r.t. $V$. This method directly furnishes the fluid state \& transverse field adjoint systems \& the resulting gradient $\nabla j(V)$.
	\item In Sect. 5.7, we again use a Min-Max strategy coupled with a state \& multiplier functional space embedding. I.e., the state \& multiplier variables live in the hold-all domain $D$. Hence the derivative of the Lagrangian functional w.r.t. $V$ only involves terms coming from the flux variation through the moving boundary $\Gamma_t(V)$. This again leads to the direct computation of the fluid state \& transverse field adjoints \& consequently to the gradient $\nabla j(V)$.'' -- \cite[Chap. 5, Sect. 5.2, pp. 110--114]{Moubachir_Zolesio2006}
\end{enumerate}

\subsection{Elements of Non-cylindrical Shape Calculus}
``This section introduces several concepts that will be intensively used through this chapter. It concerns the differential calculus of integrals defined on moving domains or boundaries w.r.t.  their support.'' -- \cite[Chap. 5, Sect. 5.3, p. 114]{Moubachir_Zolesio2006}

\subsubsection{Non-cylindrical speed method}
``In this paragraph, we are interested in differentiability properties of integrals defined over moving domains,
\begin{align*}
	J_1(\Omega_t) = \int_{\Omega_t} f(\Omega_t)\,{\rm d}\Omega,\ J_2(\Gamma_t) = \int_{\Gamma_t} g(\Gamma_t)\,{\rm d}\Gamma.
\end{align*}
The behavior of $J_1$ \& $J_2$ while perturbing their moving support highly depends on the regularity in space \& time of the domains. In this work, we choose to work with domains $\Omega_t$ that are images of a fixed domain $\Omega_0$ through an ALE map $T_t(V)$ as introduced in the 1st section. Hence, the design parameter is no more the support $\Omega_t$ but rather the velocity field $V\in\mathcal{U}\coloneqq\mathcal{C}([0,T];(W^{k,\infty}(D))^d)$ that builds the support. This technique has the advantage to transform shape calculus into classical differential calculus on vector spaces [157, 59]. For another choice based on the \textit{non-cylindrical identity perturbation}, the reader is referred to the \cite[Chap. 6]{Moubachir_Zolesio2006}.''

\paragraph{Transverse applications.}
\begin{definition}[Transverse map]
	The \emph{transverse map} $\mathcal{T}_\rho^t$ associated to 2 vector fields $(V,W)\in\mathcal{U}$ is defined as follows,
	\begin{align*}
		\mathcal{T}_\rho^t:\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\coloneqq\overline{\Omega_t(V + \rho W)}\\
		{\bf x}&\mapsto T_t(V + \rho W)\circ T_t(V)^{-1}.
	\end{align*}
\end{definition}

\begin{remark}
	The transverse map allows us to perform sensitivity analysis on functions defined on the unperturbed domain $\Omega_t(V)$.
\end{remark}
The following result states that the transverse map $\mathcal{T}_\rho^t$ can be considered as a dynamical flow w.r.t. the perturbation variable $\rho$,

\begin{theorem}[ref. 156]
	The Transverse map $\mathcal{T}_\rho^t$ is the flow of a transverse field $\mathcal{Z}_\rho^t$ defined as follows \textbf{(5.20)}
	\begin{align*}
		\mathcal{Z}_\rho^t\coloneqq\mathcal{Z}^t(\rho,\cdot) = \left(\frac{\partial\mathcal{T}_\rho^t}{\partial\rho}\right)\circ(\mathcal{T}_\rho^t)^{-1},
	\end{align*}
	i.e., is the solution of the following dynamical system:
	\begin{align*}
		T_t^\rho(\mathcal{Z}_\rho^t):\overline{\Omega_t}&\to\overline{\Omega_t^\rho}\\
		{\bf x}&\mapsto{\bf x}(\rho,{\bf x})\coloneqq T_t^\rho(\mathcal{Z}_\rho^t)({\bf x})
	\end{align*}
	with \textbf{(5.21)}
	\begin{equation*}
		\left\{\begin{split}
			\frac{{\rm d}{\bf x}(\rho)}{{\rm d}\rho} &= \mathcal{Z}^t(\rho,{\bf x}(\rho)),&&\rho\ge 0,\\
			{\bf x}(\rho = 0) &= {\bf x},&&\mbox{in }\Omega_t(V).
		\end{split}\right.
	\end{equation*}
\end{theorem}
Since, we will mainly consider derivatives of perturbed functions at point $\rho = 0$, we set $Z_t\coloneqq\mathcal{Z}_{\rho = 0}^t$. A fundamental result lies in the fact that $Z_t$ can be obtained as the solution of a linear time dynamical system depending on the vector fields $(V,W)\in\mathcal{U}$,

\begin{theorem}
	The vector field $Z_t$ is the unique solution of the following Cauchy problem, \textbf{(5.22)}
	\begin{equation*}
		\left\{\begin{split}
			\partial_tZ_t + [Z_t,V] &= W,&&(0,T)\times D,\\
			Z_{t=0} &= 0,&&D,
		\end{split}\right.
	\end{equation*}
	where $[Z_t,V]\coloneqq DZ_t\cdot V- DV\cdot Z_t$ stands for the Lie bracket of the pair $(Z_t,V)$.
\end{theorem}

\paragraph{Shape derivative of non-cylindrical functionals.} The main theorem of this section uses the notion of a non-cylindrical material derivative that we recall here,

\begin{definition}
	The derivative w.r.t. $\rho$ at point $\rho = 0$ of the following composed function,
	\begin{align*}
		f^\rho:[0,\rho_0]&\to H(\Omega_t(V))\\
		\rho&\mapsto f(V + \rho W)\circ\mathcal{T}_\rho^t
	\end{align*}
	$\dot{f}(V;W)$ is called the \emph{non-cylindrical material derivative} of $f(V)$ at point $V\in U$ in the direction $W\in\mathcal{U}$. We shall use the notation,
	\begin{align*}
		\dot{f}(V)\cdot W = \dot{f}(V;W)\coloneqq\left.\frac{d}{d\rho}f^\rho\right|_{\rho = 0}.
	\end{align*}
\end{definition}
With the above definition, we can state the differentiability properties of non-cylindrical integrals w.r.t. their moving support,

\begin{theorem}[ref. 59]
	For a bounded measurable domain $\Omega_0$ with boundary $\Gamma_0$, let us assume that for any direction $W\in U$ the following hypothesis holds,
	\begin{itemize}
		\item[(i)] $f(V)$ admits a non-cylindrical material derivative $\dot{f}(V)\cdot W$ then $J_1(\cdot)$ is G\^ateaux differentiable at point $V\in\mathcal{U}$ \& its derivative is given by the following expression, \textbf{(5.23)}
		\begin{align*}
			J_1'(V)\cdot W = \int_{\Omega_t(V)} [\dot{f}(V)\cdot W + f(V)\nabla\cdot Z_t]\,{\rm d}\Omega.
		\end{align*}
		Furthermore, if
		\item[(ii)] $f(V)$ admits a non-cylindrical shape derivative given by the following expression, \textbf{(5.24)}
		\begin{align*}
			f'(V)\cdot W = \dot{f}(V)\cdot W - \nabla f(V)\cdot Z_t,
		\end{align*}
	\end{itemize}
	then \textbf{(5.25)}
	\begin{align*}
		J_1'(V)\cdot W = \int_{\Omega_t(V)} [f'(V)\cdot W + \nabla\cdot(f(V)Z_t)]\,{\rm d}\Omega.
	\end{align*}
	Furthermore, if $\Omega_0$ is an open domain with a Lipschitzian boundary $\Gamma_0$, then \textbf{(5.26)}
	\begin{align*}
		J_1'(V)\cdot W = \int_{\Omega_t(V)} f'(V)\cdot W\,{\rm d}\Omega + \int_{\Gamma_t(V)} f(V)\langle Z_t,{\bf n}\rangle\,{\rm d}\Gamma.
	\end{align*}
\end{theorem}

\begin{remark}
	The last identity will be of great interest while trying to prove a gradient structure result for general non-cylindrical functionals.
\end{remark}
It is also possible to establish a similar result for integrals over moving boundaries. For that purpose, we need to define the non-cylindrical tangential material derivative,

\begin{definition}
	The derivative w.r.t. $\rho$ at point $\rho = 0$ of the following composed function,
	\begin{align*}
		g^\rho:[0,\rho_0]&\to H(\Gamma_t(V))\\
		\rho&\mapsto g(V + \rho W)\circ\mathcal{T}_\rho^t
	\end{align*}
	is called the \emph{non-cylindrical material derivative} of the function $g(V)\in H(\Gamma_t(V))$ in the direction $W\in\mathcal{U}$. We shall use the notation
	\begin{align*}
		\dot{g}(V)\cdot W = \dot{g}(V;W)\coloneqq\left.\frac{d}{d\rho}g^\rho\right|_{\rho = 0}.
	\end{align*}
\end{definition}
This concept is involved in the differentiability property of boundary integrals,

\begin{theorem}
	For a bounded measurable domain $\Omega_0$ with boundary $\Gamma_0$, let us assume that for any direction $W\in U$ the following hypothesis holds,
	\begin{itemize}
		\item[(i)] $g(V)$ admits a non-cylindrical material derivative $\dot{g}(V)\cdot W$ then $J_2(\cdot)$ is G\^ateaux differentiable at point $V\in\mathcal{U}$ \& its derivative is given by the following expression, \textbf{(5.27)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [\dot{g}(V)\cdot W + g(V)\operatorname{div}_\Gamma Z_t]\,{\rm d}\Gamma.
		\end{align*}
		Furthermore, if
		\item[(ii)] $g(V)$ admits a non-cylindrical shape derivative given by the following expression, \textbf{(5.28)}
		\begin{align*}
			g'(V)\cdot W = \dot{g}(V)\cdot W - \nabla_\Gamma g(V)\cdot Z_t,
		\end{align*}
		then \textbf{(5.29)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [\tilde{g}'(V)\cdot W + Hg(V)\langle Z_t,{\bf n}\rangle]\,{\rm d}\Gamma,
		\end{align*}
		where $H$ stands for the additive curvature. Furthermore, if $g(V) = \tilde{g}(V)|_{\Gamma_t(V)}$ with $\tilde{g}\in H(\Omega_t(V))$, then \textbf{(5.30)}
		\begin{align*}
			J_2'(V)\cdot W = \int_{\Gamma_t(V)} [g'(V)\cdot W + (\nabla\tilde{g}(V)\cdot{\bf n} + Hg(V))\langle Z_t,{\bf n}\rangle]\,{\rm d}\Gamma.
		\end{align*}
	\end{itemize}
\end{theorem}

\paragraph{Adjoint transverse field.} It is possible to define the solution of the adjoint transverse system,

\begin{theorem}
	For $F\in L^2(0,T;(H^1(D))^d)$, there exists a unique field $\Lambda\in\mathcal{C}^0([0,T];(L^2(D))^d)$ solution of the backward dynamical system, \textbf{(5.31)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\Lambda - {\rm D}\Lambda\cdot V - {}^\star{\rm D}V\cdot\Lambda - (\nabla\cdot V)\Lambda &= F,&&(0,T),\\
			\Lambda(T) &= 0,
		\end{split}\right.
	\end{equation*}
\end{theorem}

\begin{remark}
	The field $\Lambda$ is the dual variable associated to the transverse field $Z_t$ \& is the solution of the adjoint problem associated to the transverse dynamical system.
\end{remark}
In this chapter, we shall deal with a specific RHS $F$ of the form $F(t) = {}^\star\gamma_{\Gamma^t(V)}(f(t){\bf n})$. In this case, the adjoint field $\Lambda$ is supported on the moving boundary $\Gamma_t(V)$ \& has the following structure,

\begin{theorem}[ref. 59]
	For $F(t) = {}^\star\gamma_{\Gamma^t(V)}(f(t){\bf n})$, with $f\in L^2(0,T;L^2(\Gamma_t(V)))$, the unique solution $\Lambda$ of the problem is given by the following identity, \textbf{(5.32)}
	\begin{align*}
		\Lambda = (\lambda\circ p)\nabla_{\chi_{\Omega_t}(V)}\in\mathcal{C}^0([0,T];(H^1(\Gamma_t))^d),
	\end{align*}
	where $\lambda\in\mathcal{C}^0([0,T];H^1(\Gamma_t))$ is the unique solution of the following boundary dynamical system, \textbf{(5.33)}
	\begin{equation*}
		\left\{\begin{split}
			-\partial_t\lambda - \nabla_\Gamma\lambda\cdot V - (\nabla\cdot V)\lambda &= f,&&(0,T)\\
			\lambda(T) &= 0,&&\Gamma_t(V),
		\end{split}\right.
	\end{equation*}
	$p$ is the canonical projection on $\Gamma_t(V)$ \& $\chi_(\Omega_t)(V)$ is the characteristic function of $\Omega_t(V)$ inside $D$.
\end{theorem}

\paragraph{Gradient of non-cylindrical functionals.} In the next sections, we will often deal with boundary integrals of the following forms,
\begin{align*}
	K = \int_0^T\int_{\Gamma_t(V)} E\langle Z_t,{\bf n}\rangle
\end{align*}
with $E\in L^2(0,T;\Gamma_t(V))$ \& $Z_t$ is the solution of the transverse equation (5.22). The following result allows us to eliminate the auxiliary variable $Z_t$ inside the functional $K$,

\begin{theorem}[ref. 59]
	For any $E\in L^2(0,T;\Gamma_t(V))$ \& $(V,W)\in\mathcal{U}$, the following identity holds, \textbf{(5.34)}
	\begin{align*}
		\int_0^T\int_{\Gamma_t(V)} E\langle Z_t,{\bf n}\rangle = -\int_0^T\int_{\Gamma_t(V)} \lambda\langle W,{\bf n}\rangle,
	\end{align*}
	where $\lambda\in\mathcal{C}^0([0,T];H^1(\Gamma_t))$ is the unique solution of problem (5.33) with $f = E$.
\end{theorem}
'' -- \cite[Chap. 5, Subsect. 5.3.1, pp. 114--118]{Moubachir_Zolesio2006}

\subsection{Elements of tangential calculus}
``In this section, we review basic \textit{elements of differential calculus} on a $\mathcal{C}^k$-submanifold with $k\ge 2$ of codimension 1 in $\mathbb{R}^d$. The following approach avoids the use of local bases \& coordinates by using the intrinsic tangential derivative.'' -- \cite[Chap. 5, Sect. 5.4, pp. 119]{Moubachir_Zolesio2006}

\subsubsection{Oriented distance function}

%------------------------------------------------------------------------------%

\chapter{Topology Optimization}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}