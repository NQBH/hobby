\documentclass[oneside]{book}
\usepackage[backend=biber,natbib=true,style=authoryear]{biblatex}
\addbibresource{/home/hong/1_NQBH/reference/bib.bib}
\usepackage[vietnamese,english]{babel}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,float,graphicx}
\allowdisplaybreaks
\numberwithin{equation}{section}
\newtheorem{assumption}{Assumption}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{definition}{Definition}[chapter]
\newtheorem{example}{Example}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{notation}{Notation}[chapter]
\newtheorem{principle}{Principle}[chapter]
\newtheorem{problem}{Problem}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{question}{Question}[chapter]
\newtheorem{remark}{Remark}[chapter]
\newtheorem{theorem}{Theorem}[chapter]
\usepackage[left=0.5in,right=0.5in,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\small \textsc{Sect.} ~\thesection}
\rhead{\small \nouppercase{\leftmark}}
\renewcommand{\sectionmark}[1]{\markboth{#1}{}}
\cfoot{\thepage}
\def\labelitemii{$\circ$}

\title{Some Topics in Mathematical Optimization}
\author{\selectlanguage{vietnamese} Nguyễn Quản Bá Hồng\footnote{Independent Researcher, Ben Tre City, Vietnam\\e-mail: \texttt{nguyenquanbahong@gmail.com}}}
\date{\today}

\begin{document}
\maketitle
\setcounter{tocdepth}{3}
\setcounter{secnumdepth}{3}
\tableofcontents

\chapter*{Foreword}

A collection of \& some personal notes on Mathematical Optimization, especially the 3 major topics: Optimal Control, Shape Optimization, \& Topology Optimization.

\textbf{Keywords.} Optimal control; Shape optimization; Topology optimization.

%------------------------------------------------------------------------------%

\chapter{Wikipedia's}

\section{\href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}Shape Optimization}}
``\textit{Shape optimization} is part of the field of \href{https://en.wikipedia.org/wiki/Optimal_control}{optimal control} theory. The typical problem is to find the \href{https://en.wikipedia.org/wiki/Shape}{shape} which is optimal in that it minimizes a certain cost \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} while satisfying given \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraints}. In many cases, the functional being solved depends on the solution of a given \href{https://en.wikipedia.org/wiki/Partial_differential_equation}{PDE} defined on the variable domain.

\href{https://en.wikipedia.org/wiki/Topology_optimization}{Topology optimization} is, in addition, concerned with the number of connected components\texttt{/}boundaries belonging to the domain. Such methods are needed since typically shape optimization methods work in a subset of allowable shapes which have fixed topological properties, such as having a fixed number of holes in them. Topological optimization techniques can then help work around the limitations of pure shape optimization.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization}{Wikipedia\texttt{/}shape optimization}

\subsection{Definition}
``Mathematically, shape optimization can be posed as the problem of finding a \href{https://en.wikipedia.org/wiki/Bounded_set}{bounded set} $\Omega$, \href{https://en.wikipedia.org/wiki/Maxima_and_minima}{minimizing} a \href{https://en.wikipedia.org/wiki/Functional_(mathematics)}{functional} $\mathcal{F}(\Omega)$, possibly subject to a \href{https://en.wikipedia.org/wiki/Constraint_(mathematics)}{constraint} of the form $\mathcal{G}(\Omega) = 0$. Usually we are interested in sets $\Omega$ which are \href{https://en.wikipedia.org/wiki/Lipschitz_continuity}{Lipschitz} or $C^1$ \href{https://en.wikipedia.org/wiki/Boundary_(topology)}{boundary} \& consist of finite many \href{https://en.wikipedia.org/wiki/Connected_component_(analysis)}{components}, which is a way of saying that we would like to find a rather pleasing shape as a solution, \fbox{not some jumble of rough bits \& pieces}. Sometimes additional constraints need to be imposed to that end to ensure well-posedness of the problem \& uniqueness of the solution.

Shape optimization is an \href{https://en.wikipedia.org/wiki/Infinite-dimensional_optimization}{infinite-dimensional optimization} problem. Furthermore, the space of allowable shapes over which the optimization is performed does not admit a \href{https://en.wikipedia.org/wiki/Vector_space}{vector space} structure, making application of traditional optimization methods more difficult.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Definition}{Wikipedia\texttt{/}shape optimization\texttt{/}definition}

\subsection{Examples}
\begin{itemize}
	\item ``among all 3D shapes of given volume, find the one which has minimal surface area. Here: $\mathcal{F}(\Omega) = \operatorname{Area}(\partial\Omega)$, with $\mathcal{G}(\Omega) = \operatorname{Volume}(\Omega) = {\rm const}$. The answer, given by the \href{https://en.wikipedia.org/wiki/Isoperimetric_inequality}{isoperimetric inequality}, is a \href{https://en.wikipedia.org/wiki/Ball_(mathematics)}{ball}.
	\item Find the shape of an airplane wing which minimizes \href{https://en.wikipedia.org/wiki/Drag_(physics)}{drag}. Here the constraints could be the wing strength, or the wing dimensions.
	\item Find the shape of various mechanical structures, which can resist a given \href{https://en.wikipedia.org/wiki/Stress_(physics)}{stress} while having a minimal mass\texttt{/}volume.
	\item Given a known 3D object with a fixed radiation source inside, deduce the shape \& size of the source based on measurements done on part of the boundary of the object. A formulation of this \href{https://en.wikipedia.org/wiki/Inverse_problem}{inverse problem} using \href{https://en.wikipedia.org/wiki/Least-squares}{least squares} fit leads to a shape optimization problem.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Examples}{Wikipedia\texttt{/}shape optimization\texttt{/}examples}
\end{itemize}

\subsection{Techniques}
``Shape optimization problems are usually solved \href{https://en.wikipedia.org/wiki/Numerical_analysis}{numerically}, by using \href{https://en.wikipedia.org/wiki/Iterative_method}{iterative methods}. I.e., one starts with an initial guess for a shape, \& then gradually evolves it, until it morphs into the optimal shape.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Techniques}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques}

\subsubsection{Keeping track of the shape}
\textsf{Fig. Example: Shape optimization as applied to building geometry. Example provided courtesy of \url{Formsolver.com}.}

``To solve a shape optimization problem, one needs to find a way to represent a shape in the \href{https://en.wikipedia.org/wiki/Computer_memory}{computer memory}, \& follow its evolution. Several approaches are usually used.

1 approach is to follow the boundary of the shape. For that, one can sample the shape boundary in a relatively dense \& uniform manner, i.e., to consider enough points to get a sufficiently accurate outline of the shape. Then, one can evolve the shape by gradually moving the boundary points. This is called the \textit{Lagrangian approach}.

Another approach is to consider a \href{https://en.wikipedia.org/wiki/Function_(mathematics)}{function} defined on a rectangular box around the shape, which is positive inside of the shape, zero on the boundary of the shape, \& negative outside of the shape. One can then evolve this function instead of the shape itself. One can consider a rectangular grid on the box \& sample the function at the grid points. As the shape evolves, the grid points do not change; only the function values at the grid points change. This approach, of using a fixed grid, is called the \textit{Eulerian approach}. The idea of using a function to represent the shape is at the basis of the \href{https://en.wikipedia.org/wiki/Level-set_method}{level set method}.

\textsf{Fig. Example: Optimization shape families resulting from differing goal parameters. Example provided courtesy of \url{Formsolver.com}}

A 3rd approach is to \fbox{think of the shape evolution as of a flow problem}. I.e., one can imagine that the shape is made of a plastic material gradually deforming s.t. any point inside or on the boundary of the shape can be always traced back to a point of the original shape in a 1-1 fashion. Mathematically, if $\Omega_0$ is the initial shape, \& $\Omega_t$ is the shape at time $t$, one considers the \href{https://en.wikipedia.org/wiki/Diffeomorphism}{diffeomorphisms} $f_t:\Omega_0\to\Omega_t$, for $t\le t\le t_0$. The idea is again that shapes are difficult entities to be dealt with directly, so manipulate them by means of a function.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Keeping_track_of_the_shape}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}keeping track of the shape}

\subsubsection{Iterative methods using shape gradients}
``Consider a smooth velocity field $V$ \& the family of transformations $T_s$ of the initial domain $\Omega_0$ under the velocity field $V$: $x(0) = x_0\in\Omega_0$, $x'(s) = V(x(s))$, $T_s(x_0) = x(s)$, $s\ge 0$, \& denote $\Omega_0\mapsto T_s(\Omega_0) = \Omega_s$. Then the G\^ateaux or shape derivative of $\mathcal{F}(\Omega)$ at $\Omega_0$ w.r.t. the shape is the limit of
\begin{align*}
	d\mathcal{F}(\Omega_0;V) = \lim_{s\to 0} \frac{\mathcal{F}(\Omega_s) - \mathcal{F}(\Omega_0)}{s}
\end{align*}
if this limit exists. If in addition the derivative is linear w.r.t. $V$, there is a unique element of $\nabla\mathcal{F}\in L^2(\partial\Omega)$ \& $d\mathcal{F}(\Omega_0;V) = \langle\nabla\mathcal{F},V\rangle_{\partial\Omega_0}$ where $\nabla\mathcal{F}$ is called the \textit{shape gradient}. This gives a natural idea of \href{https://en.wikipedia.org/wiki/Gradient_descent}{gradient descent}, where the boundary $\partial\Omega$ is evolved in the direction of negative shape gradient in order to reduce the value of the cost functional. Higher order derivatives can be similarly defined, leading to Newtonlike methods.

Typically, gradient descent is preferred, even if requires a large number of iterations, because, it can be hard to compute the 2nd-order derivative (i.e., the \href{https://en.wikipedia.org/wiki/Hessian_matrix}{Hessian}) of the objective functional $\mathcal{F}$.

If the shape optimization problem has constrains, i.e., the functional $\mathcal{G}$ is present, one has to find ways to convert the constrained problem into an unconstrained one. Sometimes ideas based on \href{https://en.wikipedia.org/wiki/Lagrange_multipliers}{Lagrange multipliers}, like the \href{https://en.wikipedia.org/wiki/Adjoint_state_method}{adjoint state method}, can work.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Iterative_methods_using_shape_gradients}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}iterative methods using shape gradients}

\subsubsection{Geometry parametrization}
``Shape optimization can be faced using standard optimization methods if a parametrization of the geometry is defined. Such parametrization is very important in CAE field where goal functions are usually complex functions evaluated using numerical models (CFD, FEA, $\ldots$). A convenient approach, suitable for a wide class of problems, consists in the paramtrization of the CAD model coupled with a full automation of all the process required for function evaluation (meshing, solving \& result processing). \textit{Mesh morphing} is a valid choice for complex problems that resolves typical issues associated with \textit{re-meshing} such as discontinuities in the computed objective \& constraint functions. In this case the parametrization is defined after the meshing stage acting directly on the numerical model used for calculation that is changed using mesh updating methods. There are several algorithms available for mesh morphing (\textit{deforming volumes, pseudosolids}, \href{https://en.wikipedia.org/wiki/Radial_basis_function}{radical basis functions}). The selection of the parametrization approach depends mainly on the size of the problem: the CAD approach is preferred for small-to-medium sized models whilst the mesh morphing approach is the best (\& sometimes the only feasible one) for large \& very large models. The multi-objective Pareto optimization (NSGA II) could be utilized as a powerful approach for shape optimization. In this regard, the Pareto optimization approach displays useful advantages in design method such as the effect of area constraint that other multi-objective optimization cannot declare it. The approach of using a penalty function is an effective technique which could be used in the 1st stage of optimization. In this method the constrained shape design problem is adapted to an unconstrained problem with utilizing the constraints in the objective function as a penalty factor. Most of the time penalty factor is dependent to the amount of constraint variation rather than constrain number. The GA real-coded technique is applied in the present optimization problem. Therefore, the calculations are based on real value of variables.'' -- \href{https://en.wikipedia.org/wiki/Shape_optimization#Geometry_parametrization}{Wikipedia\texttt{/}shape optimization\texttt{/}techniques\texttt{/}geometry parametrization}

%------------------------------------------------------------------------------%

\chapter{\href{formsolver.com}{Formsolver.com}}

%------------------------------------------------------------------------------%

\chapter{Optimal Control}

\section{Introduction}
``The mathematical optimization of process governed by PDEs has seen considerable progress in the past decade. Ever faster computational facilities \& newly developed numerical techniques have opened the door to important practical applications in fields e.g. fluid flow, microelectronics\footnote{\textbf{microelectronics} [n] [uncountable] the design, production \& use of very small electronic circuits.}, crystal\footnote{\textbf{crystal} [n] \textbf{1.} [countable] a small piece of a substance with many even sides, that is formed naturally when the substance becomes solid; in chemistry, a \textbf{crystal} is any solid that has its atoms, ions or molecules arranged in an ordered, symmetrical way; \textbf{2.} [uncountable] a clear mineral, e.g. quartz, used in making decorative objects.} growth, vascular\footnote{\textbf{vascular} [a] [usually before noun] (\textit{medical}) connected with or containing veins.} surgery\footnote{\textbf{surgery} [n] \textbf{1.} [uncountable, countable] medical treatment of injuries or diseases that involves cutting open a person's body, sewing up wounds, etc.; \textbf{2.} [countable] (\textit{British English}) a place where a doctor sees patients; \textbf{3.} [countable] (\textit{British English}) a time during which a doctor, an MP or another professional person is available to see people.}, \& cardiac\footnote{\textbf{cardiac} [a] [only before noun] (\textit{medical}) connected with the heart or heart disease; if somebody has a \textbf{cardiac arrest}, their heart suddenly stops temporarily or permanently.} medicine, to name just a few. As a consequence, the communities of numerical analysts \& optimizers have taken a growing interest in applying their methods to optimal control problems involving PDEs $\ldots$'' [$\ldots$] ``$\ldots$ the comprehensive text by J.-L. Lions \cite{Lions1971} covers much of the theory of linear equations \& convex cost functionals.'' -- \cite[Preface to the German edition, p. xiii]{Troltzsch2010}

\cite{Troltzsch2010} focuses on basic concepts \& notions e.g.:
\begin{itemize}
	\item Existence theory for linear \& semilinear PDEs
	\item Existence of optimal controls
	\item Necessary optimality conditions \& adjoint equations
	\item 2nd-order sufficient optimality conditions
	\item Foundation of numerical methods
\end{itemize}

\begin{question}
	What is optimal control?
\end{question}
``The mathematical theory of optimal control has in the past few decades rapidly developed into an important \& separate field of applied mathematics. 1 area of application of this theory lies in aviation\footnote{\textbf{aviation} [n] [uncountable] the activity of designing, building \& flying aircraft.} \& space technology: aspects of optimization come into play whenever the motion of an aircraft or a space vessel\footnote{\textbf{vessel} [n] \textbf{1.} a tube that carries blood through the body of a person or an animal, or liquid through the parts of a plant; \textbf{2.} (\textit{formal}) a large ship or boat; \textbf{3.} (\textit{formal}) a container used for holding liquids, e.g. a bowl or cup.} (which can be modeled by ODEs) has to follow a trajectory\footnote{\textbf{trajectory} [n] (plural \textbf{trajectories}) (\textit{specialist}) \textbf{1.} the curved part of something that has been fired, hit or thrown into the air; \textbf{2.} the way in which a person, an event or a process develops over a period of time, often leading to a particular result.} that is ``optimal'' in a sense to be specified.'' -- \cite[Sect. 1.1: \textit{What is optimal control?}, p. 1]{Troltzsch2010}

All the essential features of an \textit{optimal control problem}:
\begin{itemize}
	\item a \textit{cost functional} to be minimized,
	\item an IVP for an ODE in order to determine the \textit{state} $y$,
	\item a \textit{control function} $u$, \&
	\item various constraints that have to be obeyed.
\end{itemize}
``The control $u$ may be freely chosen within the given constraints, while the state is uniquely determined by the differential equation \& the initial conditions. We have to choose $u$ in such a way that the cost function is minimized. Such controls are called \textit{optimal}.'' [$\ldots$] ``The optimal control of ODEs is of interest not only for aviation \& space technology. In fact, it is also important in fields e.g. robotics\footnote{\textbf{robotics} [n] [uncountable] the science of designing \& operating robots.}, movement sequences in sports, \& the control of chemical processes \& power plants, to name just a few of the various applications. In many cases, however, the processes to be optimized can no longer be adequately modeled by ODEs; instead, PDEs have to be employed for their description. E.g., heat conduction\footnote{\textbf{conduction} [n] [uncountable] (\textit{physics}) the process by which heat or electricity passes along or through a material.}, diffusion\footnote{\textbf{diffusion} [n] [uncountable] \textbf{1.} the spreading of something more widely; \textbf{2.} the mixing of substances by the natural movement of their particles; \textbf{3.} the spreading of elements of culture from 1 region or group to another.}, electromagnetic\footnote{\textbf{electromagnetic} [a] (\textit{physics}) in which the electrical \& magnetic properties of something are related.} waves, fluid flows, freezing processes, \& many other physical phenomenon\footnote{\textbf{phenomenon} [n] (plural \textbf{phenomena} a fact or an event in nature or society, especially one that is not fully understood.)} can be modeled by PDEs.

In these fields, there are numerous interesting problems in which a given cost functional has to be minimized subject to a differential equation \& certain constraints being satisfied. The difference from the above problem ``merely'' consists of the fact that a PDE has to be dealt with in place of an ordinary one.'' -- \cite[pp. 2--3]{Troltzsch2010}

\cite{Troltzsch2010} discusses, ``through examples in the form of mathematically simplified case studies, the optimal control of heating processes, 2-phase problems, \& fluid flows''. \cite{Troltzsch2010} focuses ``on linear \& semilinear elliptic \& parabolic PDEs, since a satisfactory regularity theory is available for the solutions to such equations. This is not the case for hyperbolic equations. Also, the treatment of quasilinear PDEs is considerably more difficult, \& the theory of their optimal control is still an open field in many respects.'' [$\ldots$] ``$\ldots$ the Hilbert space setting suffices as a functional analytic framework in the case of linear-quadratic theory.'' -- \cite[p. 3]{Troltzsch2010}

\subsection{Examples of Convex Problems}

\subsubsection{Optimal boundary heating}
See \cite[Subsect. 1.2.1, pp. 3--5]{Troltzsch2010}.

\begin{example}[Optimal boundary heating]
	Consider a body heated or cooled which occupies the spatial domain $\Omega\subset\mathbb{R}^3$. Apply to its boundary $\Gamma$ a \emph{heat source} $u$ (the \emph{control}), which is constant in time but depends on the location ${\bf x}$ on the boundary, i.e., $u = u({\bf x})$. Aim: choose the control in such a way that the corresponding \emph{temperature distribution} $y = y({\bf x})$ in $\Omega$ (the \emph{state}) is the best possible approximation to a desired stationary temperature distribution $y_\Omega = y_\Omega({\bf x})$:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Gamma |u({\bf x})|^2\,{\rm d}s({\bf x}),
	\end{align*}
	subject to the \emph{state equation}:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and the \emph{pointwise control constraints} $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ on $\Gamma$. ``Such pointwise bounds for the control are quite natural, since the available capacities for heating or cooling are usually restricted. The constant $\lambda\ge 0$ can be viewed as a measure of the energy costs needed to implement the control $u$. From the mathematical viewpoint, this term also serves as a \emph{regularization parameter}; it has the effect that possible optimal controls show improved regularity properties.'' [$\ldots$] ``The function $\alpha$ represents the \emph{heat transmission coefficient} from $\Omega$ to the surrounding medium. The functional $J$ to be minimized is called the \emph{cost functional}. The factor $\frac{1}{2}$ appearing in it has no influence on the solution of the problem. It is introduced just for the sake of convenience: it will later cancel out a factor 2 arising from differentiation. We seek an optimal control $u = u({\bf x})$ together with the associated state $y = y({\bf x})$. The minus sign in front of the Laplacian $\Delta$ appears to be unmotivated at 1st glance. It is introduced because $\Delta$ is not a \emph{coercive operator}, while $-\Delta$ is.'' -- \cite[p. 4]{Troltzsch2010}
\end{example}
``Observe that in the above problem the cost functional is quadratic, the state is governed by a linear elliptic PDE, \& the control acts on the boundary of the domain.'': thus have a \textit{linear-quadratic elliptic boundary control problem}.

\begin{remark}[Notations used in \cite{Troltzsch2010}]
	Denote the element of surface area by $ds$ \& the outward unit normal to $\Gamma$ at ${\bf x}\in\Gamma$ by $\nu({\bf x})$\footnote{NQBH: I prefer to use ${\bf n}({\bf x})$, with ``n'' stands for ``normal'', naturally \& obviously.}.
\end{remark}

\begin{remark}
	``The problem is strongly simplified. Indeed, in a realistic model Laplace's equation $\Delta y = 0$ has to be replaced by the stationary heat conduction equation $\nabla\cdot(a\nabla y) = 0$, where the coefficient $a$ can depend on ${\bf x}$ or even on $y$. If $a = a(y)$ or $a = a({\b f x},y)$, then the PDE is quasilinear. In addition, it will in many cases be more natural to describe the process by a time-dependent PDE.'' -- \cite[p. 4]{Troltzsch2010}
\end{remark}

\begin{example}[Optimal heat source]
	Similarly, the control can act as a \emph{heat source in the domain} $\Omega$. Problems of this kind arise if the body $\Omega$ is heated by electromagnetic induction or by microwaves. Assuming at 1st that the boundary temperature vanishes, we obtain the following problem:
	\begin{align*}
		\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y({\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_\Omega |u({\bf x})|^2\,{\rm d}{\bf x},
	\end{align*}
	subject to
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			y &= 0,&&\mbox{ on }\Gamma,
		\end{split}\right.
	\end{equation*}
	and $u_a({\bf x})\le u({\bf x})\le u_b({\bf x})$ in $\Omega$. Here, the coefficient $\beta = \beta({\bf x})$ is prescribed. Observe that by the special choice $\beta = \chi_{\Omega_{\rm c}}$ (where $\chi_E$ denotes the characteristic function of a set $E$), it can be achieved that $u$ acts only in a subdomain $\Omega_{\rm c}\subset\Omega$. This problem is a \emph{linear-quadratic elliptic control problem with distributed control}. It can be more realistic to prescribe an exterior temperature $y_a$ rather than assume that the boundary temperature vanishes. Then a better model is given by the state equation
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= \beta u,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(y_a - y),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
\end{example}

\subsubsection{Optimal nonstationary boundary control}
See \cite[pp. 5--6]{Troltzsch2010}. ``Let $\Omega\subset\mathbb{R}^3$ represent a potato that is to be roasted over a fire for some period of time $T > 0$.'' Denote its temperature by $y = y(t,{\bf x})$, with $(t,x)\in[0,T]\times\Omega$. ``Initially, the potato has temperature $y_0 = y_0({\bf x})$, \& we want to serve it at a pleasant palatable\footnote{\textbf{palatable} [a] \textbf{1.} (of food or drink) having a pleasant or acceptable taste; \textbf{2.} \textbf{palatable (to somebody)} pleasant or acceptable to somebody, \textsc{opposite}: \textbf{unpalatable}.} temperature $y_\Omega$ at the final time $T$.'' Write $Q\coloneqq(0,T)\times\Omega$, $\Sigma\coloneqq(0,T)\times\Gamma$. Then problem reads as follows:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_\Omega |y(T,{\bf x}) - y_\Omega({\bf x})|^2\,{\rm d}{\bf x} + \frac{\lambda}{2}\int_0^T\int_\Gamma |u(t,{\bf x})|^2\,{\rm d}\Gamma\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_t - \Delta y &= 0,&&\mbox{ in } Q,\\
		\partial_{\bf n}y &= \alpha(u - y),&&\mbox{ on }\Sigma,\\
		y(0,{\bf x}) &= y_0({\bf x}),&&\mbox{ in }\Omega,
	\end{split}\right.
\end{equation*}
\& $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ on $\Sigma$. By continued turning of the spit\footnote{\textbf{spit} [n] \textit{in}\texttt{/}\textit{from mouth} \textbf{1.} [uncountable] the liquid produced in your mouth, \textsc{synonym}: \textbf{saliva}; \textbf{2.} [countable, usually singular] the act of spitting liquid or food out of your mouth; \textit{piece of land} \textbf{3.} [countable] a long, thin piece of land that sticks out into the sea, a lake, etc.; \textit{for cooking meat} \textbf{4.} [countable] a long, thin, straight piece of metal that you put through meat to hold \& turn it while you cook it over a fire.}, we produce $u(t,{\bf x})$. The heating process has to be described by the \textit{nonstationary heat equation}, which is a parabolic differential equation: thus have to deal with a \textit{linear-quadratic parabolic boundary control problem}.

\subsubsection{Optimal vibrations}
``Suppose that a group of pedestrians crosses a bridge, trying to excite\footnote{\textbf{excite} [v] \textbf{1.} to make somebody feel a particular emotion or react in a particular way, \textsc{synonym}: \textbf{arouse}; \textbf{2.} \textbf{excite somebody} to make somebody feel very pleased, interested or enthusiastic, especially about something that is going to happen; \textbf{3.} \textbf{excite somebody\texttt{/}something} to make somebody\texttt{/}something nervous, upset or active \& unable to relax; \textbf{4.} \textbf{excite something} to produce a state of increased energy or activity in a physical or biological system, \textsc{synonym}: \textbf{stimulate}; \textbf{5.} \textbf{excite something} (\textit{physics}) to bring something to a state of higher energy.} oscillations\footnote{\textbf{oscillation} [n] \textbf{1.} [countable, uncountable] \textbf{oscillation (of something)} a regular movement between 1 position \& another; \textbf{2.} [countable] \textbf{oscillation (between A \& B)} a repeated change between different states, ideas, etc.; \textbf{3.} [countable] (\textit{specialist} regular variation in size, strength or position around a central point or value, especially of an electrical current or electric field.)} in it. This can be modeled (strongly abstracted) as follows: let $\Omega\subset\mathbb{R}^2$ denote the domain of the bridge, $y = y(t,{\bf x})$ its \textit{transversal\footnote{\textbf{transversal} [n] a line that intersects a system of lines.} displacement\footnote{\textbf{displacement} [n] \textbf{1.} [uncountable] the act of displacing somebody\texttt{/}something; the process of being displaced; \textbf{2.} [uncountable, singular] \textbf{displacement (of something)} (\textit{physics}) the distance between the final \& initial ($=$ 1st) positions of an object which has moved.}}, $u = u(t,{\bf x})$ the \textit{force density} acting in the vertical direction, \& $y_{\rm d} = y_{\rm d}(t,{\bf x})$ a \textit{desired evolution of the transversal vibrations\footnote{\textbf{vibration} [n] [countable, uncountable] \textbf{1.} \textbf{vibration (of something)} a continuous shaking movement; \textbf{2.} \textbf{vibration (of something)} (\textit{physics}) oscillation in a substance about its equilibrium state.}}. We then obtain the optimal control problem:
\begin{align*}
	\min J(y,u)\coloneqq\frac{1}{2}\int_0^T\int_\Omega |y(t,{\bf x}) - y_{\rm d}(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t + \frac{\lambda}{2}\int_0^T\int_\Omega |u(t,{\bf x})|^2\,{\rm d}{\bf x}\,{\rm d}t,
\end{align*}
subject to
\begin{equation*}
	\left\{\begin{split}
		y_{tt} - \Delta y &= u,&&\mbox{ in } Q,\\
		y(0) &= y_0,&&\mbox{ in }\Omega,\\
		y_t(0) &= y_1,&&\mbox{ in }\Omega,\\
		y &= 0,&&\mbox{ on }\Sigma,
	\end{split}\right.
\end{equation*}
and $u_a(t,{\bf x})\le u(t,{\bf x})\le u_b(t,{\bf x})$ in $Q$. This is a \textit{linear-quadratic hyperbolic control problem with distributed control}.'' [$\ldots$] ``Interesting control problems for oscillating elastic networks have been treated by Lagnese et al. \textbf{[LLS94]}. An elementary introduction to the controllability of oscillations can be found in \textbf{[Kra95]}.

In the linear-quadratic case, the theory of hyperbolic problems has many similarities to the parabolic theory studied in \cite{Troltzsch2010}. However, the treatment of semilinear hyperbolic problems is much more difficult, since the smoothing properties of the associated solution operators are weaker. As a consequence, many of the techniques presented in \cite{Troltzsch2010} fail in the hyperbolic case.'' -- \cite[pp. 6--7]{Troltzsch2010}

\subsection{Examples of Nonconvex Problems}
``However, linear models do not suffice for many real-world phenomena. Instead, one often needs quasilinear or, much simpler, semilinear equations. Recall that a 2nd-order equation is called \textit{semilinear} if the main parts (i.e., the expressions involving highest-order derivatives) of the differential operators considered in the domain \& on the boundary are linear w.r.t. the desired solution. For such equations, the theory of optimal control is well developed.

\fbox{Optimal control problems with semilinear state equations are, as a rule, nonconvex, even if the cost functional is convex.} ``Associated optimal control problems can be obtained by prescribing a cost functional \& suitable constraints.'' -- \cite[p. 7]{Troltzsch2010}

\subsubsection{Problems involving semilinear elliptic equations}

\begin{example}[Heating with radiation boundary condition]
	If the heat radiation of the heated body is taken into account, then we obtain a problem with a nonlinear Stefan--Boltzmann boundary condition. If this case, the control $u$ is given by the temperature of the surrounding medium:
	\begin{equation*}
		\left\{\begin{split}
			-\Delta y &= 0,&&\mbox{ in }\Omega,\\
			\partial_{\bf n}y &= \alpha(u^4 - y^4),&&\mbox{ on }\Gamma.
		\end{split}\right.
	\end{equation*}
	The nonlinearity $y^4$ occurs in the boundary condition, while the heat conduction equation itself is linear.
\end{example}

\begin{example}[Simplified superconductivity]
	
\end{example}

\begin{example}[Control of stationary flows]
	
\end{example}

\subsubsection{Problems involving semilinear parabolic equations}

\section*{Quick notes}
\textit{Primal-dual active set strategies}, whose the exposition now leads to the systems of linear equations to be solved.

%------------------------------------------------------------------------------%

\chapter{Shape Optimization}

\section{Introduction}
``Shape Optimization was introduced around 1970 by Jean C\'ea \cite{Cea_Gioan_Michel1973}, who understood, after several engineering studies [127, 12, 35, 110, 102, 83, 84, 7],\footnote{(see refs. in \cite{Moubachir_Zolesio2006})}, the future issues in the context of optimization problems. At that time, he proposed a list of open problems at the French National Colloquium in Numerical Analysis. These new problems were formulated in terms of minimization of functionals (referred as \textit{open loop control} or \textit{passive control}) governed by partial differential BVPs where the control variable was the geometry of a given boundary part [103, 76]. From the beginning, the terminology \textit{shape optimization} was not connected to the structural mechanical sciences in which elasticity \& optimization of the compliance played a central role. Furthermore, these research studies were mainly addressed in the context of the numerical analysis of the FEMs.

At the same time, there was some independent close results concerning fluid mechanics by young researchers e.g. O. Pironneau [123, 124, 78], Ph. Morice [107] \& also several approaches related to perturbation theory by P.R. Garabedian [74, 75] \& D.D Joseph [91, 92].

Very soon, it appeared that the shape control of BVPs was at the crossroads of several disciplines such as PDE analysis, non-autonomous semi-group theory, numerical approximation (including FEMs), control \& optimization theory, geometry \& even physics. Indeed several classical modeling in both structural \& fluid mechanics (among other fields) needed to be extended. An illustrative example concerns a very \textit{popular} problem in the 80's concerning the thickness optimization of a plate modeled by the classical Kirchoff biharmonic equation. This kind of solid model is based on the assumption that the thickness undergoes only small variations. Therefore, many pioneering works were violating the validity of this assumption, leading to strange results, e.g., the work presented in the Iowa NATO Study [85] stating the existence of optimal beams having \textit{zero cross section} values.

In the \textit{branch} which followed the passive control approach, we shall mention the work of G. Chavent [32, 34] based on the theory of distributed system control introduced by J.-L. Lions \cite{Lions1971}. Those results did not address optimization problems related to the domain but instead related to the coefficients inside the PDE. At that time, it was hoped that the solution of elliptic problems would be continuous w.r.t. the weak convergence of the coefficients. It appeared that this property was not achieved by this class of problem\footnote{Indeed, in his thesis [33], G. Chavent referred to such a result to appear in a work by F. Murat [113]. That paper [111] appeared but as a counterexample to the expected continuity property. He showed on a 1D simple example that with weak \textit{oscillating} convergence of the coefficients, the associated solution was converging to another problem in which the new coefficients were related to the limit of the \textit{inverse} coefficients associated to the original problem [112, 114].} At that point a main \textit{bifurcation} arose with the homogenization approach [10] which up to some point was considered as a part of the \textit{Optimal Design} theory.

The mathematical analysis of shape optimization problems began with the correct definition of derivatives of functionals \& functions w.r.t. the domain, together with the choice of tangential space to the family of shapes. Following the very powerful theory developed by J. Ne\v{c}as [117], the role of bilipschitzian mapping was emphasized for Sobolev spaces defined in moving domains based on the Identity perturbation method [115, 106, 134]. Concerning the large domain deformation viewpoint the previous approach led to the incremental domain evolution methods [143].

After 1975, the 2nd author introduced [145] an asymptotic analysis for domain evolution using classical geometrical flows which are intrinsic tools for manifolds evolutions \& gave existence results for the so-called \textit{shape differential equation} (see also [79]). At that period, applications focused more on sensitivity analysis problems than on asymptotic analysis of domains evolution. In 1972, A.M. Micheletti introduced in parallel [105, 104] a metric based on the Identity perturbation method thanks to the use of differentiable mappings, in order to study eigenvalues perturbation problems. The associated topology was extended by M. Delfour et. al [52] \& turns out to be the same as the one induced by the continuity along flow field deformations [147].

The systematic use of flow mapping \& intrinsic geometry through the fundamental role of the oriented distance function [47, 50] led to the revised analysis of the elastic shell theory [48, 49, 25, 26, 27, 28], of the boundary layer theory [3] or of the manifold derivation tools [53].

The use of both Bounded Variation (BV) analysis \& the notion of Cacciapoli sets led to the 1st compactness method for domain sequences \& several extensions to more regular boundaries were done through the use of different concepts such as \textit{fractal boundaries, density parameter} [23, 20, 21, 19] or \textit{Sobolev domains} [50].

At that point, an other important \textit{bifurcation point} in that theory occurred with the relaxation theory \& the Special Bounded Variation (SBV) analysis which was particularly well adapted for image segmentation problem [6]. At the opposite, the capacity constraint for Dirichlet boundary conditions led to a fine analysis initiated in [18] \& is still going on for cracks analysis.

The method of large evolution based on the flow mapping (known from 1980 as the \textit{speed method} [150]) turns to be the natural setting for weak evolution of geometry allowing topological changes through the convection of either characteristic functions or oriented distance functions.'' -- \cite[pp. 1--3]{Moubachir_Zolesio2006}

%------------------------------------------------------------------------------%

\chapter{Topology Optimization}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}