\documentclass[oneside]{book}
\usepackage[backend=biber,natbib=true,style=authoryear]{biblatex}
\addbibresource{/home/nqbh/reference/bib.bib}
\usepackage[vietnamese,english]{babel}
\usepackage{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\usepackage[colorlinks=true,linkcolor=blue,urlcolor=red,citecolor=magenta]{hyperref}
\usepackage{amsmath,amssymb,amsthm,mathtools,float,graphicx}
\usepackage[inline]{enumitem}
\allowdisplaybreaks
\numberwithin{equation}{section}
\newtheorem{assumption}{Assumption}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\newtheorem{corollary}{Corollary}[chapter]
\newtheorem{definition}{Definition}[chapter]
\newtheorem{example}{Example}[chapter]
\newtheorem{hypothesis}{Hypothesis}[chapter]
\newtheorem{lemma}{Lemma}[chapter]
\newtheorem{notation}{Notation}[chapter]
\newtheorem{principle}{Principle}[chapter]
\newtheorem{problem}{Problem}[chapter]
\newtheorem{proposition}{Proposition}[chapter]
\newtheorem{question}{Question}[chapter]
\newtheorem{remark}{Remark}[chapter]
\newtheorem{theorem}{Theorem}[chapter]
\usepackage[left=0.5in,right=0.5in,top=1.5cm,bottom=1.5cm]{geometry}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{\small Sect.~\thesection}
\rhead{\small\nouppercase{\leftmark}}
\renewcommand{\sectionmark}[1]{\markboth{#1}{}}
\cfoot{\thepage}
\def\labelitemii{$\circ$}

\title{Shape Optimization}
\author{\selectlanguage{vietnamese} Nguyễn Quản Bá Hồng\footnote{Independent Researcher, Ben Tre City, Vietnam\\e-mail: \texttt{nguyenquanbahong@gmail.com}; website: \url{https://nqbh.github.io}.}}
\date{\today}

\begin{document}
\maketitle
\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\tableofcontents

%------------------------------------------------------------------------------%

\chapter{\cite{Azegami2020}. Hideyuki Azegami. Shape Optimization Problems}
``3D modeling \& numerical analysis utilizing computers are conducted on a day-to-day basis in product design, \& there is a growing interest in the optimization of design using the results of numerical analysis. Optimization problems in which geometrical parameters of a 3D model defined on a computer are taken to be the design variables are called \textit{parametric shape optimization problems}. Software for solving such problems is constructed based on experimental design methods or mathematical programming. However, when increasing the number of design variables in order to increase the degrees of freedom, the solution rapidly becomes more difficult to find.

Conversely, problems in which no geometrical parameters are used \& optimum shapes are obtained from an arbitrary form are called \textit{nonparametric shape optimization problems}. In particular, problems in which the optimum shape is sought by introducing holes are called \textit{topology optimization problems}. Moreover, a problem in which the optimum shape is obtained through domain variations is referred to as a shape optimization problem of domain variation type or a shape optimization problem in a restrictive sense. Numerical methods have been developed to solve these problems \& are being used to seek practical optimum shapes.

\textsf{Fig. 1: Rigidity maximization of a heel counter (provided by ASICS Corporation). (a) External force \& fixed sole. (b) Mises stress initial model. (c) Optimized density (inside). (d) Optimized density (outside).} shows a numerical result for a topology optimization problem in maximizing the rigidity of a heel counter. Chap. 8 explains in detail how to choose the design variables. The external force estimated by the experiment is assumed to be known, \& the work done by it, which is defined as mean compliance in the body of this book, is chosen as the objective function. The condition that mass does not exceed a prescribed value is posed as a constraint condition. \textsf{Fig. 2: Lightening of an aluminum wheel (provided by Quint Corporation). (a) Initial shape. (b) Optimized shape.} shows the result of a numerical analysis w.r.t. a shape optimization problem of domain variation type aiming to decrease the weight of an aluminum wheel. Chap. 9 explains how the design variables should be selected in this case, where volume is selected as the objective function. A constraint is imposed on the Kreisselmeier--Steinhauser function, which expresses the maximum value of Mises stress in an integral form so that it does not exceed its initial value. The analysis also includes a constraint on the shape variations which take into account the symmetry \& manufacturing requirements of the model.

The fundamental principles of nonparametric shape optimization programs used to obtain these results are also based on mathematical programming. However, from the fact that the design variables are functions expressing densities or domain variations, there are issues that cannot be dealt with by finite-dimensional vector spaces, which are the platform for mathematical programming. In this regard, it is possible to drop the nonparametric shape optimization programs into parametric optimization problems in finite-dimensional vector spaces by discretizing continua using a procedure such as FEM. However, when using these methods, one faces a new problem that there is an insufficient smoothness of the function used in updating the density or domain variation. This problem emerges as \fbox{numerical instability phenomena} when conducting numerical analysis. In order to solve this problem, there is a need to think of solutions based on theories capturing shape optimization problems as function optimization problems. The numerical techniques described above are based on such theories. However, there are no books explaining such theories from their foundations.

This book explains the formulation \& solution of shape optimization problems for continua such as elastic bodies \& flow fields in detail from the basics, bearing in mind readers with an engineering background. A continuum refers to a domain over which a BVP of a PDE is defined. W.r.t. the PDE, considering a static elastic body or a steady flow field, elliptic PDEs are assumed. The theories shown in this book, however, can be applied to time-dependent IBVPs related to hyperbolic or parabolic PDEs, as well as to nonlinear problems. These results will be introduced on another occasion. Hence, the shape optimization problems dealt with in this book are described as follows. 1st describe a BVP of an elliptic PDE as a state determination problem \& then define the state determination problem so that when a function of the design variable expressing the density or domain variation is given, it has a unique solution. Using the design variable \& its solution, we define several cost functions by boundary integrals or domain integrals. Among these cost functions, one is set as the objective function \& the remaining as constraint functions in order to construct an optimum design problem. In this way, throughout this book, shape optimization problems will be constructed in the framework of function optimization problems. Their solutions will also be considered as solutions to the function optimization problems.

Based on this sort of conception, this book uses a structure as described below.
\begin{enumerate*}
	\item[$\bullet$] Chap. 1 examines a simple optimization design problem of a 1D continuum \& looks at the process until optimum conditions are obtained. In this chapter, the \textit{Lagrange multiplier method} (\textit{adjoint variable method}) is used without proof.
	\item[$\bullet$] After understanding the usage of the Lagrange multiplier method, optimization theories will be studied from the basics in Chap. 2. It is desired to have an understanding of the principle of the Lagrange multiplier method in this chapter.
	\item[$\bullet$] After mastering optimization theories, in Chap. 3, algorithms for obtaining the optimal solutions will be considered. The theories \& algorithms shown here are the fundamentals of the academic field referred to as mathematical programming. However, these are applicable to optimization problems defined on finite-dimensional vector spaces. In order to tackle optimization problems defined on functional spaces constructed from sets of functions, which is the aim of this book, functions need to be treated as vectors. A theory systematizing its use is functional analysis.
	\item[$\bullet$] In Chap. 4, the \textit{variational principle} in mechanics is used to exemplify the basic thinking \& results regarding the functional analysis.
	\item[$\bullet$] After such preparations, Chap. 5 will look at BVPs of PDEs which are the platform of this book.
	\item[$\bullet$] Chap. 6 will look at methods for performing numerical analyses of such problems. Numerical analysis is 1 of the academic fields which continues to develop, even now, \& has a variety of perspectives for study. In this book, because theories such as \textit{error estimation} are established, FEMs using the Galerkin method as a guiding principle will be looked at. Here, remarkable results from the functional analysis will be used to show the unique existence of solutions \& in error estimations.
	\item[$\bullet$] With these results in mind, in Chap. 7, an optimum design problem with a level of abstraction, which can be used in the unification of shape optimization problems considered in this book, is defined, \& its solution \& algorithms are considered. The solutions \& algorithms have the same framework as those shown in Chap. 3. Here, however, vector spaces w.r.t. design variables are replaced by function spaces.
	\item[$\bullet$] In Chaps. 8--9, the abstract optimum design problem is translated into topology optimization problems of density variation type \& shape optimization problems of domain variation type, respectively. In both chapters, the details of the theory are shown using the Poisson problem, for simplicity. We finally consider shape optimization problems for a linear elastic body \& a Stokes flow field, which are important in engineering, where a method to obtain the derivatives of cost functions will be looked at in detail.
\end{enumerate*}
Based on the above synopsis, this book will build up theorems using results in mathematics. Therefore, we will be summarizing the key points in mathematical definitions \& theorems. This method of expression is advanced by the fact that the provable facts are clearly shown. If something that we want to investigate in the future is contained in the framework of mathematics, setting up a theory using theorems prepared by great mathematicians is thought to be an extremely effective method. Conversely, mathematics attempts to heighten the level of abstractness in order to understand may things in a unified fashion. This characteristic is also the reason that it can baffle readers with an engineering background. Hence, an attempt has been made to provide explanations using examples from dynamics with the aim of accurately denoting the provable facts using definitions \& theorems. Proofs have been added for the basic theories.''  -- \cite[pp. v--viii]{Azegami2020}

%------------------------------------------------------------------------------%

\section{Basics of Optimal Design}

%------------------------------------------------------------------------------%

\section{Basics of Optimization Theory}

%------------------------------------------------------------------------------%

\section{Basics of Mathematical Programming}

%------------------------------------------------------------------------------%

\section{Basics of Variational Principles \& Fundamental Analysis}

%------------------------------------------------------------------------------%

\section{BVPs of PDEs}

%------------------------------------------------------------------------------%

\section{Fundamentals of Numerical Analysis}

%------------------------------------------------------------------------------%

\section{Abstract Optimum Design Problem}

%------------------------------------------------------------------------------%

\section{Topology Optimization Problems of Density Variation Type}

%------------------------------------------------------------------------------%

\section{Shape Optimization Problems of Domain Variation Type}
``In Chap. 8 we looked at problems for obtaining the optimal topologies of continua with the densities of continua set to be the design variable. In this chapter, we shall look at the type of shape optimization problems in which the boundary of a continuum varies.''

``1st, let us take an abridged look at the history of research relating to a shape optimization problem of domain variation type. This type of shape optimization problem is also referred to as a domain optimization problem \& has been studied since the early 20th century. E.g., among the vast works of Hadamard, there is a description relating to a problem seeking the boundary shape of a thin membrane s.t. the fundamental vibration frequency is maximized. In this description, a notion equivalent to a Fr\'echet derivative of the fundamental frequency when a boundary is moved in the outward normal direction is presented [60], \cite{Sokolowski_Zolesio1992}. Even after that, Fr\'echet derivatives w.r.t. shape variations of domain variation type have been referred to as \textit{shape derivatives}, \& many researchers have announced research results relating to it. To add background to this research, there are works relating to optimal control theory assuming a function as a control variable by mathematicians lead by Lions \cite{Lions1971}.

In this way, theories relating to the calculation methods of shape derivatives have been developed consistently, but research relating to moving the shapes using shape derivatives has not always obtained favorable results. In reality, it is known that if the node coordinates on a boundary of a finite element model are chosen to be the design variable, \& the Fr\'echet derivatives w.r.t. the variation of the design variable are evaluated in order to move the nodes, a numerically unstable phenomenon in which the boundary becomes rippled such as shown in Fig. 9.1a appears [73]. \textsf{Fig. 9.1. Numerical examples w.r.t. the shape optimization problem of a linear elastic body (provided by Quint Corporation). (a) Rippling shape. (b) Optimal shape by $H^1$ gradient method.} Fig. 9.1a shows the result of a numerical analysis w.r.t. a mean compliance minimization problem (Problem 9.12.2) of a 3D linear elastic body. The boundary condition in the state determination problem constrains the displacement on the back edge, while a uniform downward facing nodal force (external force) on the horizontal central line of the front edge was assumed. The boundary condition in the shape variation problem restrains the variation in the normal direction on the front\texttt{/}back \& left\texttt{/}right edges, \& the variation on the horizontal central line on the front\texttt{/}back edge. Numerical analysis of a state determination problem uses the 1st-order finite elements. The calculation method of shape derivatives uses the formula of boundary integration form as shown later.

In order to avoid rippling boundaries such as in this case, there is a method to define the boundary shape as a B-spline curve, Bezier curve, etc. \& choose its control variables as the design variables [30, 31]. There is also a method for giving the shape variation as the linear sum of the basic deformation modes \& choosing the undetermined multipliers in this case as the design variables (\textit{basis vector method}) [23, 65, 136, 166, 167]. All these methods have been highlighted \& used in actual optimal designs. However, all the methods used derivatives w.r.t. parametric design variables, such as those explained in the Preface \& differ from original shape derivatives.

In this chapter, we will look at a method for evaluating the shape derivatives of cost functions after having constructed a shape optimization problem of a domain variation type in which a function expressing the domain variation defined on an appropriate function space is set to be the design variable based on the framework of the abstract optimal design problem show in Chap. 7. As a result, the shape gradient does not have enough regularity to create the following domain. This is thought to be 1 of the factors generating numerical instability. In this situation, even if such a shape derivative is used, if an appropriate gradient method is used, there is the possibility that a shape optimization problem can be solved without facing numerical instability. In this chapter, this method will be the focus of our discussion.

Fig. 9.1b shows the results obtained via the algorithm shown in Sect. 9.10. Boundary conditions \& calculation method of the shape derivative are the same as in Fig. 9.1a. Numerical analysis of the state determination problem used 2nd-order tetrahedral finite elements. Moreover, in numerical analysis of the $H^1$ gradient method using the Robin condition shown later, the 1st-order tetrahedral finite elements were used. Moreover, the validity relating to the selection of a finite element such as this is shown in Sect. 9.11.

The fundamental idea relating the gradient method on a function space was presented by Cea [34]. A primitive form of the gradient method can be found in Pironneau's monograph [134, p. 48 (17)]. In addition, a method called \textit{asymptotical regularization} was proposed by Tautenhahn [163]. In contrast, in the 1990s, the author [8] proposed a gradient method on a function space which was referred to as the \textit{traction method}, based on an engineering principle. After that, a generalization of the traction method was also introduced [14]. Furthermore, these methods have been applied in various engineering problems. Moreover, the interpretation of the traction method in mathematics was also attempted in an existing report [80]. Here the domain mapping was assumed to be an element of the set of all continuous functions of some class, \& the traction method was justified using the G\^ateaux derivative of a cost function w.r.t. the variation of the domain mapping. In this chapter, a gradient method uses the Fr\'echet derivative of a cost function by defining the variation of the domain mapping in an appropriate Hilbert space. Based on this gradient method, it is apparent that the traction method was indeed a concrete example of that computational procedure.

Furthermore, a different method for constructing a shape optimization problem of domain variation type is proposed. As thought by Hadamard [60], since the next boundary shape can be determined by moving the boundary to the normal direction, 1 method is choosing the function that represents the amount of movement in the normal direction defined on the boundary as the design variable [118]. This method also uses the gradient method with the functionality of keeping the regularity equivalent to the gradient method shown in this chapter. However, if a FEM is used for numerical analysis of a state determination problem, after the boundary has been moved by the gradient method, we have to consider a method for moving the finite element mesh within the domain along with the new boundary. In addition, methods using level-set functions for design variables are also being researched [4, 169, 180]. In these methods, a level-set function which is a continuous function with scalar value defined on a fixed domain is used to define the boundary with a set of points in the domain where its value is zero. Using these methods, the topology of the domain can easily be changed through joining the holes together by varying the level-set function. However, since the level-set function is defined using Euler notation (see after Def. 9.1.3), a wider domain is required than the actual domain. Moreover, in order to extract a numerical model from the level set of zero, some processes are required. Furthermore, stronger conditions w.r.t. the regularity of the solution for the state determination problem are required for the aforementioned 2 methods than for the method shown in this chapter. The reason for this is that when calculating the Fr\'echet derivatives of cost functions, only the formula of boundary integral type can be applicable.

This chapter is structured as follows.
\begin{enumerate*}
	\item[$\bullet$] In Sects. 9.1--9.4, the definitions \& formulae relating to functions \& functionals defined on a moving domain are summarized.
	\item[$\bullet$] In Sect. 9.1, the definitions of admissible set of a design variable (function representing domain variation) \& shape derivatives of functions \& functionals are shown. There, attention will be given to the fact that there are 2 methods of defining the derivatives of functions defined on a moving domain w.r.t. domain variation. In this book, we shall refer to these notions of derivatives as ``shape derivative of a function'' \& ``partial shape derivative of a function''.
	\item[$\bullet$] Using these definitions, the formulae for shape derivatives relating to the Jaboci matrix of the domain mapping will be obtained in Sect. 9.2.
	\item[$\bullet$] Using the formulae, in Sect. 9.3, the propositions relating to shape derivatives of functions \& functionals are shown. Here also, we will focus on the fact that the formulae using the shape derivatives of functions \& partial shape derivatives of functions can be obtained.
	\item[$\bullet$] Sect. 9.4 defines several rules for variations of functions w.r.t. domain variation using the shape derivative of a function \& the partial shape derivative of a function.
	\item[$\bullet$] In Sects. 9.5--9.8, we will consider a shape optimization problem when Poisson problem is chosen to be the state determination problem \& present the process of computing the shape derivatives of cost functions.
	\item[$\bullet$] In Sect. 9.5, a state determination problem will be defined using a Poisson problem using the variation rules for functions shown in Sect. 9.4.
	\item[$\bullet$] The solution to this problem is used in Sect. 9.6 to define a general cost function which is then used to define a shape optimization problem.
	\item[$\bullet$] The existence of a solution to the shape optimization problem of this is shown in Sec.t 9.7.
	\item[$\bullet$] In Sect. 9.8, the methods for obtaining the Fr\'echet derivatives of cost functions shown in Sect. 7.5 are followed in order to show the methods to obtain shape derivatives \& 2nd-order derivatives of cost functions w.r.t. a domain variation. In this case, we focus on the fact that we can think of 2 methods: one using formulae based on the shape derivative of a function, \& another using formulae based on the partial shape derivative of a function. As a result, it becomes clear that whichever method is used, the shape gradients of the cost functions do not have enough regularity to be able to define the following domain.
	
	Even if the shape gradients have insufficient regularities, by applying the abstract gradient method or the abstract Newton method shown in Sect. 7.6 to the shape optimization problems, a gradient method \& Newton method with the functionality to regularize the shape derivatives of cost functions can be defined.
	\item[$\bullet$] In Sect. 9.9, their abstract definitions \& several methods for specifying these are introduced.
	\item[$\bullet$] In Sect. 9.10, algorithms will be considered. However, the basic structures are as per the algorithms shown in Sect. 3.7.
	\item The error evaluation of the numerical solutions obtained using these algorithms is shown in Sect. 9.11. Here, the results from the error estimations of numerical analyses shown in Sect. 6.6 will be used.
\end{enumerate*}

Once we look at the range of solutions w.r.t. the shape optimization problem of a Poisson problem, the shape derivatives of cost functions w.r.t. a mean compliance minimization problem of a linear elastic body will be sought in Sect. 9.12. Furthermore, in Sect. 9.13, the mean flow resistance minimization problem of a Stokes flow field will be used as an example to obtain the shape derivatives of the cost functions. The conditions of optimality using these shape derivatives can be seen matching the conditions of optimality w.r.t. the mean compliance minimization problem for a 1D linear elastic body shown in Sect. 1.1 \& the mean flow resistance minimization problem for a 1D branched Stokes flow field shown in Sect. 1.3. Moreover, in Sects. 9.12.5 \& 9.13.5, numerical examples w.r.t. these simple problems will be shown.'' -- \cite[pp. 427--431]{Azegami2020}

\subsection{Set of Domain Variations \& Definition of Shape Derivatives}
``In order to construct a shape optimization problem of domain variation type, let us define the admissible set of design variables. Moreover, the Fr\'echet derivatives of functions \& functionals defined in a moving domain w.r.t. domain variation will be referred to as shape derivatives.'' -- \cite[p. 431]{Azegami2020}

\subsubsection{Initial Domain}

\subsubsection{Sets of Domain Variations}

\subsubsection{Definitions of Shape Derivatives}

\subsection{Shape Derivatives of Jacobi Determinants}

\subsubsection{Shape Derivatives of Domain Jacobi Determinant \& Domain Jacobi Inverse Matrix}

\subsubsection{Shape Derivatives of Boundary Jacobi Determinant \& the Normal}

\subsection{Shape Derivatives of Functionals}

\subsubsection{Formulae Using Shape Derivative of a Function}

\subsubsection{Formula Using Partial Shape Derivative of a Function}

\subsection{Variation Rules of Functions}

\subsection{State Determination Problem}
``Since the definitions \& formulas of shape derivatives of functions \& functional have been obtained, let us use them to define a BVP of a PDE which would be a state determination problem. In this chapter, a Poisson problem will be considered 1st for ease.

In a shape optimization problem of domain variation type, the domains of known functions \& the solution function vary along with each other. Let $b_0:D\to\mathbb{R}$, $p_{\rm N0}:D\to\mathbb{R}$, $u_{\rm D0}:D\to\mathbb{R}$ be known functions over the reference domain $\Omega_0$, which can then be recovered through a specified variation rule with the functions $b(\boldsymbol{\phi}):D\to\mathbb{R}$, $p_{\rm N}(\boldsymbol{\phi}):D\to\mathbb{R}$, $u_{\rm D}(\boldsymbol{\phi}):D\to\mathbb{R}$ defined over the perturbed domain $\Omega(\boldsymbol{\phi})$. We shall use their respective variation rules when we eventually deal with computing the shape derivative of an associated cost function.

W.r.t. the solution function, since it is a function of $H^1$ class, the Calder\'on extension theorem (Theorem 4.4.4) can be used to view it as a function defined on $D$. Hence, we define the real Hilbert space (linear space of state variables in optimal design problem) containing the homogeneous solution (given by $\tilde{u} = u - u_{\rm D}$ with a known function $u_{\rm D}$ providing the Dirichlet condition) for the solution of a state determination problem by \textbf{(9.5.1)} $U(\boldsymbol{\phi}) = \{u\in H^1(D;\mathbb{R})|u = 0\mbox{ on }\Gamma_{\rm D}(\boldsymbol{\phi})\}$ w.r.t. $\boldsymbol{\phi}\in\mathcal{D}$. Furthermore, in order for the domain variation obtained from the gradient method shown later to be in $\mathcal{D}$ of (9.1.3), the admissible set of state variables for the homogeneous solution $\tilde{u}$ w.r.t. a state determination problem is taken to be \textbf{(9.5.2)} $\mathcal{S}(\boldsymbol{\phi}) = U(\boldsymbol{\phi})\cap W^{2,4}(D;\mathbb{R})$. The regularity which is needed in addition to the condition of $\mathcal{S}(\boldsymbol{\phi})$ will be specified when required.

The following 2 types of hypotheses are set w.r.t. regularity of known functions. When the shape derivatives are sought using formulae based on the shape derivative of a function, the following hypothesis is used later.

\begin{hypothesis}[Known Functions (Shape Derivative)]
	W.r.t. the given known functions, in a neighborhood $B\subset Y$ of $\boldsymbol{\phi}\in\mathcal{D}^\circ$, we assume $b\in C_{\rm S'}^1(B;C^{0,1}(D;\mathbb{R}))$, $p_{\rm N}\in C_{\rm S'}^1(B;C^{1,1}(D;\mathbb{R}))$, $u_{\rm D}\in C_{\rm S'}^1(B;W^{2,4}(D;\mathbb{R}))$ \& denote their shape derivatives as $(\cdot)'(\boldsymbol{\phi})[\boldsymbol{\varphi}]$.
\end{hypothesis}
On the other hand, the following hypothesis is used when seeking the shape derivatives using the formulae based on the partial shape derivative of a function.

\begin{hypothesis}[Known Functions (Partial Shape Derivative)]
	W.r.t. the given known functions, in a neighborhood $B\subset Y$ of $\boldsymbol{\phi}\in\mathcal{D}^\circ$, we assume $b\in C_{\rm S^\star}^1(B;C^{0,1}(D;\mathbb{R}))$, $p_{\rm N}\in C_{\rm S^\star}^1(B;C^{1,1}(D;\mathbb{R}))$, $u_{\rm D}\in C_{\rm S'}^1(B;W^{2,2q_{\rm R}}(D;\mathbb{R}))$ where $q_{\rm R} > d$, \& denote their partial shape derivatives as $(\cdot)^\star(\boldsymbol{\phi})[\boldsymbol{\varphi}]$.
\end{hypothesis}
The following hypothesis is established w.r.t. regularity of the boundary.

\begin{hypothesis}[Opening Angle of Corner Point]
	Let $\Omega(\boldsymbol{\phi})$ be a 2D domain \& consider a corner point on the boundary. When $\Omega(\boldsymbol{\phi})$ is a 3D domain, we consider a plane which is perpendicular to the corner line on the boundary \& the corner line on the boundary in the plane. Let $\beta$ be the opening angle of the corner point between 2 boundaries that are a Dirichlet boundary or Neumann boundary,
	\begin{enumerate*}
		\item[(1)] if the boundaries are same of the type, assume $\beta < \frac{2\pi}{3}$,
		\item[(2)] if the boundaries are of mixed type, assume $\beta < \frac{\pi}{3}$.
	\end{enumerate*}
\end{hypothesis}
If Hypotheses 9.5.1 \& 9.5.3 hold, the fact that $u$ is in $\mathcal{S}$ is shown by Proposition 5.3.1. Using the hypotheses above, a Poisson problem of domain variation type will be defined as follows. Here, we write $\partial_\nu = \boldsymbol{\nu}\cdot\nabla$.

\begin{problem}[Poisson Problem of Domain Variation Type]
	Let $\boldsymbol{\phi}\in\mathcal{D}$ \& $b(\boldsymbol{\phi}),p_{\rm N}(\boldsymbol{\phi}),u_{\rm D}(\boldsymbol{\phi})$ be given. Find $u:\Omega(\boldsymbol{\phi})\to\mathbb{R}$ which satisfies
	\begin{equation*}
		\left\{\begin{split}
			-\Delta u &= b(\boldsymbol{\phi}),&&\mbox{in }\Omega(\boldsymbol{\phi}),\\
			\partial_\nu u &= p_{\rm N}(\boldsymbol{\phi}),&&\mbox{on }\Gamma_p(\boldsymbol{\phi}),\\
			\partial_\nu u &= 0,&&\mbox{on }\Gamma_{\rm N}(\boldsymbol{\phi})\backslash\overline{\Gamma}_p(\boldsymbol{\phi}),\\
			u &= u_{\rm D}(\boldsymbol{\phi}),&&\mbox{on }\Gamma_{\rm D}(\boldsymbol{\phi}).
		\end{split}\right.
	\end{equation*}
\end{problem}
Here \& in what follows, $b(\boldsymbol{\phi})$ or $u_{\rm D}(\boldsymbol{\phi})$ \& $U(\boldsymbol{\phi})$ or $\mathcal{S}(\boldsymbol{\phi})$, etc. will be written resp. as $b$ or $u_{\rm D}$ \& $U$ or $\mathcal{S}$, etc.

Problem 9.5.4 will be used as an equality constraint in the shape optimization problem (Problem 9.6.3) of domain variation type shown later. In a later argument, an equality constraint will be replaced with stationary conditions for a Lagrange function. Here, as a preparation for this, we define the Lagrange function of Problem 9.5.4 as \textbf{(9.5.3)}
\begin{align*}
	\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v) = \int_{\Omega(\boldsymbol{\phi})} (-\nabla u\cdot\nabla v + bv)\,{\rm d}{\bf x} + \int_{\Gamma_p(\boldsymbol{\phi})} p_{\rm N}v\,{\rm d}\gamma + \int_{\Gamma_{\rm D}(\boldsymbol{\phi})} \left[(u - u_{\rm D})\partial_\nu v + v\partial_\nu u\right]\,{\rm d}\gamma,
\end{align*}
where $u$ is not necessarily the solution of Problem 9.5.4 \& $v$ is an element of $\mathcal{S}$ introduced as a Lagrange multiplier. In (9.5.3), the 3rd term on the RHS was added in order to make the later discussion easier in a similar way to (8.2.4) in Chap. 8 defining the Lagrange function w.r.t. a $\theta$-type Poisson problem. Moreover, in a similar manner to (7.2.3) defining the Lagrange w.r.t. the abstract variation problem in Chap. 7, using $\tilde{u} = u - u_{\rm D}$, we write \textbf{(9.5.4)}
\begin{align*}
	\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v) = -a(\boldsymbol{\phi})(u,v) + l(\boldsymbol{\phi})(v) = -a(\boldsymbol{\phi})(\tilde{u},v) + \hat{l}(\boldsymbol{\phi})(v),
\end{align*}
where \textbf{(9.5.5)--(9.5.7)}
\begin{align*}
	a(\boldsymbol{\phi})(u,v) = \int_{\Omega(\boldsymbol{\phi})} \nabla u\cdot\nabla v\,{\rm d}{\bf x},\ l(\boldsymbol{\phi})(v) = \int_{\Omega(\boldsymbol{\phi})} bv\,{\rm d}{\bf x} + \int_{\Gamma_p(\boldsymbol{\phi})} p_{\rm N}v\,{\rm d}\gamma,\ \hat{l}(\boldsymbol{\phi})(v) = l(\boldsymbol{\phi})(v) + a(\boldsymbol{\phi})(u_{\rm D},v).
\end{align*}
When $u$ is the solution to Problem 9.5.4, $\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v) = 0$ holds for all $v\in U$. This equation is equivalent to the weak form of Problem 9.5.4.

Following the notation in Sect. 9.3, $\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v)$ should be written as $\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,\nabla u,\partial_\nu u,v,\nabla v,\partial_\nu v)$. However, from now on, it will be written as $\mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v)$.'' -- \cite[pp. 464--467]{Azegami2020}

\subsection{Shape Optimization Problem of Domain Variation Type}
``In Sect. 9.5, we saw how the state variable $\tilde{u} = u - u_{\rm D}\in\mathcal{S}$ is determined as the solution of a state determination problem when a design variable $\boldsymbol{\phi}\in\mathcal{D}$ is given. These variables are used to define a shape optimization problem. Here, the cost functions are set to \textbf{(9.6.1)}
\begin{align*}
	f_i(\boldsymbol{\phi},u) = \int_{\Omega(\boldsymbol{\phi})} \zeta_i(\boldsymbol{\phi},u,\nabla u)\,{\rm d}{\bf x} + \int_{\Gamma_{\eta i}(\boldsymbol{\phi})} \eta_{{\rm N}i}(\boldsymbol{\phi},u)\,{\rm d}\gamma - \int_{\Gamma_{\rm D}(\boldsymbol{\phi})} \eta_{{\rm D}i}(\boldsymbol{\phi},\partial_\nu u)\,{\rm d}\gamma - c_i,\ \forall i\in\{0,1,\ldots,m\},
\end{align*}
respectively. Here $c_i$, $i = 1,\ldots,m$ are constants \& have to be determined s.t. there exists some $(\boldsymbol{\phi},\tilde{u})\in\mathcal{D}\times\mathcal{S}$ which satisfies $f_i\le 0$, $\forall i\in\{0,1,\ldots,m\}$. Moreover, $\zeta_i,\eta_{{\rm N}i}$, \& $\eta_{{\rm D}i}$ are assumed to be given \& satisfy 2 types of hypotheses as follows. Those hypotheses will be needed to obtain an appropriate regularity in the solution of a adjoint problem (Problem 9.8.1) shown later. To calculate the 2nd-order shape derivatives of cost functions, additional hypotheses are required. However, details of these conditions will be omitted \& we shall only tacitly assume that they were already satisfied to carry out a 2nd-order differentiation of the costs.

The following assumption is used when employing the formula based on the shape derivative of a function.

\begin{hypothesis}[Cost Functions (Shape Derivative)]
	W.r.t. the cost function $f_i$ ($i\in\{0,1,\ldots,m\}$) of (9.6.1), let $\zeta_i\in C^1(\mathbb{R}\times\mathbb{R}\times\mathbb{R}^d;\mathbb{R})$, $\eta_{{\rm N}i}\in C^1(\mathbb{R};\mathbb{R})$, $\eta_{{\rm D}i}\in C^1(\mathbb{R};\mathbb{R})$ be functions fixed with material satisfying [$\ldots$] Moreover, $(\cdot)_{\boldsymbol{\phi}'}(\boldsymbol{\phi},\cdot)[\boldsymbol{\varphi}]$ represents the shape derivatives of functions (Def. 9.1.1).
\end{hypothesis}
Moreover, if the formulae based on the partial shape derivative of a function are used, the following hypothesis will be used.

\begin{hypothesis}[Cost Functions (Partial Shape Derivative)]
	W.r.t. cost function $f_i$ ($i\in\{0,1,\ldots,m\}$) of (9.6.1), let $\zeta_i\in C^1(\mathbb{R}\times\mathbb{R}\times\mathbb{R}^d;\mathbb{R})$, $\eta_{{\rm N}i}\in C^1(\mathbb{R};\mathbb{R})$, $\eta_{{\rm D}i}\in C^1(\mathbb{R};\mathbb{R})$ be functions fixed in space satisfying [$\ldots$]. Moreover, $(\cdot)_{\boldsymbol{\phi}^\star}(\boldsymbol{\phi},\cdot)[\boldsymbol{\varphi}]$ represents the partial shape derivatives of functions (Def. 9.1.3).
\end{hypothesis}
These cost functions are used to define a shape optimization problem of domain variation type as follows.

\begin{problem}[Shape Optimization of Domain Variation Type]
	Let $\mathcal{D}$ \& $\mathcal{S}$ be defined as (9.1.3) \& (9.5.2), respectively. Also, let $f_0,\ldots,f_m$ is defined by (9.6.1). Find $\Omega(\boldsymbol{\phi})$ which satisfies
	\begin{align*}
		\min_{(\boldsymbol{\phi},u - u_{\rm D})\in\mathcal{D}\times\mathcal{S}} \{f_0(\boldsymbol{\phi},u)|f_1(\boldsymbol{\phi},u)\le 0,\ldots,f_m(\boldsymbol{\phi},u)\le 0,\mbox{ Problem 9.5.4}\}.
	\end{align*}
\end{problem}
In what follows, we will look at the Fr\'echet derivatives of cost functions \& the KKT conditions w.r.t. a shape optimization problem (Problem 9.6.3) of domain variation type. In this respect, Lagrange functions based on several definitions will be used. Here, their relationships are summarized in order to avoid confusion. Let the Lagrange function w.r.t. the shape optimization problem (Problem 9.6.3) of domain variation type be \textbf{(9.6.2)}
\begin{align*}
	\mathcal{L}(\boldsymbol{\phi},u,v_0,v_1,\ldots,v_m,\lambda_1,\ldots,\lambda_m) = \mathcal{L}_0(\boldsymbol{\phi},u,v_0) + \sum_{i=1}^m \lambda_i\mathcal{L}_i(\boldsymbol{\phi},u,v_i),
\end{align*}
where $\boldsymbol{\lambda} = (\lambda_1,\ldots,\lambda_m)^\top\in\mathbb{R}^m$ is a Lagrange multiplier w.r.t. $f_i(\boldsymbol{\phi},u)\le 0$, $i = 1,\ldots,m$. Furthermore, if $f_i$ is a functional of $u$ for all $i\in\{0,1,\ldots,m\}$, \& in view of the fact that the state determination problem (Problem 9.5.4) is an equality constraint, the functional \textbf{(9.6.3)}
\begin{align*}
	\mathcal{L}_i(\boldsymbol{\phi},u,v_i) = f_i(\boldsymbol{\phi},u) + \mathcal{L}_{\rm S}(\boldsymbol{\phi},u,v_i) =&\, \int_{\Omega(\boldsymbol{\phi})} \zeta_i(\boldsymbol{\phi},u,\nabla u) - \nabla u\cdot\nabla v_i + bv_i\,{\rm d}{\bf x} + \int_{\Gamma_{\eta i}(\boldsymbol{\phi})} \eta_{{\rm N}i}(\boldsymbol{\phi},u)\,{\rm d}\gamma + \int_{\Gamma_p(\boldsymbol{\phi})} p_{\rm N}v_i\,{\rm d}\gamma + \int_{\Gamma_{\rm D}(\boldsymbol{\phi})}\\
	&+ \int_{\Gamma_{\rm D}(\boldsymbol{\phi})} (u - u_{\rm D})\partial_\nu v_i + v_i\partial_\nu u - \eta_{{\rm D}i}(\boldsymbol{\phi},\partial_\nu u)\,{\rm d}\gamma - c_i
\end{align*}
is called the \textit{Lagrange function} of $f_i(\boldsymbol{\phi},u)$. Here, $\mathcal{L}_{\rm S}$ is the Lagrange function of the state determination problem defined by (9.5.3). Moreover, $v_i$ is introduced as a Lagrange multiplier w.r.t. the state determination problem corresponding to $f_i$ \& $\tilde{v}_i = v_i - \eta_{{\rm D}i\partial_\nu u}$ is assumed to be an element of $\mathcal{S}$. Similarly to $u$, if a variation $\hat{v}_i$ of $\tilde{v}_i$ is to be considered, $\hat{v}_i$ is contained in $U$.'' -- \cite[pp. 467--469]{Azegami2020}

\subsection{Existence of an Optimum Solution}
``The existence of an optimum solution of Problem 9.6.3 can be confirmed in the same fashion as in Chap. 8. To use Theorem 7.4.4 in Chap. 7, we will show the compactness of \textbf{(9.7.1)} $\mathcal{F} = \{(\boldsymbol{\phi},u(\boldsymbol{\phi}))\in\mathcal{D}\times\mathcal{S}|\mbox{Problem 9.5.4}\}$ \& the continuity of $f_0$. Hereinafter, we let $\tilde{u} = u - u_{\rm D}\in U$.

The compactness of $\mathcal{F}$ is presented in the following lemma [62, Lemma 2.5, p. 27, Lemma 2.15, p. 55, Lemma 2.20, p. 63].

\begin{lemma}[Compactness of $\mathcal{F}$]
	Suppose that Hypothesis 9.5.1 \& Hypothesis 9.5.3 are satisfied. Moreover, $\tilde{\Gamma}_0 = \Gamma_{p0}\cup\Gamma_{\eta00}\cup\Gamma_{\eta10}\cup\cdots\cup\Gamma_{\eta m0}$ is (not piecewise) $H^3\cap C^{1,1}$ class. W.r.t. an arbitrary Cauchy sequence $\boldsymbol{\phi}_n\to\boldsymbol{\phi}$ which is uniformly convergent in $\mathcal{D}$ \& their solutions $\tilde{u}_n = \tilde{u}(\boldsymbol{\phi}_n)\in U$ ($n\to\infty$) of Problem 9.5.4, the convergence $\tilde{u}_n\to\tilde{u}$ strongly in $U$ holds, \& $\tilde{u} = \tilde{u}(\boldsymbol{\phi})\in U$ solves Problem 9.5.4.
\end{lemma}
\textit{Proof.} See \cite[pp. 470--474]{Azegami2020}.

We consider that the condition of $\tilde{u}(\boldsymbol{\phi})$ included in $\mathcal{S}$ is guaranteed in the setting of Problem 9.5.4 satisfying Hypotheses 9.5.1 \& 9.5.3. The latter assumption in Theorem 7.4.4 (continuity of $f_0$) means that $f_0$ is continuous on \textbf{(9.7.12)} $S = \{(\boldsymbol{\phi},\tilde{u}(\boldsymbol{\phi}))\in\mathcal{F}|f_i(\boldsymbol{\phi},u(\boldsymbol{\phi}))\le 0,\,\forall i = 1,\ldots,m\}$. $S$ depends on the problem setting. Then, we will confirm the continuity of $f_0$ by showing the continuity of $f_i$, $\forall i = 0,\ldots,m$, by the following lemma \& assuming that $S$ is not empty.

\begin{lemma}[Continuity of $f_i$]
	Let $f_i$ be defined as in (9.6.1) under Hypothesis 9.6.1. Let $u_n\to u$ strongly in $U$ be determined by Lemma 9.7.1 w.r.t. an arbitrary Cauchy sequence $\boldsymbol{\phi}_n\to\boldsymbol{\phi}$ in $X$ which is uniformly convergent in $\mathcal{D}$, \& satisfy $\|\partial_\nu u_n - \partial_\nu u\|_{L^2(\Gamma_{\rm D};\mathbb{R})}\to 0$ ($n\to\infty$) on $\Gamma_{\rm D}$. Then, $f_i$ is continuous w.r.t. $\boldsymbol{\phi}\in\mathcal{D}$.
\end{lemma}
\textit{Proof.} See \cite[pp. 474--476]{Azegami2020}.

In Theorem 7.4.4 showing the existence of a solution in the abstract optimum design problem, the 1st assumption (compactness of $\mathcal{F}$) was confirmed by Lemma 9.7.1. The 2nd assumption (continuity of $f_0$) can be satisfied with the conditions for Lemma 9.7.2 \& the assumption that $S\ne\emptyset$. Then, under the conditions, it can be assured that there exists an optimum solution of Problem 9.6.3.

Regarding the solution of Problem 9.6.3, let us recall the similar solution of Remark 8.4.3 in Chap. 8. In the definition of $\mathcal{D}$ shown in (9.1.3), a side constraint $\|\boldsymbol{\phi}\|_{H^2\cap C^{0,1}(D;\mathbb{R}^d)}\le\beta$ is added. When this condition becomes active, we have to deal this condition as an inequality condition. Depending on the setting of the problem, we may meet a situation s.t. a boundary converges to a shape with sharp corners which is not a Lipschitz boundary. In this case, a converged shape can be obtained by activating the side constraint. Moreover, regarding the selection of $X$ \& $\mathcal{D}$, the same situation as Remark 8.4.4 holds.'' -- \cite[pp. 470--477]{Azegami2020}

\subsection{Derivatives of Cost Functions}
``In this chapter, we consider the solution of the shape optimization problem (Problem 9.6.3) of domain variation type using a gradient method \& a Newton method. In order to use the gradient method, the 1st-order shape derivatives of cost functions are necessary. Moreover, if the Newton method is to be used, the 2nd-order shape derivatives (Hessians) of the cost functions are required. Here, let us obtain the 1st \& 2nd-order shape derivatives of the cost functions $f_i$ using the Lagrange multiplier method shown in Sect. 7.5.2 \& the method shown in 7.5.3, respectively. In this case, let us look at the methods using the formulae based on the shape derivative of a function separately from the method using the formulae based on the partial shape derivative of a function shown in Sect. 9.3. However, w.r.t. the 2nd-order shape derivatives, only the results using the method with the formulae based on the shape derivative of a function will be shown.'' -- \cite[p. 477]{Azegami2020}

\subsubsection{Shape Derivative of $f_i$ Using Formulae Based on Shape Derivative of a Function}
``1stly, let us use the formulae based on the shape derivative of a function (Sect. 9.3.1) to obtain the Fr\'echet derivative of $\mathcal{L}_i$ \& use its stationary conditions to seek the shape derivative of $f_i$. The Fr\'echet derivative of $\mathcal{L}_i(\boldsymbol{\phi},u,v_i)$ is written as: \textbf{(9.8.1)}
\begin{align*}
	\mathcal{L}_i'(\boldsymbol{\phi},u,v_i)[\boldsymbol{\varphi},\hat{u},\hat{v}_i] = \mathcal{L}_{i\boldsymbol{\phi}'}(\boldsymbol{\phi},u,v_i)[\boldsymbol{\varphi}] + \mathcal{L}_{iu}(\boldsymbol{\phi},u,v_i)[\hat{u}] + \mathcal{L}_{iv_i}(\boldsymbol{\phi},u,v_i)[\hat{v}_i]
\end{align*}
w.r.t. an arbitrary $(\boldsymbol{\varphi},\hat{u},\hat{v}_i)\in X\times U\times U$. Here, the notations in (9.3.5) \& (9.3.15) are used. In this case, the shape derivative $u'$ used in (9.3.5) \& (9.3.15) following Def. 9.1.1 was replaced with an arbitrary $\hat{u}\in X$, because it was assumed that $u$ is not necessarily the solution of Problem 9.5.4 in the definition of the Lagrange function.

\subsubsection{2nd-Order Shape Derivative of $f_i$ Using Formulae Based on Shape Derivative of a Function}

\subsubsection{2nd-Order Shape Derivative of Cost Function Using Lagrange Multiplier Method}

\subsubsection{Shape Derivative of $f_i$ Using Formulae Based on Partial Shape Derivative of a Function}

\subsection{Descent Directions of Cost Functions}

\subsubsection{$H^1$ Gradient Method}

\subsubsection{$H^1$ Newton Method}

\subsection{Solution to Shape Optimization Problem of Domain Variation Type}

\subsubsection{Gradient Method for Constrained Problems}

\subsubsection{Newton Method for Constrained Problems}

\subsection{Error Estimation}

\subsection{Shape Optimization Problem of Linear Elastic Body}

\subsubsection{State Determination Problem}

\subsubsection{Mean Compliance Minimization Problem}

\subsubsection{Shape Derivatives of Cost Functions}

\subsubsection{Relation with Optimal Design Problem of Stepped 1D Linear Elastic Body}

\subsubsection{Numerical Example}

\subsection{Shape Optimization Problem of Stokes Flow Field}

\subsubsection{State Determination Problem}

\subsubsection{Mean Compliance Minimization Problem}

\subsubsection{Shape Derivatives of Cost Functions}

\subsubsection{Relation with Optimal Design Problem of Stepped 1D Linear Elastic Body}

\subsubsection{Numerical Example}

\subsection{Shape Optimization Problem of Stoke Flow Field}

\subsubsection{State Determination Problem}

\subsubsection{Mean Flow Resistance Minimization Problem}

\subsubsection{Shape Derivatives of Cost Functions}

\subsubsection{Relationship with Optimal Design Problem of 1D Branched Stokes Flow Field}

\subsubsection{Numerical Example}

\subsection{Summary}

\subsection{Practice Problems}

%------------------------------------------------------------------------------%

\section{Appendices}

%------------------------------------------------------------------------------%

\printbibliography[heading=bibintoc]
	
\end{document}